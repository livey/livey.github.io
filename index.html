<!doctype html><html lang=en dir=auto><head><meta name=generator content="Hugo 0.140.1"><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Fuwei's Tech Notes</title>
<meta name=keywords content="Computer Vision,Robotics,Software Engineering,Tech Notes,Programming,Optimization,SLAM,3D Reconstruction,SLAM,Autonomous Driving,Mathematics"><meta name=description content="Technical blog covering topics in autonomous driving, computer vision, robotics, optimization, and software engineering"><meta name=author content="Fuwei Li"><link rel=canonical href=https://livey.github.io/><link crossorigin=anonymous href=/assets/css/stylesheet.d6fcd20a4fb86efa4dfac8ec95da60244cc8871042183da1ef28e3a762ad79c8.css integrity="sha256-1vzSCk+4bvpN+sjsldpgJEzIhxBCGD2h7yjjp2Ktecg=" rel="preload stylesheet" as=style><link rel=icon href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://livey.github.io/index.xml><link rel=alternate hreflang=en href=https://livey.github.io/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="index, follow"><meta name=author content="Fuwei Li"><meta name=description content="Technical blog covering topics in autonomous driving, computer vision, robotics, optimization, and software engineering"><meta property="og:type" content="website"><meta property="og:url" content="https://livey.github.io/"><meta property="og:title" content="Fuwei's Tech Notes"><meta property="og:description" content="Technical blog covering topics in autonomous driving, computer vision, robotics, optimization, and software engineering"><meta property="og:image" content="https://livey.github.io/images/site-preview.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="Fuwei's Tech Notes"><meta name=twitter:description content="Technical blog covering topics in autonomous driving, computer vision, robotics, optimization, and software engineering"><meta name=twitter:image content="https://livey.github.io/images/site-preview.jpg"><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css integrity=sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js integrity=sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><meta property="og:url" content="https://livey.github.io/"><meta property="og:site_name" content="Fuwei's Tech Notes"><meta property="og:title" content="Fuwei's Tech Notes"><meta property="og:description" content="Technical blog covering topics in autonomous driving, computer vision, robotics, optimization, and software engineering"><meta property="og:locale" content="en"><meta property="og:type" content="website"><meta property="og:image" content="https://livey.github.io/images/site-preview.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://livey.github.io/images/site-preview.jpg"><meta name=twitter:title content="Fuwei's Tech Notes"><meta name=twitter:description content="Technical blog covering topics in autonomous driving, computer vision, robotics, optimization, and software engineering"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","name":"Fuwei's Tech Notes","url":"https://livey.github.io/","description":"Technical blog covering topics in autonomous driving, computer vision, robotics, optimization, and software engineering","logo":"https://livey.github.io/%3Clink%20/%20abs%20url%3E","sameAs":["https://github.com/livey","index.xml"]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://livey.github.io/ accesskey=h title="Home (Alt + H)"><img src=https://livey.github.io/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://livey.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://livey.github.io/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://livey.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://livey.github.io/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><article class="first-entry home-info"><header class=entry-header><h1>üëã Welcome to Fuwei&rsquo;s Tech Notes</h1></header><div class=entry-content>Hi, this is Fuwei. I&rsquo;m documenting my tech notes in this blog.</div><footer class=entry-footer><div class=social-icons><a href=https://github.com/livey target=_blank rel="noopener noreferrer me" title=Github><svg viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg>
</a><a href=index.xml target=_blank rel="noopener noreferrer me" title=Rss><svg viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></div></footer></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Coordinate Systems</h2></header><div class=entry-content><p>In this post, we will discuss the coordinate systems commonly used in autonomous driving. In practice, different positioning providers may define their own coordinate systems. This post will introduce the fundamental concepts of these coordinate systems and explain how to convert between them for your specific needs.
Pose on the Earth When we talk about pose, we refer to the position and orientation of an object in the world. In the context of autonomous driving, the world is the Earth. Therefore, pose describes the position and orientation of an object relative to the Earth.
...</p></div><footer class=entry-footer><span title='2025-02-07 00:00:00 +0000 UTC'>February 7, 2025</span>&nbsp;¬∑&nbsp;5 min&nbsp;¬∑&nbsp;1003 words&nbsp;¬∑&nbsp;Fuwei Li</footer><a class=entry-link aria-label="post link to Coordinate Systems" href=https://livey.github.io/posts/2025-02-07-coordinate/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>End of Line Camera Calibration</h2></header><div class=entry-content><p>In this post, we will discuss the end-of-line (EOL) camera calibration, especially for camera bird‚Äôs-eye view (BEV) extrinsic calibration.
Suggested Pipeline Do single camera intrinsic calibration
Measure each corner in the world coordinate
Refine the corners‚Äô coordinates according to board constraints (plane, parallel, equally spaced)
Find the plane equation in the world coordinate
Initialize each camera‚Äôs extrinsic parameters by solving the perspective and point (PnP) problem
Estimate the 3D coordinates by the intersection of the image ray and board plane
...</p></div><footer class=entry-footer><span title='2025-02-03 00:00:00 +0000 UTC'>February 3, 2025</span>&nbsp;¬∑&nbsp;11 min&nbsp;¬∑&nbsp;2243 words&nbsp;¬∑&nbsp;Fuwei Li</footer><a class=entry-link aria-label="post link to End of Line Camera Calibration" href=https://livey.github.io/posts/2025-02-eol-calib/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>3D Gaussian Splatting</h2></header><div class=entry-content><p>I highly recommend reading the two papers: [5] and [3]. [5] provides a comprehensive description of the splatting process. [3] provides an efficient implementation of the splatting process.
Problem formulation Volume rendering with radiance fields [1, 2] figure from https://www.cs.cornell.edu/courses/cs5670/2022sp/lectures/lec22_nerf_for_web.pdf. The volume density $\sigma(\mathbf{x})$ can be interpreted as the differential probability of a ray terminating (being absorbed or scattered) at an infinitesimal particle at location $\mathbf{x}$.
...</p></div><footer class=entry-footer><span title='2024-12-28 00:00:00 +0000 UTC'>December 28, 2024</span>&nbsp;¬∑&nbsp;15 min&nbsp;¬∑&nbsp;3131 words&nbsp;¬∑&nbsp;Fuwei Li</footer><a class=entry-link aria-label="post link to 3D Gaussian Splatting" href=https://livey.github.io/posts/2024-12-3dgs/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Fast LIO Paper Reading</h2></header><div class=entry-content><p>In this document, we provide detailed derivations complementing those presented in [2].
Details of the derivation Discrete model Based on the $\boxplus$ operation defined above, we can discretize the continuous model in (1) at the IMU sampling period $\Delta t$ using a zero-order holder. The resultant discrete model is
$$ \mathbf{x}_{i+1} = \mathbf{x}_i \boxplus (\Delta t f(\mathbf{x}_i, \mathbf{u}_i, \mathbf{w}_i))$$where $i$ is the index of IMU measurements, and the function $f$, state $\mathbf{x}$, input $\mathbf{u}$, and noise $\mathbf{w}$ are defined below:
...</p></div><footer class=entry-footer><span title='2024-12-27 00:00:00 +0000 UTC'>December 27, 2024</span>&nbsp;¬∑&nbsp;7 min&nbsp;¬∑&nbsp;1401 words&nbsp;¬∑&nbsp;Fuwei Li</footer><a class=entry-link aria-label="post link to Fast LIO Paper Reading" href=https://livey.github.io/posts/2024-12-fast-lio/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Iterative Closest Point Problem</h2></header><div class=entry-content><p>Problem Formulation (Point to Point ICP) Let two 3D point-sets $\mathcal{X} = \{\mathbf{x}_i\}, i = 1, \ldots, N$ and $\mathcal{Y} = \{\mathbf{y}_j\}, j = 1, \ldots, M$, where $\mathbf{x}_i, \mathbf{y}_j \in \mathbb{R}^3$ are point coordinates, be the data point-set and the model point-set respectively. The goal is to estimate a rigid motion with rotation $\mathbf{R} \in SO(3)$ and translation $\mathbf{t} \in \mathbb{R}^3$ that minimizes the following $L_2$-error $E$:
$$\underset{\mathbf{R}, \mathbf{t}}{\arg\min E(\mathbf{R}}, \mathbf{t}) = \sum_{i=1}^N e_i(\mathbf{R}, \mathbf{t})^2 = \sum_{i=1}^N \left\| \mathbf{R} \mathbf{x}_i + \mathbf{t} - \mathbf{y}_{j^*} \right\|^2 \tag{1}$$where $e_i(\mathbf{R}, \mathbf{t})$ is the per-point residual error for $x_i$. Given $\mathbf{R}$ and $\mathbf{t}$, the point $y_{j^*} \in \mathcal{Y}$ is denoted as the optimal correspondence of $x_i$, which is the closest point to the transformed $x_i$ in $\mathcal{Y}$, i.e.,
...</p></div><footer class=entry-footer><span title='2024-12-26 00:00:00 +0000 UTC'>December 26, 2024</span>&nbsp;¬∑&nbsp;6 min&nbsp;¬∑&nbsp;1118 words&nbsp;¬∑&nbsp;Fuwei Li</footer><a class=entry-link aria-label="post link to Iterative Closest Point Problem" href=https://livey.github.io/posts/2024-12-icp/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Radar Signal Processing: A Tutorial</h2></header><div class=entry-content><p>System Diagram See Appendix.VII
Figure 1: System diagram of a typical 4D mmWave radar signal processing chain (figure from [1])
Single Object Tx-Rx Model Below is a mathematical formalization of each major step in the traditional 4D mmWave Frequency Modulated Continuous Wave (FMCW) radar signal processing chain, from transmitted signals through to point-cloud generation. Please note that these equations represent a general framework; actual implementations may vary slightly depending on specific system parameters and design choices.
...</p></div><footer class=entry-footer><span title='2024-12-26 00:00:00 +0000 UTC'>December 26, 2024</span>&nbsp;¬∑&nbsp;23 min&nbsp;¬∑&nbsp;4800 words&nbsp;¬∑&nbsp;Fuwei Li</footer><a class=entry-link aria-label="post link to Radar Signal Processing: A Tutorial" href=https://livey.github.io/posts/2024-12-radar-processing/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Pose Tracking with Iterative Extended Kalman Filter</h2></header><div class=entry-content><p>Tracking ego pose is critical in autonomous driving. In this article, we will discuss how to fuse the IMU, wheel encoder, GPS, etc. to track the ego pose. We will derive the pose tracking algorithm based on the iterative extended Kalman filter. This document mainly follows [1] and [2].
Preliminaries Let $\mathcal{M}$ be the manifold of dimension $n$ in consideration (e.g., $\mathcal{M} = SO(3)$). Since manifolds are locally homeomorphic to $\mathbb{R}^n$, we can establish a bijective mapping from a local neighborhood on $\mathcal{M}$ to its tangent space $\mathbb{R}^n$ via two encapsulation operators $\boxplus$ and $\boxminus$:
...</p></div><footer class=entry-footer><span title='2024-12-24 00:00:00 +0000 UTC'>December 24, 2024</span>&nbsp;¬∑&nbsp;14 min&nbsp;¬∑&nbsp;2955 words&nbsp;¬∑&nbsp;Fuwei Li</footer><a class=entry-link aria-label="post link to Pose Tracking with Iterative Extended Kalman Filter" href=https://livey.github.io/posts/2024-12-pose-tracking/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Position Filtering with Ego Motion Compensation</h2></header><div class=entry-content><p>When tracking an object‚Äôs position, we always from the ego‚Äôs perspective. However, ego‚Äôs motion makes the tracking of the object a little difficult. The basic idea is doing the tracking on the world coordinate, then transforming into the ego-car‚Äôs coordinate. In this post, we will discuss how to combine the ego‚Äôs motion into the object‚Äôs tracking concisely.
Continuous Form Definitions The target‚Äôs movement in the world coordinate: $o(t)$; ego-car movement in the world coordinate: $g(t)$; ego-car‚Äôs heading angle: $\theta(t)$; observed target‚Äôs coordinate: $f(t)$.
...</p></div><footer class=entry-footer><span title='2024-12-02 00:00:00 +0000 UTC'>December 2, 2024</span>&nbsp;¬∑&nbsp;10 min&nbsp;¬∑&nbsp;2073 words&nbsp;¬∑&nbsp;Fuwei Li</footer><a class=entry-link aria-label="post link to Position Filtering with Ego Motion Compensation" href=https://livey.github.io/posts/2024-12-positioning-track/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Angle Kalman Filter</h2></header><div class=entry-content><p>Besides object position tracking, heading angle tracking is also critical in autonomous driving. In this article, we will discuss how to track the angle of an object using the Kalman filter and how to do motion compensation.
Wrap the angle In this paper ‚ÄúOn wrapping the Kalman filter and estimating with the SO(2) group‚Äù, the author has the conclusion:
‚Äúbased on the mathematically grounded framework of filtering on Lie groups, yields the same result as heuristically wrapping the angular variable within the EKF framework‚Äù.
...</p></div><footer class=entry-footer><span title='2024-11-30 00:00:00 +0000 UTC'>November 30, 2024</span>&nbsp;¬∑&nbsp;2 min&nbsp;¬∑&nbsp;362 words&nbsp;¬∑&nbsp;Fuwei Li</footer><a class=entry-link aria-label="post link to Angle Kalman Filter" href=https://livey.github.io/posts/2024-12-angle-filter/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Rolling Shutter Camera Projection</h2></header><div class=entry-content><p>Unlike global shutter cameras that capture the entire frame at once, rolling shutter cameras capture each row sequentially, leading to image distortions when there is motion. This paper discusses the rolling shutter effect in cameras and methods to handle it.
Fundamentals of Rolling Shutter Camera Global Shutter Camera v.s. Rolling Shutter Camera. (a) Global Shutter Camera. (b) Rolling Shutter Camera. (figure from [6]) To efficiently capture and read the image, the time constraints for rolling shutter camera are:
...</p></div><footer class=entry-footer><span title='2024-11-25 00:00:00 +0000 UTC'>November 25, 2024</span>&nbsp;¬∑&nbsp;6 min&nbsp;¬∑&nbsp;1142 words&nbsp;¬∑&nbsp;Fuwei Li</footer><a class=entry-link aria-label="post link to Rolling Shutter Camera Projection" href=https://livey.github.io/posts/2024-12-rolling-shutter/></a></article><footer class=page-footer><nav class=pagination><a class=next href=https://livey.github.io/page/2/>Next&nbsp;&nbsp;¬ª</a></nav></footer></main><footer class=footer><span>&copy; 2025 <a href=https://livey.github.io/>Fuwei's Tech Notes</a></span> ¬∑
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>
<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Iterative Closest Point Problem | Fuwei's Tech Notes</title>
<meta name=keywords content="Iterative Closest Point,ICP,Signal Processing,Optimization,SLAM"><meta name=description content="A detailed derivation of the Iterative Closest Point (ICP) problem."><meta name=author content="Fuwei Li"><link rel=canonical href=https://livey.github.io><link crossorigin=anonymous href=/assets/css/stylesheet.d6fcd20a4fb86efa4dfac8ec95da60244cc8871042183da1ef28e3a762ad79c8.css integrity="sha256-1vzSCk+4bvpN+sjsldpgJEzIhxBCGD2h7yjjp2Ktecg=" rel="preload stylesheet" as=style><link rel=icon href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://livey.github.io/posts/2024-12-icp/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="index, follow"><meta name=author content="Fuwei Li"><meta name=description content="A detailed derivation of the Iterative Closest Point (ICP) problem."><meta property="og:type" content="article"><meta property="og:url" content="https://livey.github.io/posts/2024-12-icp/"><meta property="og:title" content="Iterative Closest Point Problem"><meta property="og:description" content="A detailed derivation of the Iterative Closest Point (ICP) problem."><meta property="og:image" content="https://livey.github.io/images/site-preview.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="Iterative Closest Point Problem"><meta name=twitter:description content="A detailed derivation of the Iterative Closest Point (ICP) problem."><meta name=twitter:image content="https://livey.github.io/images/site-preview.jpg"><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css integrity=sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js integrity=sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><meta property="og:url" content="https://livey.github.io/posts/2024-12-icp/"><meta property="og:site_name" content="Fuwei's Tech Notes"><meta property="og:title" content="Iterative Closest Point Problem"><meta property="og:description" content="A detailed derivation of the Iterative Closest Point (ICP) problem."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-12-26T00:00:00+00:00"><meta property="article:modified_time" content="2024-12-26T00:00:00+00:00"><meta property="article:tag" content="Iterative Closest Point"><meta property="article:tag" content="ICP"><meta property="article:tag" content="Signal Processing"><meta property="article:tag" content="Optimization"><meta property="article:tag" content="SLAM"><meta property="og:image" content="https://livey.github.io/posts/2024-12-icp/%3Cimage%20path/url%3E"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://livey.github.io/posts/2024-12-icp/%3Cimage%20path/url%3E"><meta name=twitter:title content="Iterative Closest Point Problem"><meta name=twitter:description content="A detailed derivation of the Iterative Closest Point (ICP) problem."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://livey.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Iterative Closest Point Problem","item":"https://livey.github.io/posts/2024-12-icp/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Iterative Closest Point Problem","name":"Iterative Closest Point Problem","description":"A detailed derivation of the Iterative Closest Point (ICP) problem.","keywords":["Iterative Closest Point","ICP","Signal Processing","Optimization","SLAM"],"articleBody":"In this post, we will discuss the Iterative Closest Point (ICP) problem: from poit-to-point and point-to-plane ICP to generalized ICP.\nProblem Formulation Let two 3D point-sets $\\mathcal{X} = \\{\\mathbf{x}_i\\}, i = 1, \\ldots, N$ and $\\mathcal{Y} = \\{\\mathbf{y}_j\\}, j = 1, \\ldots, M$, where $\\mathbf{x}_i, \\mathbf{y}_j \\in \\mathbb{R}^3$ are point coordinates, be the data point-set and the model point-set respectively. The goal is to estimate a rigid motion with rotation $\\mathbf{R} \\in SO(3)$ and translation $\\mathbf{t} \\in \\mathbb{R}^3$ that minimizes the following $L_2$-error $E$:\n$$\\underset{\\mathbf{R}, \\mathbf{t}}{\\arg\\min E(\\mathbf{R}}, \\mathbf{t}) = \\sum_{i=1}^N e_i(\\mathbf{R}, \\mathbf{t})^2 = \\sum_{i=1}^N \\left\\| \\mathbf{R} \\mathbf{x}_i + \\mathbf{t} - \\mathbf{y}_{j^*} \\right\\|^2 \\tag{1}$$where $e_i(\\mathbf{R}, \\mathbf{t})$ is the per-point residual error for $x_i$. Given $\\mathbf{R}$ and $\\mathbf{t}$, the point $y_{j^*} \\in \\mathcal{Y}$ is denoted as the optimal correspondence of $x_i$, which is the closest point to the transformed $x_i$ in $\\mathcal{Y}$, i.e.,\n$$j^* = \\underset{j \\in \\{1, \\ldots, M\\}}{\\arg \\min} \\left\\| \\mathbf{R} x_i + \\mathbf{t} - \\mathbf{y}_j \\right\\|\\tag{2}$$Note the short-hand notation used here: $j^*$ varies as a function of $(\\mathbf{R}, \\mathbf{t})$ and also depends on $x_i$.\nIterative closest point algorithm solves problem (1) by iteratively solving problem (1) and (2).\nIterative Solution Solving the Problem with Fixed Pose With fixed pose, problem (2) can be solved with a computational complexity of $\\mathcal{O}(NM)$. However, we can build an oct-tree to accelerate the closest point search. Further, if the data points are received sequentially, we can use an incremental kd-tree to update the tree [4].\nSolving the Problem with Known Point Correspondence With known point correspondence, problem (1) can be solved analytically.\n$$\\min_{\\mathbf{R}\\in SO(3), \\mathbf{t}}\\|\\mathbf{R}\\mathbf{x}_i+t-\\mathbf{y}_i\\|_2^2$$For any $\\mathbf{R}$, taking the derivative of the objective with respect to $\\mathbf{t}$ and letting it equal to zero we have\n$$\\mathbf{t} = \\frac{1}{N}\\sum_i(\\mathbf{y}_i - \\mathbf{R}\\mathbf{x}_i) = \\bar{\\mathbf{y}} - \\mathbf{R}\\bar{\\mathbf{x}}$$where we have $\\bar{\\mathbf{y}}\\triangleq\\frac{1}{N}\\sum_i \\mathbf{y}_i$ and $\\bar{\\mathbf{x}}\\triangleq\\frac{1}{N}\\sum_i \\mathbf{x}_i$. So, plug them into the objective function and let $\\mathbf{x}_i\\triangleq \\mathbf{x}_i-\\bar{\\mathbf{x}}$ and $\\mathbf{y}_i\\triangleq \\mathbf{y}_i - \\bar{\\mathbf{y}}$, we have\n$$\\min_{\\mathbf{R}\\in SO(3)} \\|\\mathbf{R}\\mathbf{x}_i - \\mathbf{y}_i\\|_2^2$$It is equivalent to\n$$\\max_{\\mathbf{R}\\in SO(3)}\\,\\mathbf{y}_i^\\top\\mathbf{R}\\mathbf{x}_i$$and further we have\n$$\\max_{\\mathbf{R}\\in SO(3)}\\text{tr}(\\mathbf{R}\\sum_i \\mathbf{x}_i\\mathbf{y}_i^\\top)$$Let $\\begin{matrix}\\mathbf{M} = \\sum_i \\mathbf{x}_i\\mathbf{y}_i^\\top\\end{matrix}$. We are thus solving:\n$$\\max_{\\mathbf{R}\\in SO(3)}\\text{tr}(\\mathbf{R}\\mathbf{M})$$Let the SVD of $\\mathbf{M} = \\mathbf{U}\\mathbf{\\Sigma}\\mathbf{V}^\\top$. Then $\\text{tr}(\\mathbf{R}\\mathbf{U}\\mathbf{\\Sigma}\\mathbf{V}^\\top) = \\text{tr}(\\mathbf{V}^\\top\\mathbf{R}\\mathbf{U}\\mathbf{\\Sigma}) \\triangleq \\text{tr}(\\mathbf{Q}\\mathbf{\\Sigma})$, where $\\mathbf{Q}=\\mathbf{V}^\\top\\mathbf{R}\\mathbf{U}$ is an orthonormal matrix.\n$$\\text{tr}(\\mathbf{Q}\\mathbf{\\Sigma}) = \\sum_i q_{i,i}\\sigma_{i}\\leq \\sum_i \\sigma_{i}$$The last equality holds when $q_{i,i}=1$ for all $i$ and $\\sigma_{i,i}\u003e0$, which means $\\mathbf{Q}=\\mathbf{I}$. Therefore, we have $\\mathbf{R}=\\mathbf{V}\\mathbf{U}^\\top$.\nSince $SO(3)$ puts a determinant constraint on the orthonormal matrix with $\\text{det}(R)=1$, we have two cases:\nIf $\\text{det}(\\mathbf{R})=1$, the optimal solution is $\\mathbf{R}=\\mathbf{V}\\mathbf{U}^\\top$. If $\\text{det}(\\mathbf{R})=-1$, the algorithm fails. In the case where $\\text{det}(\\mathbf{R})=-1$ and there exists at least one $\\sigma_i$ that is zero, we can multiply $-1$ to its corresponding column of $\\mathbf{U}$ or $\\mathbf{V}$.\nIn the case where $\\text{det}(\\mathbf{R})=-1$ and all $\\sigma_i$’s are positive, “This can happen only when the noises are very large. In that case, the least-squares solution is probably useless anyway. A better approach would be to use a RANSAC-like technique (using 3 points at a time) to combat against outliers”[1].\nOther Variants of ICP Let us first write the cost of problem (1) in a more general form:\n$$ \\underset{\\mathbf{T}}{\\text{argmin}} \\sum_{i=1}^N \\ell( \\mathbf{T}\\mathbf{x}_i, \\mathbf{y}_{j^*}) $$where $\\mathbf{T} \\in SE(3)$ and we have write the points in its homogeneous form.\nRobust Point-to-point ICP When there are outliers in the dataset or not every point has a corresponding correspondence, we can use a robust loss function $\\ell$ to handle them. Typical choices are\n$$ \\ell(\\mathbf{T}\\mathbf{x}, \\mathbf{y}) = w\\|\\mathbf{T}\\mathbf{x}-\\mathbf{y}\\|_2^2 $$where\n$$ w = \\begin{cases} 1, \u0026 \\text{if } \\|\\mathbf{T}\\mathbf{x}-\\mathbf{y}\\|_2 \u003c d_{max} \\\\ 0, \u0026 \\text{otherwise} \\end{cases} $$which means when the distance is larger than $d_{max}$, the point is considered an outlier and ignored.\nPoint to Plane ICP The point-to-plane ICP is used as a more robust and accurate variant of the standard ICP. It minimizes the distance between the point and the plane [5]. The corresponding cost function is\n$$ \\ell(\\mathbf{T}\\mathbf{x}, \\mathbf{y}) = \\|w\\cdot\\mathbf{n}^\\top(\\mathbf{T}\\mathbf{x}-\\mathbf{y})\\|_2^2 $$where $\\mathbf{n}$ is the normal vector of the plane where the point $\\mathbf{y}$ is located.\nPoint to Line ICP This variant is used when we know the target feature is a line. So, the cost function is the distance between the point and the line.\n$$ \\ell(\\mathbf{T}\\mathbf{x}, \\mathbf{y}) = \\|w\\cdot(\\mathbf{I} - \\mathbf{n}\\mathbf{n}^\\top)(\\mathbf{T}\\mathbf{x}-\\mathbf{y})\\|_2^2 $$where $\\mathbf{n}$ is the unit direction vector of the line in which the point $\\mathbf{y}$ is located.\nGeneralized ICP Assume points $\\{\\mathbf{x}_i\\}_{i=1}^N$ and $\\{\\mathbf{y}_i\\}_{i=1}^N$ are already aligned, $\\mathbf{x}_i\\sim \\mathcal{N}(\\bar{\\mathbf{x}}_i, \\mathbf{C}^x_i)$ and $\\mathbf{y}_i\\sim \\mathcal{N}(\\bar{\\mathbf{y}}_i, \\mathbf{C}^y_i)$. Further, assume $\\mathbf{y}_i = \\mathbf{T}\\mathbf{x}_i$. Thus, the residual, $\\mathbf{d}^T_i = \\mathbf{y}_i - \\mathbf{T}\\mathbf{x}_i$, is distributed as $\\mathcal{N}(0, \\mathbf{C}^y_i + \\mathbf{T}\\mathbf{C}^x_i\\mathbf{T}^\\top)$. Using the maximum log likelihood estimation, we have [6]\n$$ \\underset{\\mathbf{T}}{\\text{argmin}} \\sum_{i=1}^N (\\mathbf{d}_i^T)^\\top\\left(\\mathbf{C}^y_i + \\mathbf{T}\\mathbf{C}^x_i\\mathbf{T}^\\top\\right)^{-1}\\mathbf{d}_i^T. \\tag{3} $$If we set $\\mathbf{C}_i^x = \\mathbf{0}$ and $\\mathbf{C}_i^y =\\mathbf{I}$, problem (3) is equivalent to the standard point-to-point ICP.\nIf we set $\\mathbf{C}_i^x =\\mathbf{0}$ and $\\mathbf{C}_i^y = \\mathbf{P}_i^{-1}$, where $\\mathbf{P}_i$ is the projection onto the space spanned by the plane normal. Then, problem (3) is equivalent to the point-to-plane ICP. Also, we can construct the point-to-line ICP from the generalized ICP problem formulation.\nPlane to Plane ICP If the points are generated from a plane, we can assume that the points are generated from the distribution $\\mathcal{N}(\\bar{\\mathbf{x}}, \\mathbf{\\Sigma})$, where\n$$ \\mathbf{\\Sigma} = \\mathbf{U} \\begin{bmatrix} \\mathbf{s_1} \u0026 \\mathbf{0} \u0026 \\mathbf{0} \\\\ \\mathbf{0} \u0026 \\mathbf{s_2} \u0026 \\mathbf{0} \\\\ \\mathbf{0} \u0026 \\mathbf{0} \u0026 \\mathbf{\\epsilon} \\end{bmatrix} \\mathbf{U}^\\top, $$where $\\epsilon$ should be a positive number near zero. By applying PCA on the point and along with its near by points, we can find such covariance matrix. Then, with the estimated covariance matrix, we can plug it into problem (3) to solve the generalized ICP problem, which is also called as the plane-to-plane ICP in [6]. In real practice, we should force $\\mathbf{\\Sigma}=\\text{diag}(1, 1, \\epsilon)$ to mitigate the effect of non uniformly distributed LiDAR points.\nNormal Distributions Transform Normal distributions transform [7] is published prior to generalized ICP [6].\nThe NDT models the distribution of all reconstructed 2D-Points of one laser scan by a collection of local normal distributions. First, the 2D space around the robot is subdivided regularly into cells with constant size. Then for each cell, that contains at least three points, the following is done:\nCollect all 2D-Points $\\mathbf{x}_i$, $i = 1..n$, contained in this box. Calculate the mean $\\mathbf{q} = \\frac{1}{n} \\sum_i \\mathbf{x}_i$. Calculate the covariance matrix $$ \\Sigma = \\frac{1}{n} \\sum_i (\\mathbf{x}_i - \\mathbf{q})(\\mathbf{x}_i - \\mathbf{q})^t. $$The probability of measuring a sample at 2D-point $\\mathbf{x}$ contained in this cell is now modeled by the normal distribution $N(\\mathbf{q}, \\Sigma)$:\n$$ p(\\mathbf{x}) \\sim \\exp\\left( -\\frac{(\\mathbf{x} - \\mathbf{q})^t \\Sigma^{-1} (\\mathbf{x} - \\mathbf{q})}{2} \\right). $$The outline of the proposed approach, given two scans (the first one and the second one), is as follows:\nBuild the NDT of the first scan. Initialize the estimate for the parameters (by zero or by using odometry data). For each sample of the second scan: Map the reconstructed 2D point into the coordinate frame of the first scan according to the parameters. Determine the corresponding normal distributions for each mapped point. The score for the parameters is determined by evaluating the distribution for each mapped point and summing the result. Calculate a new parameter estimate by trying to optimize the score. This is done by performing one step of Newton’s Algorithm. Go to step 3 until a convergence criterion is met. The first four steps are straightforward: Building the NDT was described in the last section. As noted above, odometry data could be used to initialize the estimate. Mapping the second scan is done using $T$ and finding the corresponding normal distribution is a simple lookup in the grid of the NDT.\nThe rest is now described in detail using the following notation:\n$\\mathbf{p} = (p_i)_{i=1..3} = (t_x, t_y, \\phi)^t$: The vector of the parameters to estimate. $\\mathbf{x}_i$: The reconstructed 2D point of laser scan sample $i$ of the second scan in the coordinate frame of the second scan. $\\mathbf{x}_i'$: The point $\\mathbf{x}_i$ mapped into the coordinate frame of the first scan according to the parameters $\\mathbf{p}$, that is $\\mathbf{x}_i' = T(\\mathbf{x}_i, \\mathbf{p})$. $\\Sigma_i$, $\\mathbf{q}_i$: The covariance matrix and the mean of the corresponding normal distribution to point $\\mathbf{x}_i'$, looked up in the NDT of the first scan. The mapping according to $\\mathbf{p}$ could be considered optimal if the sum evaluating the normal distributions of all points $\\mathbf{x}_i'$ with parameters $\\Sigma_i$ and $\\mathbf{q}_i$ is a maximum. We call this sum the score of $\\mathbf{p}$. It is defined as:\n$$ \\text{score}(\\mathbf{p}) = \\sum_i \\exp\\left( -\\frac{(\\mathbf{x}_i' - \\mathbf{q}_i)^t \\Sigma_i^{-1} (\\mathbf{x}_i' - \\mathbf{q}_i)}{2} \\right). $$Finally, Newton’s method is applied iteratively to find the optimal parameters.\nVoxelized GICP Voxelized GICP [8] is build upon GICP [6]. It employs a poit to multi-voxel mapping so that it eliminates the nearest neighbor search in the GICP. Then, it can efficiently compute the loss function by parallelizing the computation.\nThe following notation is similar to the one used in Eq. (3).\nTo derive the voxelized GICP algorithm, we first extend $\\tilde{\\mathbf{d}}_i$ so that it calculates the distances between $\\mathbf{a}_i$ and its neighbor points $\\{\\mathbf{b}_j \\mid \\|\\mathbf{a}_i - \\mathbf{b}_j\\| \u003c r\\}$ as follows:\n$$ \\tilde{\\mathbf{d}}_i = \\sum_j \\left( \\hat{\\mathbf{b}}_j - \\mathbf{T} \\hat{\\mathbf{a}}_i \\right). $$This equation can be interpreted as smoothing the target point distributions. Then, the distribution of $\\tilde{\\mathbf{d}}_i$ is given by\n$$ \\tilde{\\mathbf{d}}_i \\sim \\left( \\boldsymbol{\\mu}^{\\tilde{d}_i}, \\mathbf{C}^{\\tilde{d}_i} \\right), $$$$ \\mathbf{\\mu}^{\\tilde{d}_i} = \\sum_j \\left( \\hat{\\mathbf{b}}_j - \\mathbf{T} \\hat{\\mathbf{a}}_i \\right) = \\mathbf{0}, $$$$ \\mathbf{C}^{\\tilde{d}_i} = \\sum_j \\left( \\mathbf{C}^B_j + \\mathbf{T} \\mathbf{C}^A_i \\mathbf{T}^T \\right). $$We estimate the transformation $\\mathbf{T}$ that maximizes the log-likelihood of as follows:\n$$ \\mathbf{T} = \\arg\\min_\\mathbf{T} \\sum_i \\left( \\tilde{\\mathbf{d}}_i^T \\tilde{\\mathbf{C}}_i^{-1} \\tilde{\\mathbf{d}}_i \\right), $$where\n$$ \\tilde{\\mathbf{d}}_i = \\sum_j \\left( \\mathbf{b}_j - \\mathbf{T} \\mathbf{a}_i \\right), $$$$ \\tilde{\\mathbf{C}}_i = \\sum_j \\left( \\mathbf{C}^B_j + \\mathbf{T} \\mathbf{C}^A_i \\mathbf{T}^T \\right). $$To efficiently calculate the above equation, we modify it to:\n$$ \\mathbf{T} = \\arg\\min_\\mathbf{T} \\sum_i \\left( N_i \\tilde{\\mathbf{d}}_i^T \\tilde{\\mathbf{C}}_i^{-1} \\tilde{\\mathbf{d}}_i \\right), $$where:\n$$ \\tilde{\\mathbf{d}}_i = \\frac{\\sum_j \\mathbf{b}_j}{N_i} - \\mathbf{T} \\mathbf{a}_i, $$$$ \\tilde{\\mathbf{C}}_i = \\frac{\\sum_j \\mathbf{C}^B_j}{N_i} + \\mathbf{T} \\mathbf{C}^A_i \\mathbf{T}^T. $$where $N_i$ is the number of neighbor points. It suggests that we can efficiently compute the objective function by substituting the mean of the distributions of the points ($\\mathbf{b}_j$ and $\\mathbf{C}^B_j$) around $\\mathbf{a}_i$ for $\\mathbf{b}_i$ and $\\mathbf{C}^B_i$ and weighting the function by $N_i$.\nWe can naturally adapt this equation to voxel-based calculation by storing $\\mathbf{b}'_i = \\frac{\\sum \\mathbf{b}_j}{N_i}$ and $\\mathbf{C}'_i = \\frac{\\sum \\mathbf{C}^B_j}{N_i}$ in each voxel.\nFollowing the log-likelihood function, it uses Gauss-Newton method to optimize the objective function.\nReferences [1] K. S. Arun, T. S. Huang, and S. D. Blostein, “Least-Squares Fitting of Two 3-D Point Sets,” IEEE Trans. Pattern Anal. Mach. Intell., vol. PAMI-9, no. 5, pp. 698–700, Sep. 1987, doi: 10.1109/TPAMI.1987.4767965.\n[2] Y. Zheng, Y. Kuang, S. Sugimoto, K. Astrom, and M. Okutomi, “Revisiting the PnP Problem: A Fast, General and Optimal Solution,” in 2013 IEEE International Conference on Computer Vision, Sydney, Australia: IEEE, Dec. 2013, pp. 2344–2351. doi: 10.1109/ICCV.2013.291.\n[3] G. Terzakis and M. Lourakis, “A Consistently Fast and Globally Optimal Solution to the Perspective-n-Point Problem,” in Computer Vision – ECCV 2020, vol. 12346, A. Vedaldi, H. Bischof, T. Brox, and J.-M. Frahm, Eds., in Lecture Notes in Computer Science, vol. 12346. , Cham: Springer International Publishing, 2020, pp. 478–494. doi: 10.1007/978-3-030-58452-8_28.\n[4] Cai, Yixi, Wei Xu, and Fu Zhang. “ikd-tree: An incremental kd tree for robotic applications.” arXiv preprint arXiv:2102.10808 (2021).\n[5] Chen, Yang, and Gérard Medioni. “Object modelling by registration of multiple range images.” Image and vision computing 10.3 (1992): 145-155.\n[6] Segal, Aleksandr, Dirk Haehnel, and Sebastian Thrun. “Generalized-icp.” Robotics: science and systems. Vol. 2. No. 4. 2009.\n[7] P. Biber and W. Strasser, “The normal distributions transform: a new approach to laser scan matching,” in Proceedings 2003 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2003) (Cat. No.03CH37453), Las Vegas, Nevada, USA: IEEE, 2003, pp. 2743–2748. doi: 10.1109/IROS.2003.1249285.\n[8] K. Koide, M. Yokozuka, S. Oishi, and A. Banno, “Voxelized GICP for Fast and Accurate 3D Point Cloud Registration,” in 2021 IEEE International Conference on Robotics and Automation (ICRA), Xi’an, China: IEEE, May 2021, pp. 11054–11059. doi: 10.1109/ICRA48506.2021.9560835.\n","wordCount":"1982","inLanguage":"en","image":"https://livey.github.io/posts/2024-12-icp/%3Cimage%20path/url%3E","datePublished":"2024-12-26T00:00:00Z","dateModified":"2024-12-26T00:00:00Z","author":{"@type":"Person","name":"Fuwei Li"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://livey.github.io/posts/2024-12-icp/"},"publisher":{"@type":"Organization","name":"Fuwei's Tech Notes","logo":{"@type":"ImageObject","url":"https://livey.github.io/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://livey.github.io/ accesskey=h title="Home (Alt + H)"><img src=https://livey.github.io/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://livey.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://livey.github.io/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://livey.github.io/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://livey.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://livey.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Iterative Closest Point Problem</h1><div class=post-description>A detailed derivation of the Iterative Closest Point (ICP) problem.</div><div class=post-meta><span title='2024-12-26 00:00:00 +0000 UTC'>December 26, 2024</span>&nbsp;·&nbsp;10 min&nbsp;·&nbsp;1982 words&nbsp;·&nbsp;Fuwei Li&nbsp;|&nbsp;<a href=https://github.com/livey/livey.github.io/issues/new rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#problem-formulation aria-label="Problem Formulation">Problem Formulation</a></li><li><a href=#iterative-solution aria-label="Iterative Solution">Iterative Solution</a><ul><li><a href=#solving-the-problem-with-fixed-pose aria-label="Solving the Problem with Fixed Pose">Solving the Problem with Fixed Pose</a></li><li><a href=#solving-the-problem-with-known-point-correspondence aria-label="Solving the Problem with Known Point Correspondence">Solving the Problem with Known Point Correspondence</a></li></ul></li><li><a href=#other-variants-of-icp aria-label="Other Variants of ICP">Other Variants of ICP</a><ul><li><a href=#robust-point-to-point-icp aria-label="Robust Point-to-point ICP">Robust Point-to-point ICP</a></li><li><a href=#point-to-plane-icp aria-label="Point to Plane ICP">Point to Plane ICP</a></li><li><a href=#point-to-line-icp aria-label="Point to Line ICP">Point to Line ICP</a></li><li><a href=#generalized-icp aria-label="Generalized ICP">Generalized ICP</a></li><li><a href=#plane-to-plane-icp aria-label="Plane to Plane ICP">Plane to Plane ICP</a></li><li><a href=#normal-distributions-transform aria-label="Normal Distributions Transform">Normal Distributions Transform</a></li><li><a href=#voxelized-gicp aria-label="Voxelized GICP">Voxelized GICP</a></li></ul></li><li><a href=#references aria-label=References>References</a></li></ul></div></details></div><div class=post-content><p>In this post, we will discuss the Iterative Closest Point (ICP) problem: from poit-to-point and point-to-plane ICP to generalized ICP.</p><h1 id=problem-formulation>Problem Formulation<a hidden class=anchor aria-hidden=true href=#problem-formulation>#</a></h1><p>Let two 3D point-sets $\mathcal{X} = \{\mathbf{x}_i\}, i = 1, \ldots, N$ and $\mathcal{Y} = \{\mathbf{y}_j\}, j = 1, \ldots, M$, where $\mathbf{x}_i, \mathbf{y}_j \in \mathbb{R}^3$ are point coordinates, be the data point-set and the model point-set respectively. The goal is to estimate a rigid motion with rotation $\mathbf{R} \in SO(3)$ and translation $\mathbf{t} \in \mathbb{R}^3$ that minimizes the following $L_2$-error $E$:</p>$$\underset{\mathbf{R}, \mathbf{t}}{\arg\min E(\mathbf{R}}, \mathbf{t}) = \sum_{i=1}^N e_i(\mathbf{R}, \mathbf{t})^2 = \sum_{i=1}^N \left\| \mathbf{R} \mathbf{x}_i + \mathbf{t} - \mathbf{y}_{j^*} \right\|^2 \tag{1}$$<p>where $e_i(\mathbf{R}, \mathbf{t})$ is the per-point residual error for $x_i$. Given $\mathbf{R}$ and $\mathbf{t}$, the point $y_{j^*} \in \mathcal{Y}$ is denoted as the optimal correspondence of $x_i$, which is the closest point to the transformed $x_i$ in $\mathcal{Y}$, i.e.,</p>$$j^* = \underset{j \in \{1, \ldots, M\}}{\arg \min} \left\| \mathbf{R} x_i + \mathbf{t} - \mathbf{y}_j \right\|\tag{2}$$<p>Note the short-hand notation used here: $j^*$ varies as a function of $(\mathbf{R}, \mathbf{t})$ and also depends on $x_i$.</p><p>Iterative closest point algorithm solves problem (1) by iteratively solving problem (1) and (2).</p><h1 id=iterative-solution>Iterative Solution<a hidden class=anchor aria-hidden=true href=#iterative-solution>#</a></h1><h2 id=solving-the-problem-with-fixed-pose>Solving the Problem with Fixed Pose<a hidden class=anchor aria-hidden=true href=#solving-the-problem-with-fixed-pose>#</a></h2><p>With fixed pose, problem (2) can be solved with a computational complexity of $\mathcal{O}(NM)$. However, we can build an oct-tree to accelerate the closest point search. Further, if the data points are received sequentially, we can use an incremental kd-tree to update the tree [4].</p><h2 id=solving-the-problem-with-known-point-correspondence>Solving the Problem with Known Point Correspondence<a hidden class=anchor aria-hidden=true href=#solving-the-problem-with-known-point-correspondence>#</a></h2><p>With known point correspondence, problem (1) can be solved analytically.</p>$$\min_{\mathbf{R}\in SO(3), \mathbf{t}}\|\mathbf{R}\mathbf{x}_i+t-\mathbf{y}_i\|_2^2$$<p>For any $\mathbf{R}$, taking the derivative of the objective with respect to $\mathbf{t}$ and letting it equal to zero we have</p>$$\mathbf{t} = \frac{1}{N}\sum_i(\mathbf{y}_i - \mathbf{R}\mathbf{x}_i) = \bar{\mathbf{y}} - \mathbf{R}\bar{\mathbf{x}}$$<p>where we have $\bar{\mathbf{y}}\triangleq\frac{1}{N}\sum_i \mathbf{y}_i$ and $\bar{\mathbf{x}}\triangleq\frac{1}{N}\sum_i \mathbf{x}_i$. So, plug them into the objective function and let $\mathbf{x}_i\triangleq \mathbf{x}_i-\bar{\mathbf{x}}$ and $\mathbf{y}_i\triangleq \mathbf{y}_i - \bar{\mathbf{y}}$, we have</p>$$\min_{\mathbf{R}\in SO(3)} \|\mathbf{R}\mathbf{x}_i - \mathbf{y}_i\|_2^2$$<p>It is equivalent to</p>$$\max_{\mathbf{R}\in SO(3)}\,\mathbf{y}_i^\top\mathbf{R}\mathbf{x}_i$$<p>and further we have</p>$$\max_{\mathbf{R}\in SO(3)}\text{tr}(\mathbf{R}\sum_i \mathbf{x}_i\mathbf{y}_i^\top)$$<p>Let $\begin{matrix}\mathbf{M} = \sum_i \mathbf{x}_i\mathbf{y}_i^\top\end{matrix}$. We are thus solving:</p>$$\max_{\mathbf{R}\in SO(3)}\text{tr}(\mathbf{R}\mathbf{M})$$<p>Let the SVD of $\mathbf{M} = \mathbf{U}\mathbf{\Sigma}\mathbf{V}^\top$. Then $\text{tr}(\mathbf{R}\mathbf{U}\mathbf{\Sigma}\mathbf{V}^\top) = \text{tr}(\mathbf{V}^\top\mathbf{R}\mathbf{U}\mathbf{\Sigma}) \triangleq \text{tr}(\mathbf{Q}\mathbf{\Sigma})$, where $\mathbf{Q}=\mathbf{V}^\top\mathbf{R}\mathbf{U}$ is an orthonormal matrix.</p>$$\text{tr}(\mathbf{Q}\mathbf{\Sigma}) = \sum_i q_{i,i}\sigma_{i}\leq \sum_i \sigma_{i}$$<p>The last equality holds when $q_{i,i}=1$ for all $i$ and $\sigma_{i,i}>0$, which means $\mathbf{Q}=\mathbf{I}$. Therefore, we have $\mathbf{R}=\mathbf{V}\mathbf{U}^\top$.</p><p>Since $SO(3)$ puts a determinant constraint on the orthonormal matrix with $\text{det}(R)=1$, we have two cases:</p><ol><li>If $\text{det}(\mathbf{R})=1$, the optimal solution is $\mathbf{R}=\mathbf{V}\mathbf{U}^\top$.</li><li>If $\text{det}(\mathbf{R})=-1$, the algorithm fails.</li></ol><p>In the case where $\text{det}(\mathbf{R})=-1$ and there exists at least one $\sigma_i$ that is zero, we can multiply $-1$ to its corresponding column of $\mathbf{U}$ or $\mathbf{V}$.</p><p>In the case where $\text{det}(\mathbf{R})=-1$ and all $\sigma_i$&rsquo;s are positive, &ldquo;This can happen only when the noises are very large. In that case, the least-squares solution is probably useless anyway. A better approach would be to use a RANSAC-like technique (using 3 points at a time) to combat against outliers&rdquo;[1].</p><h1 id=other-variants-of-icp>Other Variants of ICP<a hidden class=anchor aria-hidden=true href=#other-variants-of-icp>#</a></h1><p>Let us first write the cost of problem (1) in a more general form:</p>$$
\underset{\mathbf{T}}{\text{argmin}}
\sum_{i=1}^N \ell( \mathbf{T}\mathbf{x}_i, \mathbf{y}_{j^*})
$$<p>where $\mathbf{T} \in SE(3)$ and we have write the points in its homogeneous form.</p><h2 id=robust-point-to-point-icp>Robust Point-to-point ICP<a hidden class=anchor aria-hidden=true href=#robust-point-to-point-icp>#</a></h2><p>When there are outliers in the dataset or not every point has a corresponding correspondence, we can use a robust loss function $\ell$ to handle them. Typical choices are</p>$$
\ell(\mathbf{T}\mathbf{x}, \mathbf{y}) = w\|\mathbf{T}\mathbf{x}-\mathbf{y}\|_2^2
$$<p>where</p>$$
w =
\begin{cases}
1, & \text{if } \|\mathbf{T}\mathbf{x}-\mathbf{y}\|_2 < d_{max} \\
0, & \text{otherwise}
\end{cases}
$$<p>which means when the distance is larger than $d_{max}$, the point is considered an outlier and ignored.</p><h2 id=point-to-plane-icp>Point to Plane ICP<a hidden class=anchor aria-hidden=true href=#point-to-plane-icp>#</a></h2><p>The point-to-plane ICP is used as a more robust and accurate variant of the standard ICP. It minimizes the distance between the point and the plane [5]. The corresponding cost function is</p>$$
\ell(\mathbf{T}\mathbf{x}, \mathbf{y}) = \|w\cdot\mathbf{n}^\top(\mathbf{T}\mathbf{x}-\mathbf{y})\|_2^2
$$<p>where $\mathbf{n}$ is the normal vector of the plane where the point $\mathbf{y}$ is located.</p><h2 id=point-to-line-icp>Point to Line ICP<a hidden class=anchor aria-hidden=true href=#point-to-line-icp>#</a></h2><p>This variant is used when we know the target feature is a line. So, the cost function is the distance between the point and the line.</p>$$
\ell(\mathbf{T}\mathbf{x}, \mathbf{y}) = \|w\cdot(\mathbf{I} - \mathbf{n}\mathbf{n}^\top)(\mathbf{T}\mathbf{x}-\mathbf{y})\|_2^2
$$<p>where $\mathbf{n}$ is the unit direction vector of the line in which the point $\mathbf{y}$ is located.</p><h2 id=generalized-icp>Generalized ICP<a hidden class=anchor aria-hidden=true href=#generalized-icp>#</a></h2><p>Assume points $\{\mathbf{x}_i\}_{i=1}^N$ and $\{\mathbf{y}_i\}_{i=1}^N$ are already aligned, $\mathbf{x}_i\sim \mathcal{N}(\bar{\mathbf{x}}_i, \mathbf{C}^x_i)$ and $\mathbf{y}_i\sim \mathcal{N}(\bar{\mathbf{y}}_i, \mathbf{C}^y_i)$. Further, assume $\mathbf{y}_i = \mathbf{T}\mathbf{x}_i$. Thus, the residual, $\mathbf{d}^T_i = \mathbf{y}_i - \mathbf{T}\mathbf{x}_i$, is distributed as $\mathcal{N}(0, \mathbf{C}^y_i + \mathbf{T}\mathbf{C}^x_i\mathbf{T}^\top)$.
Using the maximum log likelihood estimation, we have [6]</p>$$
\underset{\mathbf{T}}{\text{argmin}} \sum_{i=1}^N (\mathbf{d}_i^T)^\top\left(\mathbf{C}^y_i + \mathbf{T}\mathbf{C}^x_i\mathbf{T}^\top\right)^{-1}\mathbf{d}_i^T. \tag{3}
$$<p>If we set $\mathbf{C}_i^x = \mathbf{0}$ and $\mathbf{C}_i^y =\mathbf{I}$, problem (3) is equivalent to the standard point-to-point ICP.</p><p>If we set $\mathbf{C}_i^x =\mathbf{0}$ and $\mathbf{C}_i^y = \mathbf{P}_i^{-1}$, where $\mathbf{P}_i$ is the projection onto the space spanned by the plane normal. Then, problem (3) is equivalent to the point-to-plane ICP. Also, we can construct the point-to-line ICP from the generalized ICP problem formulation.</p><h2 id=plane-to-plane-icp>Plane to Plane ICP<a hidden class=anchor aria-hidden=true href=#plane-to-plane-icp>#</a></h2><p>If the points are generated from a plane, we can assume that the points are generated from the distribution $\mathcal{N}(\bar{\mathbf{x}}, \mathbf{\Sigma})$, where</p>$$
\mathbf{\Sigma} =
\mathbf{U}
\begin{bmatrix}
\mathbf{s_1} & \mathbf{0} & \mathbf{0} \\
\mathbf{0} & \mathbf{s_2} & \mathbf{0} \\
\mathbf{0} & \mathbf{0} & \mathbf{\epsilon}
\end{bmatrix}
\mathbf{U}^\top,
$$<p>where $\epsilon$ should be a positive number near zero. By applying PCA on the point and along with its near by points, we can find such covariance matrix. Then, with the estimated covariance matrix, we can plug it into problem (3) to solve the generalized ICP problem, which is also called as the plane-to-plane ICP in [6]. In real practice, we should force $\mathbf{\Sigma}=\text{diag}(1, 1, \epsilon)$ to mitigate the effect of non uniformly distributed LiDAR points.</p><h2 id=normal-distributions-transform>Normal Distributions Transform<a hidden class=anchor aria-hidden=true href=#normal-distributions-transform>#</a></h2><p>Normal distributions transform [7] is published prior to generalized ICP [6].</p><p>The NDT models the distribution of all reconstructed 2D-Points of one laser scan by a collection of local normal distributions. First, the 2D space around the robot is subdivided regularly into cells with constant size. Then for each cell, that contains at least three points, the following is done:</p><ol><li>Collect all 2D-Points $\mathbf{x}_i$, $i = 1..n$, contained in this box.</li><li>Calculate the mean $\mathbf{q} = \frac{1}{n} \sum_i \mathbf{x}_i$.</li><li>Calculate the covariance matrix</li></ol>$$
\Sigma = \frac{1}{n} \sum_i (\mathbf{x}_i - \mathbf{q})(\mathbf{x}_i - \mathbf{q})^t.
$$<p>The probability of measuring a sample at 2D-point $\mathbf{x}$ contained in this cell is now modeled by the normal distribution $N(\mathbf{q}, \Sigma)$:</p>$$
p(\mathbf{x}) \sim \exp\left( -\frac{(\mathbf{x} - \mathbf{q})^t \Sigma^{-1} (\mathbf{x} - \mathbf{q})}{2} \right).
$$<p>The outline of the proposed approach, given two scans (the first one and the second one), is as follows:</p><ol><li>Build the NDT of the first scan.</li><li>Initialize the estimate for the parameters (by zero or by using odometry data).</li><li>For each sample of the second scan: Map the reconstructed 2D point into the coordinate frame of the first scan according to the parameters.</li><li>Determine the corresponding normal distributions for each mapped point.</li><li>The score for the parameters is determined by evaluating the distribution for each mapped point and summing the result.</li><li><strong>Calculate a new parameter estimate</strong> by trying to optimize the score. This is done by performing one step of Newton&rsquo;s Algorithm.</li><li><strong>Go to step 3</strong> until a convergence criterion is met.</li></ol><p>The first four steps are straightforward: Building the NDT was described in the last section. As noted above, odometry data could be used to initialize the estimate. Mapping the second scan is done using $T$ and finding the corresponding normal distribution is a simple lookup in the grid of the NDT.</p><p>The rest is now described in detail using the following notation:</p><ul><li>$\mathbf{p} = (p_i)_{i=1..3} = (t_x, t_y, \phi)^t$: The vector of the parameters to estimate.</li><li>$\mathbf{x}_i$: The reconstructed 2D point of laser scan sample $i$ of the second scan in the coordinate frame of the second scan.</li><li>$\mathbf{x}_i'$: The point $\mathbf{x}_i$ mapped into the coordinate frame of the first scan according to the parameters $\mathbf{p}$, that is $\mathbf{x}_i' = T(\mathbf{x}_i, \mathbf{p})$.</li><li>$\Sigma_i$, $\mathbf{q}_i$: The covariance matrix and the mean of the corresponding normal distribution to point $\mathbf{x}_i'$, looked up in the NDT of the first scan.</li></ul><p>The mapping according to $\mathbf{p}$ could be considered optimal if the sum evaluating the normal distributions of all points $\mathbf{x}_i'$ with parameters $\Sigma_i$ and $\mathbf{q}_i$ is a maximum. We call this sum the <strong>score</strong> of $\mathbf{p}$. It is defined as:</p>$$
\text{score}(\mathbf{p}) = \sum_i \exp\left( -\frac{(\mathbf{x}_i' - \mathbf{q}_i)^t \Sigma_i^{-1} (\mathbf{x}_i' - \mathbf{q}_i)}{2} \right).
$$<p>Finally, Newton&rsquo;s method is applied iteratively to find the optimal parameters.</p><h2 id=voxelized-gicp>Voxelized GICP<a hidden class=anchor aria-hidden=true href=#voxelized-gicp>#</a></h2><p>Voxelized GICP [8] is build upon GICP [6]. It employs a poit to multi-voxel mapping so that it eliminates the nearest neighbor search in the GICP. Then, it can efficiently compute the loss function by parallelizing the computation.</p><p><img alt="ICP Illustration" loading=lazy src=/posts/2024-12-icp/resources/image.png></p><p>The following notation is similar to the one used in Eq. (3).</p><p>To derive the voxelized GICP algorithm, we first extend $\tilde{\mathbf{d}}_i$ so that it calculates the distances between $\mathbf{a}_i$ and its neighbor points $\{\mathbf{b}_j \mid \|\mathbf{a}_i - \mathbf{b}_j\| < r\}$ as follows:</p>$$
\tilde{\mathbf{d}}_i = \sum_j \left( \hat{\mathbf{b}}_j - \mathbf{T} \hat{\mathbf{a}}_i \right).
$$<p>This equation can be interpreted as smoothing the target point distributions. Then, the distribution of $\tilde{\mathbf{d}}_i$ is given by</p>$$
\tilde{\mathbf{d}}_i \sim \left( \boldsymbol{\mu}^{\tilde{d}_i}, \mathbf{C}^{\tilde{d}_i} \right),
$$$$
\mathbf{\mu}^{\tilde{d}_i} = \sum_j \left( \hat{\mathbf{b}}_j - \mathbf{T} \hat{\mathbf{a}}_i \right) = \mathbf{0},
$$$$
\mathbf{C}^{\tilde{d}_i} = \sum_j \left( \mathbf{C}^B_j + \mathbf{T} \mathbf{C}^A_i \mathbf{T}^T \right).
$$<p>We estimate the transformation $\mathbf{T}$ that maximizes the log-likelihood of as follows:</p>$$
\mathbf{T} = \arg\min_\mathbf{T} \sum_i \left( \tilde{\mathbf{d}}_i^T \tilde{\mathbf{C}}_i^{-1} \tilde{\mathbf{d}}_i \right),
$$<p>where</p>$$
\tilde{\mathbf{d}}_i = \sum_j \left( \mathbf{b}_j - \mathbf{T} \mathbf{a}_i \right),
$$$$
\tilde{\mathbf{C}}_i = \sum_j \left( \mathbf{C}^B_j + \mathbf{T} \mathbf{C}^A_i \mathbf{T}^T \right).
$$<p>To efficiently calculate the above equation, we modify it to:</p>$$
\mathbf{T} = \arg\min_\mathbf{T} \sum_i \left( N_i \tilde{\mathbf{d}}_i^T \tilde{\mathbf{C}}_i^{-1} \tilde{\mathbf{d}}_i \right),
$$<p>where:</p>$$
\tilde{\mathbf{d}}_i = \frac{\sum_j \mathbf{b}_j}{N_i} - \mathbf{T} \mathbf{a}_i,
$$$$
\tilde{\mathbf{C}}_i = \frac{\sum_j \mathbf{C}^B_j}{N_i} + \mathbf{T} \mathbf{C}^A_i \mathbf{T}^T.
$$<p>where $N_i$ is the number of neighbor points. It suggests that we can efficiently compute the objective function by substituting the mean of the distributions of the points ($\mathbf{b}_j$ and $\mathbf{C}^B_j$) around $\mathbf{a}_i$ for $\mathbf{b}_i$ and $\mathbf{C}^B_i$ and weighting the function by $N_i$.</p><p>We can naturally adapt this equation to voxel-based calculation by storing $\mathbf{b}'_i = \frac{\sum \mathbf{b}_j}{N_i}$ and $\mathbf{C}'_i = \frac{\sum \mathbf{C}^B_j}{N_i}$ in each voxel.</p><p>Following the log-likelihood function, it uses Gauss-Newton method to optimize the objective function.</p><h1 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h1><p>[1] K. S. Arun, T. S. Huang, and S. D. Blostein, “Least-Squares Fitting of Two 3-D Point Sets,” IEEE Trans. Pattern Anal. Mach. Intell., vol. PAMI-9, no. 5, pp. 698–700, Sep. 1987, doi: 10.1109/TPAMI.1987.4767965.</p><p>[2] Y. Zheng, Y. Kuang, S. Sugimoto, K. Astrom, and M. Okutomi, “Revisiting the PnP Problem: A Fast, General and Optimal Solution,” in 2013 IEEE International Conference on Computer Vision, Sydney, Australia: IEEE, Dec. 2013, pp. 2344–2351. doi: 10.1109/ICCV.2013.291.</p><p>[3] G. Terzakis and M. Lourakis, “A Consistently Fast and Globally Optimal Solution to the Perspective-n-Point Problem,” in Computer Vision – ECCV 2020, vol. 12346, A. Vedaldi, H. Bischof, T. Brox, and J.-M. Frahm, Eds., in Lecture Notes in Computer Science, vol. 12346. , Cham: Springer International Publishing, 2020, pp. 478–494. doi: 10.1007/978-3-030-58452-8_28.</p><p>[4] Cai, Yixi, Wei Xu, and Fu Zhang. &ldquo;ikd-tree: An incremental kd tree for robotic applications.&rdquo; arXiv preprint arXiv:2102.10808 (2021).</p><p>[5] Chen, Yang, and Gérard Medioni. &ldquo;Object modelling by registration of multiple range images.&rdquo; Image and vision computing 10.3 (1992): 145-155.</p><p>[6] Segal, Aleksandr, Dirk Haehnel, and Sebastian Thrun. &ldquo;Generalized-icp.&rdquo; Robotics: science and systems. Vol. 2. No. 4. 2009.</p><p>[7] P. Biber and W. Strasser, “The normal distributions transform: a new approach to laser scan matching,” in Proceedings 2003 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2003) (Cat. No.03CH37453), Las Vegas, Nevada, USA: IEEE, 2003, pp. 2743–2748. doi: 10.1109/IROS.2003.1249285.</p><p>[8] K. Koide, M. Yokozuka, S. Oishi, and A. Banno, “Voxelized GICP for Fast and Accurate 3D Point Cloud Registration,” in 2021 IEEE International Conference on Robotics and Automation (ICRA), Xi’an, China: IEEE, May 2021, pp. 11054–11059. doi: 10.1109/ICRA48506.2021.9560835.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://livey.github.io/tags/iterative-closest-point/>Iterative Closest Point</a></li><li><a href=https://livey.github.io/tags/icp/>ICP</a></li><li><a href=https://livey.github.io/tags/signal-processing/>Signal Processing</a></li><li><a href=https://livey.github.io/tags/optimization/>Optimization</a></li><li><a href=https://livey.github.io/tags/slam/>SLAM</a></li></ul><nav class=paginav><a class=prev href=https://livey.github.io/posts/2024-12-fast-lio/><span class=title>« Prev</span><br><span>Fast LIO Paper Reading</span>
</a><a class=next href=https://livey.github.io/posts/2024-12-radar-processing/><span class=title>Next »</span><br><span>Radar Signal Processing: A Tutorial</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Iterative Closest Point Problem on x" href="https://x.com/intent/tweet/?text=Iterative%20Closest%20Point%20Problem&amp;url=https%3a%2f%2flivey.github.io%2fposts%2f2024-12-icp%2f&amp;hashtags=IterativeClosestPoint%2cICP%2cSignalProcessing%2cOptimization%2cSLAM"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Iterative Closest Point Problem on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2flivey.github.io%2fposts%2f2024-12-icp%2f&amp;title=Iterative%20Closest%20Point%20Problem&amp;summary=Iterative%20Closest%20Point%20Problem&amp;source=https%3a%2f%2flivey.github.io%2fposts%2f2024-12-icp%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Iterative Closest Point Problem on reddit" href="https://reddit.com/submit?url=https%3a%2f%2flivey.github.io%2fposts%2f2024-12-icp%2f&title=Iterative%20Closest%20Point%20Problem"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Iterative Closest Point Problem on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2flivey.github.io%2fposts%2f2024-12-icp%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Iterative Closest Point Problem on whatsapp" href="https://api.whatsapp.com/send?text=Iterative%20Closest%20Point%20Problem%20-%20https%3a%2f%2flivey.github.io%2fposts%2f2024-12-icp%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Iterative Closest Point Problem on telegram" href="https://telegram.me/share/url?text=Iterative%20Closest%20Point%20Problem&amp;url=https%3a%2f%2flivey.github.io%2fposts%2f2024-12-icp%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Iterative Closest Point Problem on ycombinator" href="https://news.ycombinator.com/submitlink?t=Iterative%20Closest%20Point%20Problem&u=https%3a%2f%2flivey.github.io%2fposts%2f2024-12-icp%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://livey.github.io/>Fuwei's Tech Notes</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>
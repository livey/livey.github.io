<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Radar Signal Processing: A Tutorial | Fuwei's Tech Notes</title>
<meta name=keywords content="Radar,Signal Processing,Tutorial"><meta name=description content="A tutorial on radar signal processing and the article is partially generated by ChatGPT-o1"><meta name=author content="Fuwei Li"><link rel=canonical href=https://livey.github.io><link crossorigin=anonymous href=/assets/css/stylesheet.d6fcd20a4fb86efa4dfac8ec95da60244cc8871042183da1ef28e3a762ad79c8.css integrity="sha256-1vzSCk+4bvpN+sjsldpgJEzIhxBCGD2h7yjjp2Ktecg=" rel="preload stylesheet" as=style><link rel=icon href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://livey.github.io/posts/2024-12-radar-processing/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="index, follow"><meta name=author content="Fuwei Li"><meta name=description content="A tutorial on radar signal processing and the article is partially generated by ChatGPT-o1"><meta property="og:type" content="article"><meta property="og:url" content="https://livey.github.io/posts/2024-12-radar-processing/"><meta property="og:title" content="Radar Signal Processing: A Tutorial"><meta property="og:description" content="A tutorial on radar signal processing and the article is partially generated by ChatGPT-o1"><meta property="og:image" content="https://livey.github.io/images/site-preview.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="Radar Signal Processing: A Tutorial"><meta name=twitter:description content="A tutorial on radar signal processing and the article is partially generated by ChatGPT-o1"><meta name=twitter:image content="https://livey.github.io/images/site-preview.jpg"><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css integrity=sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js integrity=sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><meta property="og:url" content="https://livey.github.io/posts/2024-12-radar-processing/"><meta property="og:site_name" content="Fuwei's Tech Notes"><meta property="og:title" content="Radar Signal Processing: A Tutorial"><meta property="og:description" content="A tutorial on radar signal processing and the article is partially generated by ChatGPT-o1"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-12-26T00:00:00+00:00"><meta property="article:modified_time" content="2024-12-26T00:00:00+00:00"><meta property="article:tag" content="Radar"><meta property="article:tag" content="Signal Processing"><meta property="article:tag" content="Tutorial"><meta property="og:image" content="https://livey.github.io/posts/2024-12-radar-processing/%3Cimage%20path/url%3E"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://livey.github.io/posts/2024-12-radar-processing/%3Cimage%20path/url%3E"><meta name=twitter:title content="Radar Signal Processing: A Tutorial"><meta name=twitter:description content="A tutorial on radar signal processing and the article is partially generated by ChatGPT-o1"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://livey.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Radar Signal Processing: A Tutorial","item":"https://livey.github.io/posts/2024-12-radar-processing/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Radar Signal Processing: A Tutorial","name":"Radar Signal Processing: A Tutorial","description":"A tutorial on radar signal processing and the article is partially generated by ChatGPT-o1","keywords":["Radar","Signal Processing","Tutorial"],"articleBody":"System Diagram See Appendix.VII\nFigure 1: System diagram of a typical 4D mmWave radar signal processing chain (figure from [1])\nSingle Object Tx-Rx Model Below is a mathematical formalization of each major step in the traditional 4D mmWave Frequency Modulated Continuous Wave (FMCW) radar signal processing chain, from transmitted signals through to point-cloud generation. Please note that these equations represent a general framework; actual implementations may vary slightly depending on specific system parameters and design choices.\nNotation and Definitions:\n$f_c$: Carrier frequency of the radar.\n$B$: Bandwidth swept by each chirp.\n$T_c$: Chirp duration (time taken to sweep the bandwidth B).\n$T_f$: Frame duration (consisting of $N_c$ chirps).\n$N_c$: Number of chirps per frame.\n$M$: Number of samples per chirp (fast-time samples).\n$N$: Number of slow-time samples (across chirps), typically equals $N_c$.\n$P$: Number of virtual antenna elements (after combining Tx-Rx pairs).\n$\\lambda$: Wavelength of the radar signal.\n$d$: Spacing between adjacent virtual antenna elements.\n$j=\\sqrt{-1}$.\nTransmitted FMCW Chirp Signal A single FMCW chirp can be modeled as a complex exponential with a time-varying instantaneous frequency:\n$$s_{\\text{TX}}(t) = A_{\\text{TX}} e^{j2\\pi \\left( f_c t + \\frac{B}{2T_c} t^2 \\right)} \\quad \\text{for } t \\in [0, T_c]$$For a frame of $N_c$ chirps, each chirp is repeated with a period $T_f = N_c T_c$ (neglecting idle times for simplicity):\n$$s_{\\text{TX,frame}}(t) = \\sum_{n=0}^{N_c-1} s_{\\text{TX}}(t - nT_c) u(t - nT_c) $$where $u(t)$ is the unit step function ensuring the waveform is only defined during each chirp interval.\nTarget Reflection and Received Signal Assume one point target at range $R$ moving with radial velocity $v$. The received signal from that target after reflection is delayed and Doppler shifted:\n$$s_{\\text{RX}}(t) = A_{\\text{RX}} e^{j2\\pi \\left(f_c (t - \\tau) + \\frac{B}{2T_c} (t - \\tau)^2 \\right)} e^{j2\\pi f_D t}$$where\n$\\tau = \\frac{2R}{c}$ is the round-trip delay (with $c$ the speed of light),\n$f_D = \\frac{2v}{\\lambda}$ is the Doppler frequency due to target motion, where $v\u003e0$ indicates the target is approaching the radar (higher received frequency); $v\u003c0$ denotes the target is moving away from the radar (lower received frequency).\nIn practice, multiple targets sum linearly:\n$$s_{\\text{RX}}(t) = \\sum_{\\ell} A_{\\ell} e^{j2\\pi \\left( f_c (t - \\tau_{\\ell}) + \\frac{B}{2T_c} (t - \\tau_{\\ell})^2 \\right)} e^{j2\\pi f_{D,\\ell} t}$$Please refer Appendix.II for the meaning of $A_\\ell$.\nMixing and Downconversion The received signal (Appendix.III) is mixed with a replica of the transmitted chirp (local oscillator, LO):\n$$s_{\\text{IF}}(t) = s_{\\text{RX}}(t)\\cdot s_{\\text{LO}}^*(t)$$where $s^*_{LO}$ indicates the conjugate of $s_{LO}$.\nLet $s_{\\text{LO}}(t) = e^{j2\\pi (f_c t + \\frac{B}{2T_c}t^2)}$\nThen:\n$$s_{\\text{IF}}(t) = \\sum_{\\ell} A_{\\ell} e^{j2\\pi\\left( (f_c(t-\\tau_\\ell)+\\frac{B}{2T_c}(t-\\tau_\\ell)^2 + f_{D,\\ell} t) - (f_c t + \\frac{B}{2T_c} t^2) \\right)}$$After simplification (assuming $\\tau_\\ell$ and Doppler are small relative to the chirp period see Appendix.IV):\n$$s_{\\text{IF}}(t) \\approx \\sum_{\\ell} A_{\\ell} e^{-j2\\pi \\left( f_{R,\\ell} t \\right)} e^{j2\\pi f_{D,\\ell} t}$$Where $f_{R,\\ell} = \\frac{2 B R_{\\ell}}{c T_c}$ is the beat frequency related to target range.\nThus the IF signal carries range (beat frequency) and Doppler (phase change across chirps) information.\nADC Sampling and Data Cube Formation The IF signal is sampled at a rate $f_s=\\frac{1}{T_s}$ yielding discrete samples for each chirp. For the $p$-th antenna element, the $m$-th sample in the $n$-th chirp is:\n$$x[m,n,p] = s_{\\text{IF},p}(mT_s + nT_c)$$with $m = 0,\\dots,M-1$; $n = 0,\\dots,N_c-1$; $p = 0,\\dots,P-1$.\nThis forms a 3D data cube:\nFast-time (range dimension): $m$\nSlow-time (Doppler dimension): $n$\nAntenna (spatial dimension): $p$\nRange-Doppler Processing Why they are called range FFT and doppler FFT (Appendix.V)\nRange FFT: We apply an M-point FFT along the fast-time dimension to transform from time samples to frequency (range) domain:\n$$X_{\\text{range}}[k,n,p] = \\sum_{m=0}^{M-1} x[m,n,p] e^{-j\\frac{2\\pi k m}{M}}, \\quad k=0,\\dots,M-1$$Each k-index corresponds to a particular range bin.\nDoppler FFT: Then, we apply an N-point FFT along the slow-time (chirp) dimension to extract Doppler information:\n$$X_{\\text{RD}}[k,l,p] = \\sum_{n=0}^{N-1} X_{\\text{range}}[k,n,p] e^{-j\\frac{2\\pi l n}{N}}, \\quad l=0,\\dots,N-1$$Each l-index corresponds to a Doppler bin (velocity).\nThis produces a Range-Doppler (RD) map for each antenna $p$.\nAngle Estimation (Spatial FFT or Beamforming) To estimate angle, we use the antenna array. If the p-th antenna element is located at $d_p = p \\cdot d$, the received signal for a target at angle $\\theta$ has a phase progression:\n$$X_{\\text{RDA}}[k,l,\\theta] = \\sum_{p=0}^{P-1} X_{\\text{RD}}[k,l,p] w_p(\\theta) e^{-j \\frac{2\\pi}{\\lambda} d_p \\sin(\\theta)}$$Here:\n$w_p(\\theta)$ are optional beamforming weights.\nBy performing an P-point FFT over p instead of a sum over a continuous angle, we discretize angles into angular bins. For a uniform linear array (ULA):\n$$X_{\\text{RDA}}[k,l,q] = \\sum_{p=0}^{P-1} X_{\\text{RD}}[k,l,p] e^{-j\\frac{2\\pi}{P} p q}$$where q indexes discrete angle bins. Similar extensions are made for elevation using a 2D antenna array, resulting in a 4D cube: (Range, Doppler, Azimuth, Elevation).\nCFAR Detection A Constant False Alarm Rate (CFAR) detector sets a threshold based on local noise statistics. For each cell $(k,l,q)$ in the RDA cube, we estimate noise power from a neighboring window and set a threshold:\n$$T(k,l,q) = \\alpha \\cdot \\hat{\\sigma}^2(k,l,q)$$where $\\hat{\\sigma}^2$ is the estimated noise variance and $\\alpha$ a scaling factor based on desired false alarm probability. A detection occurs if:\n$$|X_{\\text{RDA}}[k,l,q]|^2 \u003e T(k,l,q)$$ Digital Beamforming (DBF) (Appendix.VIII)\nIf we use a weighting vector $\\mathbf{w}$ (e.g., minimum variance distortionless response (MVDR) or other beamformer):\n$$X_{\\text{RDA}}[k,l,\\theta] = \\mathbf{w}^H(\\theta) \\mathbf{X}_{\\text{RD}}[k,l]$$where $\\mathbf{X}_{\\text{RD}}[k,l]$ is the vector of RD samples across antennas (Appendix.IX) and $\\mathbf{w}(\\theta)$ is chosen to form a beam in the direction $\\theta$.\nPoint Cloud Generation After detection, we convert range $R_k$, angle $\\theta_q$ (and $\\phi$ if elevation is considered), and Doppler $v_l$ bins into Cartesian coordinates:\n$$x = R_k \\cos(\\theta_q) \\cos(\\phi), \\quad y = R_k \\sin(\\theta_q) \\cos(\\phi), \\quad z = R_k \\sin(\\phi)$$Velocity can be derived from Doppler frequency ():\n$$v = \\frac{\\lambda l}{2N T_c}$$Each detected cell forms a point in the 3D space with an associated velocity, resulting in a point cloud:\n$$\\mathcal{P} = \\{(x_i, y_i, z_i, v_i) \\mid \\text{CFAR detection holds}\\}$$ In summary Transmission \u0026 Reception: Defined by chirp signals and their reflections.\nMixing \u0026 Downconversion: Produces IF signals with range-Doppler information encoded as beat frequencies and slow-time phase shifts.\n$$x[m,n,p]$$ samples form a 3D tensor.\nRange \u0026 Doppler FFTs: Convert time-domain samples into range-Doppler spectra: $X_{\\text{RD}}[k,l,p]$.\nAngle Estimation: Spatial processing (FFT or beamforming) yields $X_{\\text{RDA}}[k,l,q]$, a 4D data cube (range, Doppler, azimuth, elevation).\nCFAR Detection: Sets thresholds and identifies target cells.\nPoint Cloud Generation: Converts detected bins into Cartesian coordinates and velocities.\nExtend to MIMO System When extended to MIMO system, the signal transmitted via different antennas are orthogonal. So, problem will be simplified into the trans-receiver pair problem as we have discussed before.\nAppendix I: The transmitted signal The factor $\\frac{B}{2T_c}$ appears in the phase term of the transmitted FMCW signal because of the integral relationship between frequency and phase.\nDetailed Explanation: Instantaneous Frequency vs. Phase: A linear frequency-modulated (chirp) signal sweeps from a starting frequency $f_c$ to $f_c + B$ over a duration $T_c$. The instantaneous frequency $f(t)$ of such a chirp is usually defined as: $$f(t) = f_c + \\frac{B}{T_c} t \\quad \\text{for } 0 \\leq t \\leq T_c$$ From Frequency to Phase: The transmitted signal $$s_{\\text{TX}}(t)$$ in complex exponential form can be written as: $$s_{\\text{TX}}(t) = A_{\\text{TX}} e^{j \\phi(t)}$$Since $f(t) = f_c + \\frac{B}{T_c} t$, the angular frequency is:\n$$\\omega(t) = 2 \\pi \\left( f_c + \\frac{B}{T_c} t \\right)$$ Integrating to Get Phase: The phase $\\phi(t)$ is given by: $$\\phi(t) = \\int_0^t \\omega(\\tau) d\\tau = \\int_0^t 2\\pi \\left( f_c + \\frac{B}{T_c}\\tau \\right) d\\tau.$$Performing the integration:\n$$\\phi(t) = 2\\pi \\left( f_c t + \\frac{B}{T_c} \\frac{t^2}{2} \\right) = 2\\pi f_c t + 2\\pi \\frac{B}{2T_c} t^2$$ Resulting Phase Expression: After integration, the phase term associated with the chirp’s frequency sweep has a quadratic component $\\frac{B}{2T_c} t^2$, not $\\frac{B}{T_c} t^2$. The factor of $\\frac{1}{2}$ emerges naturally from the integral of a linear function. Thus the transmitted signal is:\n$$s_{\\text{TX}}(t) = A_{\\text{TX}} e^{j2\\pi \\left( f_c t + \\frac{B}{2T_c} t^2 \\right)}$$In summary The slope of the frequency is $\\frac{B}{T_c}$.\nThe phase is the integral of frequency over time.\nIntegrating a linearly increasing frequency (which goes as $f(t) = f_c + (B/T_c) t$) introduces a factor of $1/2$ in front of the $t^2$ term.\nThis is why the phase term has $\\frac{B}{2T_c}$ rather than $\\frac{B}{T_c}$.\nII: The received amplitude In the context of the received radar signal model, $A_\\ell$ represents the complex amplitude corresponding to the $\\ell$-th target’s reflected signal. Specifically, it encapsulates all the gain, attenuation, and reflectivity factors associated with that particular target, including:\nTarget Reflectivity (Radar Cross Section, RCS): Different targets reflect radar waves differently depending on their shape, orientation, and material properties. A larger or more reflective target will contribute a higher amplitude return.\nPropagation Losses: The signal undergoes attenuation while traveling to the target and back. The amplitude decreases with range and is also influenced by atmospheric conditions.\nAntenna Gain Patterns: The gain of the transmitting and receiving antennas in the direction of the target affects the amplitude of the received signal. Targets that lie in the main lobe of the antenna pattern will produce larger amplitude returns than those in sidelobes.\nChannel and System Factors: The receiver’s front-end gain, noise figure, and other hardware elements also factor into the effective amplitude captured in $A_\\ell$.\nIn essence, $A_\\ell$ combines all these effects into a single complex scalar that, when multiplied by the phase term of the $\\ell$-th target’s return, gives the overall contribution of that target’s echo to the received signal.\nIII: Intermediate Frequency “IF” stands for Intermediate Frequency; in radar and other RF systems, the signal received at the antenna is typically at the original (or a very high) carrier frequency. Before it is sampled or digitized, it is mixed with a locally generated reference signal to shift it down to a lower, more manageable frequency range called the intermediate frequency. This process simplifies subsequent signal processing steps such as filtering, amplification, and analog-to-digital conversion.\nSo, $s_{IF}(t)$ refers to the received radar signal after it has been mixed (downconverted) from the original RF (radio frequency) carrier down to an intermediate frequency.\nIV: Simplify the intermediate signal When deriving the IF signal and inserting the time delay $\\tau_\\ell$ and Doppler term $f_{D,\\ell}$, the expression initially appears complicated because of the quadratic term in $2(t-\\tau_\\ell)^2$. The phrase “assuming $\\tau_\\ell$ and Doppler are small relative to the chirp period” refers to making reasonable approximations that drop very small second-order terms, leaving only the dominant, physically meaningful components.\nStep-by-Step Detail:\nStarting Point: After mixing the received signal with the local oscillator (LO), we had something like: $$s_{\\text{IF}}(t) = \\sum_{\\ell} A_{\\ell} \\exp\\left\\{ j2\\pi \\left[ f_c (t-\\tau_\\ell) + \\tfrac{B}{2T_c}(t-\\tau_\\ell)^2 + f_{D,\\ell} t - \\left(f_c t + \\tfrac{B}{2T_c} t^2\\right) \\right] \\right\\}$$ Expand the Quadratic Term: Expand $(t - \\tau_\\ell)^2 = t^2 - 2t\\tau_\\ell + \\tau_\\ell^2$. Substituting this in gives: $$f_c(t-\\tau_\\ell) + \\tfrac{B}{2T_c}(t-\\tau_\\ell)^2 = f_c t - f_c \\tau_\\ell + \\tfrac{B}{2T_c}(t^2 - 2t\\tau_\\ell + \\tau_\\ell^2)$$ Combine Terms: Now, the exponent inside the summation becomes: $$f_c t - f_c \\tau_\\ell + \\frac{B}{2T_c}(t^2 - 2t\\tau_\\ell + \\tau_\\ell^2) + f_{D,\\ell} t - f_c t - \\frac{B}{2T_c} t^2$$Notice that $f_c t$ and $-f_c t$ cancel. Also, $\\frac{B}{2T_c} t^2$ and $-\\frac{B}{2T_c} t^2$ cancel. After these cancellations, we have:\n$$- f_c \\tau_\\ell + \\frac{B}{2T_c}(- 2t\\tau_\\ell + \\tau_\\ell^2) + f_{D,\\ell} t$$his simplifies to:\n$$- f_c \\tau_\\ell - \\frac{B}{T_c} t \\tau_\\ell + \\frac{B}{2T_c}\\tau_\\ell^2 + f_{D,\\ell} t$$ Applying the “Small” Assumptions: The main assumptions are:\n$\\tau_\\ell = \\frac{2R_\\ell}{c}$ is small compared to the chirp duration $T_c$. This means $\\tau_\\ell^2$ (a second-order small term) is even smaller and can be neglected.\nThe Doppler frequency $f_{D,\\ell}$ is typically much smaller than the chirp’s instantaneous bandwidth spread $\\frac{B}{T_c}$, so its influence within a single chirp period is limited to a nearly linear phase term $f_{D,\\ell} t$.\nBy neglecting $\\tau_\\ell^2$, we discard:\n$$\\frac{B}{2T_c}\\tau_\\ell^2 \\approx 0$$Thus, we have:\n$$s_{\\text{IF}}(t) \\approx \\sum_{\\ell} A_{\\ell} e^{j2\\pi \\left(- f_c \\tau_\\ell - \\frac{B}{T_c} t \\tau_\\ell + f_{D,\\ell} t \\right)}$$This can be rearranged as:\n$$s_{\\text{IF}}(t) \\approx \\sum_{\\ell} A_{\\ell} e^{-j2\\pi f_c \\tau_\\ell} e^{-j2\\pi \\left( \\frac{B}{T_c} \\tau_\\ell \\right) t} e^{j2\\pi f_{D,\\ell} t}$$ Defining the Range Frequency $f_{R,\\ell}$: Recall that $\\tau_\\ell = \\frac{2 R_\\ell}{c}$. By defining:\n$$f_{R,\\ell} = \\frac{B}{T_c}\\tau_\\ell = \\frac{B}{T_c}\\cdot \\frac{2R_\\ell}{c}$$we identify the term $\\frac{B}{T_c}\\tau_\\ell$ as the “beat frequency” associated with the target’s range. Now the equation becomes:\n$$s_{\\text{IF}}(t) \\approx \\sum_{\\ell} A_{\\ell} e^{-j2\\pi f_c \\tau_\\ell} e^{-j2\\pi f_{R,\\ell} t} e^{j2\\pi f_{D,\\ell} t}$$ Absorbing Constant Phase into Amplitude: The factor $e^{-j2\\pi f_c \\tau_\\ell}$ is a constant phase term (does not depend on t). Such a constant phase can be absorbed into the amplitude $A_{\\ell}$ since amplitudes in complex notation can carry both magnitude and phase information. Define:\n$$A_{\\ell}' = A_{\\ell} e^{-j2\\pi f_c \\tau_\\ell}$$With this redefinition, we have:\n$$s_{\\text{IF}}(t) \\approx \\sum_{\\ell} A_{\\ell}' e^{-j2\\pi f_{R,\\ell} t} e^{j2\\pi f_{D,\\ell} t}$$ Final Form: Combining the exponential terms for range and Doppler, we arrive at:\n$$s_{\\text{IF}}(t) \\approx \\sum_{\\ell} A_{\\ell}' e^{-j2\\pi f_{R,\\ell} t} e^{j2\\pi f_{D,\\ell} t}$$V: Rang and doppler FFT Why “Range FFT”? The first FFT, commonly referred to as the Range FFT, is performed along the fast-time axis (the time samples within a single chirp). In an FMCW radar system, each chirp sweeps linearly in frequency over a bandwidth B. When this transmitted chirp is reflected by a target at some range R, the received echo is time-delayed by $\\tau = \\frac{2R}{c}$. Mixing the received signal with the transmitted chirp produces a beat frequency $f_{b}$ proportional to that delay, and hence proportional to the target’s range. Specifically, the relationship is:\n$$f_{b} \\approx \\frac{2B}{cT_c} R$$where $c$ is the speed of light and $T_c$ is the chirp duration.\nWhen you take a Fourier Transform (FFT) of the time-domain samples of the IF (intermediate frequency) signal within one chirp, you convert these samples from time domain into frequency domain. Each frequency bin corresponds to a potential beat frequency $f_{b}$, and thus directly maps to a range bin. Hence, the first FFT is called the Range FFT because performing it reveals the target’s range information.\nWhy “Doppler FFT”? The second FFT, known as the Doppler FFT, is applied along the slow-time axis. Slow-time refers to the sequence of successive chirps within a radar frame. If a target is moving, the small changes in the echo’s phase or frequency from one chirp to the next encode the Doppler shift $f_{D}$. The Doppler shift is related to the target’s radial velocity $v$ as:\n$$f_{D} = \\frac{2v}{\\lambda}$$where $\\lambda$ is the radar wavelength.\nBy taking an FFT across multiple chirps (the slow-time dimension), you transform from the time domain (sequence of returns over chirps) into the Doppler frequency domain. Each bin in this Doppler spectrum corresponds to a different velocity. Thus, the second FFT is called the Doppler FFT, as performing it reveals the velocity (Doppler) information of the targets.\nHow Range and Doppler Are Encoded: Range Encoding (Fast-Time Dimension): Within a single chirp, the time delay to a target introduces a beat frequency after mixing. This beat frequency is directly tied to the target’s range. Thus, the “fast-time” samples encode range information. Taking the FFT along this axis converts time samples into frequency bins that represent different ranges.\nDoppler Encoding (Slow-Time Dimension): Across multiple chirps, a moving target causes a slight phase shift in each subsequent echo. Over many chirps, these phase changes manifest as a sinusoidal variation in the slow-time domain. Taking an FFT across the slow-time samples converts these variations into a Doppler frequency. This Doppler frequency bin corresponds to the target’s radial velocity. Thus, the “slow-time” samples encode Doppler (velocity) information.\nIn Summary The first FFT (“Range FFT”) extracts range by turning per-chirp time-domain samples into a frequency spectrum where each frequency bin corresponds to a certain range.\nThe second FFT (“Doppler FFT”) extracts velocity by turning the sequence of echoes over multiple chirps into a frequency spectrum where each frequency bin corresponds to a certain radial velocity.\nVI: Velocity Derivation $v = \\frac{\\lambda l}{2N T_c}$ relates the target’s radial velocity $v$ to the Doppler bin index $l$, where $\\lambda$ is the radar wavelength, $N$ is the number of chirps per frame used in the Doppler FFT, and $T_c$ is the chirp duration (or the pulse repetition interval when considering one chirp per interval).\nDerivation Steps Definition of Doppler Frequency: A moving target induces a Doppler frequency shift $f_D$ in the radar signal. For a target moving directly along the radar’s line-of-sight, the Doppler frequency is given by: $$f_D = \\frac{2v}{\\lambda}$$Here, $v$ is the target’s radial velocity and $\\lambda$ is the radar wavelength. The factor of 2 comes from the round-trip nature of the radar measurement (signal going to the target and reflecting back).\nDoppler FFT and Frequency Bins: The Doppler FFT is typically computed over $N$ chirps in a frame. The time between consecutive chirps is $T_c$. Thus, the total frame duration for Doppler processing is approximately: $$T_{\\text{frame}} = N T_c$$When you take an N-point FFT over these N slow-time samples, the Doppler frequency resolution (the spacing between adjacent Doppler frequency bins) is:\n$$\\Delta f_D = \\frac{1}{N T_c}$$This means that each Doppler bin index $l$ (ranging from $l = 0, 1, \\ldots, N-1$) corresponds to a Doppler frequency:\n$$f_{D,l} = l \\Delta f_D = \\frac{l}{N T_c}$$ Relating Doppler Frequency to Velocity Since $f_D = \\frac{2v}{\\lambda}$, we have:\n$$\\frac{2v}{\\lambda} = f_{D,l} = \\frac{l}{N T_c}$$Solving for $v$:\n$$v = \\frac{\\lambda}{2} \\cdot \\frac{l}{N T_c}$$ Final Relationship: Thus, we get: $$v = \\frac{\\lambda l}{2N T_c}$$Intuition Each Doppler bin $l$ corresponds to a certain Doppler frequency shift $f_{D,l}$.\nThe Doppler frequency resolution $\\Delta f_D$ depends on the total slow-time observation window $N T_c$. Longer observation time (more chirps) yields finer Doppler resolution.\nMapping the Doppler frequency back to velocity uses the fundamental radar Doppler equation $f_D = 2v/\\lambda$.\nIn summary, the formula is derived by first determining the Doppler frequency per FFT bin, then using the Doppler-velocity relationship to convert frequency into a corresponding radial velocity.\nVII: Why (5a, 6a) and (5b, 6b) in two different paths In many radar processing architectures, there are two general approaches to extracting angle information and detecting targets. The diagram you are referring to likely shows two parallel paths labeled as (5a, 6a) and (5b, 6b) to represent these different possible processing sequences:\nPath (5a, 6a): Angle Estimation Before Detection\n(5a) Angle/Spatial FFT: After the Range-Doppler (RD) processing, the data still contains all range-Doppler bins, including noise, clutter, and potential targets. Applying an angle estimation step (such as a spatial FFT across antennas) at this stage produces a full Range-Doppler-Angle (RDA) cube.\n(6a) CFAR Detection in 3D/4D Space: Once you have the RDA cube, you run CFAR detection in this higher-dimensional space. The targets are detected directly in the RDA domain. This approach ensures that angle estimation is done on all data before detection, potentially increasing computational load since you’re performing angle estimation for every bin, even if most are noise.\nPath (5b, 6b): Detection Before Angle Estimation\n(5b) CFAR Detection in Range-Doppler Domain: In this path, you first detect the presence of potential targets in the Range-Doppler map using CFAR before doing any angle estimation. The CFAR process identifies a small number of “candidate” bins as potential targets.\n(6b) Angle Estimation Only for Detected Points: Instead of computing angle for every bin, you only apply angle estimation techniques (spatial FFT, beamforming, or other angle finding methods) to those bins that have passed the detection threshold. This greatly reduces the computational burden since angle estimation is done only for a handful of detected target bins rather than for the entire RD map.\nWhy Two Paths? These two paths represent different trade-offs and system design choices:\nPath (5a, 6a) - Angle First, Then Detect:\nPros: You have complete angle information at the time of detection, potentially yielding more accurate detections since you know the angular distribution of returns.\nCons: More computationally expensive because angle processing is done on all cells, the majority of which may be noise.\nPath (5b, 6b) - Detect First, Then Angle:\nPros: More computationally efficient since you narrow down candidate target cells first and only then do the more complex angle estimation.\nCons: You must be careful that your detection in just the Range-Doppler domain is robust enough that you don’t miss weak targets that could have been more easily identified after angle processing.\nIn summary The diagram shows these two paths separately to illustrate different possible workflows in radar signal processing. They are not necessarily both used simultaneously; rather, they represent two common methodologies: either you perform angle estimation before detection (Path 5a, 6a) or you perform detection first and then angle estimation only for detected targets (Path 5b, 6b).\nVIII: Digital beamforming Digital Beamforming (DBF) is the process by which signals received from multiple antennas are combined with carefully chosen complex weights to form a beam that is “steered” toward a desired angle (or set of angles). It’s a key technique in radar and wireless communications that leverages antenna arrays and advanced signal processing to improve directional selectivity, enhance signal-to-noise ratio (SNR) for targets of interest, and suppress interference.\nWhat is $\\mathbf{w}(\\theta)$? $\\mathbf{w}(\\theta)$ is a vector of complex weights applied to the signals from each element of the antenna array to focus the radar’s sensitivity in a particular direction specified by the angle $\\theta$. Consider an array of $P$ antenna elements. At a given time or frequency bin, you have a vector of received signals:\n$$\\mathbf{x} = \\begin{bmatrix} x_0 \\\\ x_1 \\\\ \\vdots \\\\ x_{P-1} \\end{bmatrix}$$where $x_p$ is the signal from the p-th antenna element.\nA beamformer output $y(\\theta)$ that “looks” or “points” in direction $\\theta$ is formed by taking a weighted sum of these antenna signals:\n$$y(\\theta) = \\mathbf{w}(\\theta)^H \\mathbf{x} = \\sum_{p=0}^{P-1} w_p(\\theta) x_p$$Interpreting the Weight $\\mathbf{w}(\\theta)$ Array Geometry and Phase Shifts: If you know the geometry of your antenna array (e.g., a Uniform Linear Array), the signal arriving from angle $\\theta$ at each element will have a different phase due to the path length difference. By choosing: $$w_p(\\theta) = e^{-j2\\pi \\frac{d_p}{\\lambda} \\sin(\\theta)}$$ where $d_p$ is the position of the $p$-th antenna element, you can align (or “steer”) the phases so that a signal arriving from $\\theta$ adds constructively across all elements. This is the simplest form of beamformer weight selection (often called a delay-and-sum or conventional beamformer).\nWeight Optimization Criteria: More sophisticated beamforming techniques optimize $\\mathbf{w}(\\theta)$ based on criteria such as:\nMaximal Signal-to-Noise Ratio (SNR): Choose weights that maximize the SNR for signals from direction $\\theta$.\nMinimize Interference: Choose weights to null out signals from known interference angles.\nMinimum Variance Distortionless Response (MVDR) or Capon Beamformer: Solve an optimization problem that minimizes output power subject to maintaining a distortionless response in the desired direction. This leads to: $\\mathbf{w}_{\\text{MVDR}}(\\theta) = \\frac{\\mathbf{R}^{-1}\\mathbf{a}(\\theta)}{\\mathbf{a}(\\theta)^H \\mathbf{R}^{-1} \\mathbf{a}(\\theta)}$, where $\\mathbf{R}$ is the noise-plus-interference covariance matrix and $\\mathbf{a}(\\theta)$ is the array steering vector (the expected signal response of the array from angle $\\theta$).\nArray Steering Vector $\\mathbf{a}(\\theta)$ The vector $\\mathbf{a}(\\theta)$ describes how a plane wave from direction $\\theta$ is received at the array elements:\n$$\\mathbf{a}(\\theta) = \\begin{bmatrix} e^{-j2\\pi \\frac{d_0}{\\lambda}\\sin(\\theta)} \\\\[6pt] e^{-j2\\pi \\frac{d_1}{\\lambda}\\sin(\\theta)} \\\\[6pt] \\vdots \\\\[6pt] e^{-j2\\pi \\frac{d_{P-1}}{\\lambda}\\sin(\\theta)} \\end{bmatrix}$$ Result of Applying\u0026$\\mathbf{w}(\\theta)$: By applying the chosen beamformer weights, the antenna array focuses its sensitivity. Signals from the desired angle $\\theta$ add coherently, boosting their amplitude, while signals from other angles add less coherently or are actively suppressed. This directional sensitivity is what improves angular resolution and target detection capability in radar systems. In Short:\n$\\mathbf{w}(\\theta)$ is a vector of complex filter coefficients applied to the array elements.\nIt’s determined by the desired beam direction and any optimization criteria for improved SNR, reduced interference, or super-resolution angle estimation.\nThe choice of $\\mathbf{w}(\\theta)$ transforms a simple multi-antenna receive pattern into a powerful tool for focusing on specific directions in space, hence the name “digital beamforming.”\nIX: The RD sample $\\mathbf{X}_{\\text{RD}}[k,l]$ represents the vector of complex signal samples from the antenna array at a specific range bin $k$ and Doppler bin $l$, after the Range and Doppler FFTs have been performed but before angle estimation or beamforming.\nMore Detailed Explanation:\nContext of $\\mathbf{X}_{\\text{RD}}[k,l]:$ When processing radar data, we first perform the Range FFT along the fast-time dimension and the Doppler FFT along the slow-time dimension. This yields a two-dimensional grid (or map) of complex values for each antenna element. Each point $(k,l)$ in this grid corresponds to a particular range bin $k$ and Doppler bin $l$.\nHowever, the radar typically has multiple receive antennas (or multiple virtual channels after combining Tx/Rx pairs in a MIMO setup). Thus, at each $(k,l)$ coordinate, we don’t have just a single complex number; we have one complex number per antenna element. Collecting these values from all $P$ antenna elements at the same $(k,l)$ forms a vector:\n$$\\mathbf{X}_{\\text{RD}}[k,l] = \\begin{bmatrix} X_{\\text{RD}}[k,l,0] \\\\[6pt] X_{\\text{RD}}[k,l,1] \\\\[6pt] \\vdots \\\\[6pt] X_{\\text{RD}}[k,l,P-1] \\end{bmatrix}$$ Why a Vector? Representing the data across all antennas at a given range-Doppler coordinate as a vector is convenient for applying linear algebra-based operations like beamforming. Beamforming often involves multiplying this vector by a weight vector $\\mathbf{w}(\\theta)$ to form a beam in direction $\\theta$.\nUsing $\\mathbf{X}_{\\text{RD}}[k,l]$ in Beamforming: Once you have $\\mathbf{X}_{\\text{RD}}[k,l]$, the beamformed output $Y_{k,l}(\\theta)$ looking toward angle $\\theta$ can be written as:\n$$Y_{k,l}(\\theta) = \\mathbf{w}(\\theta)^H \\mathbf{X}_{\\text{RD}}[k,l]$$In Summary:\n$\\mathbf{X}_{\\text{RD}}[k,l]$ is the “snapshot” of the received signal across all antenna elements after performing the Range and Doppler FFTs.\nIt is this vector form that allows digital beamforming algorithms to easily apply spatial filtering, steering, and combining operations.\nX: Radar parameters Several key system parameters directly influence the radar’s precision (accuracy) and resolution (ability to distinguish close targets in range, velocity, or angle). Expressing these influences mathematically helps clarify their roles:\nRange Resolution Definition: The range resolution ($\\Delta R$) is the minimum distinguishable separation between two targets along the radar’s line-of-sight.\nMathematical Relationship:\n$$\\Delta R \\approx \\frac{c}{2B}$$where:\n$c$ is the speed of light,\n$B$ is the signal bandwidth.\nInterpretation:\nIncreasing $B$ (the chirp bandwidth) improves range resolution.\nIf $B$ is larger, $\\Delta R$ is smaller, meaning the radar can better resolve two closely spaced targets in range.\nDoppler (Velocity) Resolution Definition: The Doppler resolution ($\\Delta v$) determines how well the radar can distinguish targets moving at slightly different radial velocities.\nMathematical Relationship: First, the Doppler frequency resolution is:\n$$\\Delta f_D = \\frac{1}{N T_c}$$where:\n$N$ is the number of chirps (slow-time samples) used in the Doppler FFT,\n$T_c$ is the chirp repetition interval (or the time between consecutive chirps used for Doppler processing).\nSince Doppler frequency $f_D = \\frac{2v}{\\lambda}$, we have:\n$$\\Delta v = \\frac{\\lambda}{2} \\Delta f_D = \\frac{\\lambda}{2 N T_c}$$Interpretation:\nIncreasing $N$ (the number of integrated chirps) reduces $\\Delta f_D$, thus improving Doppler resolution.\nA longer observation time (larger $N T_c$) allows finer velocity discrimination.\nUsing a smaller wavelength $\\lambda$ (higher frequency radar) also improves velocity resolution, though this usually is a given system parameter.\nAngular Resolution Definition: The angular resolution ($\\Delta \\theta$) describes how well the radar can distinguish two targets at the same range and velocity but separated in angle.\nMathematical Relationship (For a Uniform Linear Array): For a linear array of length LL (or an effective virtual aperture length), the angular resolution is approximately:\n$$\\Delta \\theta \\approx \\frac{\\lambda}{L}$$or, if the array consists of $P$ elements spaced by $d$:\n$$L = (P-1)d, \\quad \\Delta \\theta \\approx \\frac{\\lambda}{(P-1)d}$$Interpretation:\nIncreasing the physical aperture $L$ (more antenna elements $P$ or wider spacing $d$) improves angular resolution.\nA smaller wavelength $\\lambda$ also improves angular resolution (but this typically is fixed by the radar frequency band).\nPrecision Influences Precision in measurement (the accuracy of estimating the exact range, velocity, or angle) is often influenced by:\nSignal-to-Noise Ratio (SNR): Higher SNR generally leads to more precise estimates.\nWindowing and FFT Points: The use of window functions and interpolation in the FFT domain can improve the precision of peak location estimation, thus refining range or Doppler measurements.\nFor Doppler, for example, if we interpolate the FFT or use super-resolution techniques (like MUSIC or ESPRIT), we can achieve velocity estimates more precise than the basic Doppler bin spacing $\\Delta v$.\nIn general, the precision (in terms of standard deviation of the estimation error) for parameters such as range or velocity often follows a Cramér-Rao lower bound (CRLB), which depends on SNR and waveform parameters.\nExample (Range Precision) The theoretical limit on range estimation precision $\\sigma_R$ (standard deviation) can be approximated by:\n$$\\sigma_R \\propto \\frac{c}{\\sqrt{2 \\cdot \\text{SNR}} \\cdot B}$$Here, increasing SNR or increasing bandwidth $B$ reduces the standard deviation of the range estimate, improving precision.\nSummary of Parameter Influences Bandwidth $B$:\nInversely affects range resolution ($\\Delta R \\sim 1/B$).\nImproves range estimation precision as it increases.\nNumber of Chirps $N$ and Chirp Repetition Interval $T_c$:\nDetermine Doppler resolution ($\\Delta v \\sim 1/(N T_c)$).\nMore chirps or longer integration time improves velocity resolution and precision.\nAntenna Array Size (Number of Elements $P$ and Spacing $d$):\nDetermines angular resolution ($\\Delta \\theta \\sim \\lambda/(P d)$).\nMore elements or a larger aperture improves angular resolution.\nWavelength $\\lambda$:\nSmaller $\\lambda$ improves both Doppler and angular resolution for the same array size.\nUsually fixed by the radar operating frequency band.\nSNR and Signal Processing Techniques:\nHigher SNR and advanced signal processing methods lead to better precision in estimating these parameters beyond the basic resolution limits. References [1] Z. Han et al., “4D Millimeter-Wave Radar in Autonomous Driving: A Survey,” Apr. 26, 2024, arXiv: arXiv:2306.04242. Accessed: Nov. 19, 2024. [Online]. Available: http://arxiv.org/abs/2306.04242\n","wordCount":"4800","inLanguage":"en","image":"https://livey.github.io/posts/2024-12-radar-processing/%3Cimage%20path/url%3E","datePublished":"2024-12-26T00:00:00Z","dateModified":"2024-12-26T00:00:00Z","author":{"@type":"Person","name":"Fuwei Li"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://livey.github.io/posts/2024-12-radar-processing/"},"publisher":{"@type":"Organization","name":"Fuwei's Tech Notes","logo":{"@type":"ImageObject","url":"https://livey.github.io/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://livey.github.io/ accesskey=h title="Home (Alt + H)"><img src=https://livey.github.io/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://livey.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://livey.github.io/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://livey.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://livey.github.io/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://livey.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://livey.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Radar Signal Processing: A Tutorial</h1><div class=post-description>A tutorial on radar signal processing and the article is partially generated by ChatGPT-o1</div><div class=post-meta><span title='2024-12-26 00:00:00 +0000 UTC'>December 26, 2024</span>&nbsp;·&nbsp;23 min&nbsp;·&nbsp;4800 words&nbsp;·&nbsp;Fuwei Li&nbsp;|&nbsp;<a href=https://github.com/livey/livey.github.io/issues/new rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#system-diagram aria-label="System Diagram">System Diagram</a></li><li><a href=#single-object-tx-rx-model aria-label="Single Object Tx-Rx Model">Single Object Tx-Rx Model</a><ul><li><a href=#transmitted-fmcw-chirp-signal aria-label="Transmitted FMCW Chirp Signal">Transmitted FMCW Chirp Signal</a></li><li><a href=#target-reflection-and-received-signal aria-label="Target Reflection and Received Signal">Target Reflection and Received Signal</a></li><li><a href=#mixing-and-downconversion aria-label="Mixing and Downconversion">Mixing and Downconversion</a></li><li><a href=#adc-sampling-and-data-cube-formation aria-label="ADC Sampling and Data Cube Formation">ADC Sampling and Data Cube Formation</a></li><li><a href=#range-doppler-processing aria-label="Range-Doppler Processing">Range-Doppler Processing</a></li><li><a href=#angle-estimation-spatial-fft-or-beamforming aria-label="Angle Estimation (Spatial FFT or Beamforming)">Angle Estimation (Spatial FFT or Beamforming)</a></li><li><a href=#cfar-detection aria-label="CFAR Detection">CFAR Detection</a></li><li><a href=#digital-beamforming-dbfx20 aria-label="Digital Beamforming (DBF) ">Digital Beamforming (DBF)</a></li><li><a href=#point-cloud-generation aria-label="Point Cloud Generation">Point Cloud Generation</a></li><li><a href=#in-summary aria-label="In summary">In summary</a></li></ul></li><li><a href=#extend-to-mimo-systemx20 aria-label="Extend to MIMO System ">Extend to MIMO System</a></li><li><a href=#appendix aria-label=Appendix>Appendix</a><ul><li><a href=#i-the-transmitted-signal aria-label="I: The transmitted signal">I: The transmitted signal</a><ul><li><a href=#detailed-explanation aria-label="Detailed Explanation:">Detailed Explanation:</a></li><li><a href=#in-summary-1 aria-label="In summary">In summary</a></li></ul></li><li><a href=#ii-the-received-amplitude aria-label="II: The received amplitude">II: The received amplitude</a></li><li><a href=#iii-intermediate-frequency aria-label="III: Intermediate Frequency">III: Intermediate Frequency</a></li><li><a href=#iv-simplify-the-intermediate-signal aria-label="IV: Simplify the intermediate signal">IV: Simplify the intermediate signal</a></li><li><a href=#v-rang-and-doppler-fft aria-label="V: Rang and doppler FFT">V: Rang and doppler FFT</a><ul><li><a href=#how-range-and-doppler-are-encoded aria-label="How Range and Doppler Are Encoded:">How Range and Doppler Are Encoded:</a></li><li><a href=#in-summary-2 aria-label="In Summary">In Summary</a></li></ul></li><li><a href=#vi-velocity-derivation aria-label="VI: Velocity Derivation">VI: Velocity Derivation</a><ul><li><a href=#derivation-steps aria-label="Derivation Steps">Derivation Steps</a></li><li><a href=#intuition aria-label=Intuition>Intuition</a></li></ul></li><li><a href=#vii-why-5a-6a-and-5b-6b-in-two-different-paths aria-label="VII: Why (5a, 6a) and (5b, 6b) in two different paths">VII: Why (5a, 6a) and (5b, 6b) in two different paths</a><ul><li><a href=#why-two-paths aria-label="Why Two Paths?">Why Two Paths?</a></li><li><a href=#in-summary-3 aria-label="In summary">In summary</a></li></ul></li><li><a href=#viii-digital-beamforming aria-label="VIII: Digital beamforming">VIII: Digital beamforming</a><ul><li><a href=#what-is-mathbfwtheta aria-label="What is $\mathbf{w}(\theta)$?">What is $\mathbf{w}(\theta)$?</a></li><li><a href=#interpreting-the-weight-mathbfwtheta aria-label="Interpreting the Weight $\mathbf{w}(\theta)$">Interpreting the Weight $\mathbf{w}(\theta)$</a></li></ul></li><li><a href=#ix-the-rd-sample aria-label="IX: The RD sample">IX: The RD sample</a></li><li><a href=#x-radar-parameters aria-label="X: Radar parameters">X: Radar parameters</a><ul><li><a href=#range-resolution aria-label="Range Resolution">Range Resolution</a></li><li><a href=#doppler-velocity-resolution aria-label="Doppler (Velocity) Resolution">Doppler (Velocity) Resolution</a></li><li><a href=#angular-resolution aria-label="Angular Resolution">Angular Resolution</a></li><li><a href=#precision-influences aria-label="Precision Influences">Precision Influences</a></li><li><a href=#example-range-precision aria-label="Example (Range Precision)">Example (Range Precision)</a></li><li><a href=#summary-of-parameter-influences aria-label="Summary of Parameter Influences">Summary of Parameter Influences</a></li></ul></li></ul></li><li><a href=#references aria-label=References>References</a></li></ul></div></details></div><div class=post-content><h1 id=system-diagram>System Diagram<a hidden class=anchor aria-hidden=true href=#system-diagram>#</a></h1><p>See Appendix.VII</p><div style="text-align:center;margin:0 auto"><img src=./resources/system-diagram.png alt="System Diagram" style=width:100%><p style=margin-top:10px;font-style:italic>Figure 1: System diagram of a typical 4D mmWave radar signal processing chain (figure from [1])</p></div><h1 id=single-object-tx-rx-model>Single Object Tx-Rx Model<a hidden class=anchor aria-hidden=true href=#single-object-tx-rx-model>#</a></h1><p>Below is a mathematical formalization of each major step in the traditional 4D mmWave Frequency Modulated Continuous Wave (FMCW) radar signal processing chain, from transmitted signals through to point-cloud generation. Please note that these equations represent a general framework; actual implementations may vary slightly depending on specific system parameters and design choices.</p><p><strong>Notation and Definitions:</strong></p><ul><li><p>$f_c$: Carrier frequency of the radar.</p></li><li><p>$B$: Bandwidth swept by each chirp.</p></li><li><p>$T_c$: Chirp duration (time taken to sweep the bandwidth B).</p></li><li><p>$T_f$: Frame duration (consisting of $N_c$ chirps).</p></li><li><p>$N_c$: Number of chirps per frame.</p></li><li><p>$M$: Number of samples per chirp (fast-time samples).</p></li><li><p>$N$: Number of slow-time samples (across chirps), typically equals $N_c$.</p></li><li><p>$P$: Number of virtual antenna elements (after combining Tx-Rx pairs).</p></li><li><p>$\lambda$: Wavelength of the radar signal.</p></li><li><p>$d$: Spacing between adjacent virtual antenna elements.</p></li><li><p>$j=\sqrt{-1}$.</p></li></ul><hr><h2 id=transmitted-fmcw-chirp-signal>Transmitted FMCW Chirp Signal<a hidden class=anchor aria-hidden=true href=#transmitted-fmcw-chirp-signal>#</a></h2><p>A single FMCW chirp can be modeled as a complex exponential with a time-varying instantaneous frequency:</p>$$s_{\text{TX}}(t) = A_{\text{TX}} e^{j2\pi \left( f_c t + \frac{B}{2T_c} t^2 \right)} \quad \text{for } t \in [0, T_c]$$<p>For a frame of $N_c$ chirps, each chirp is repeated with a period $T_f = N_c T_c$ (neglecting idle times for simplicity):</p>$$s_{\text{TX,frame}}(t) = \sum_{n=0}^{N_c-1} s_{\text{TX}}(t - nT_c) u(t - nT_c) $$<p>where $u(t)$ is the unit step function ensuring the waveform is only defined during each chirp interval.</p><hr><h2 id=target-reflection-and-received-signal>Target Reflection and Received Signal<a hidden class=anchor aria-hidden=true href=#target-reflection-and-received-signal>#</a></h2><p>Assume one point target at range $R$ moving with radial velocity $v$. The received signal from that target after reflection is delayed and Doppler shifted:</p>$$s_{\text{RX}}(t) = A_{\text{RX}} e^{j2\pi \left(f_c (t - \tau) + \frac{B}{2T_c} (t - \tau)^2 \right)} e^{j2\pi f_D t}$$<p>where</p><ul><li><p>$\tau = \frac{2R}{c}$ is the round-trip delay (with $c$ the speed of light),</p></li><li><p>$f_D = \frac{2v}{\lambda}$ is the Doppler frequency due to target motion, where $v>0$ indicates the target is approaching the radar (higher received frequency); $v<0$ denotes the target is moving away from the radar (lower received frequency).</p></li></ul><p>In practice, multiple targets sum linearly:</p>$$s_{\text{RX}}(t) = \sum_{\ell} A_{\ell} e^{j2\pi \left( f_c (t - \tau_{\ell}) + \frac{B}{2T_c} (t - \tau_{\ell})^2 \right)} e^{j2\pi f_{D,\ell} t}$$<p>Please refer Appendix.II for the meaning of $A_\ell$.</p><hr><h2 id=mixing-and-downconversion>Mixing and Downconversion<a hidden class=anchor aria-hidden=true href=#mixing-and-downconversion>#</a></h2><p>The received signal (Appendix.III) is mixed with a replica of the transmitted chirp (local oscillator, LO):</p>$$s_{\text{IF}}(t) = s_{\text{RX}}(t)\cdot s_{\text{LO}}^*(t)$$<p>where $s^*_{LO}$ indicates the conjugate of $s_{LO}$.</p><p>Let $s_{\text{LO}}(t) = e^{j2\pi (f_c t + \frac{B}{2T_c}t^2)}$</p><p>Then:</p>$$s_{\text{IF}}(t) = \sum_{\ell} A_{\ell} e^{j2\pi\left( (f_c(t-\tau_\ell)+\frac{B}{2T_c}(t-\tau_\ell)^2 + f_{D,\ell} t) - (f_c t + \frac{B}{2T_c} t^2) \right)}$$<p>After simplification (assuming $\tau_\ell$ and Doppler are small relative to the chirp period see Appendix.IV):</p>$$s_{\text{IF}}(t) \approx \sum_{\ell} A_{\ell} e^{-j2\pi \left( f_{R,\ell} t \right)} e^{j2\pi f_{D,\ell} t}$$<p>Where $f_{R,\ell} = \frac{2 B R_{\ell}}{c T_c}$ is the beat frequency related to target range.</p><p>Thus the IF signal carries range (beat frequency) and Doppler (phase change across chirps) information.</p><hr><h2 id=adc-sampling-and-data-cube-formation>ADC Sampling and Data Cube Formation<a hidden class=anchor aria-hidden=true href=#adc-sampling-and-data-cube-formation>#</a></h2><p>The IF signal is sampled at a rate $f_s=\frac{1}{T_s}$ yielding discrete samples for each chirp. For the $p$-th antenna element, the $m$-th sample in the $n$-th chirp is:</p>$$x[m,n,p] = s_{\text{IF},p}(mT_s + nT_c)$$<p>with $m = 0,\dots,M-1$; $n = 0,\dots,N_c-1$; $p = 0,\dots,P-1$.</p><p>This forms a 3D data cube:</p><ul><li><p>Fast-time (range dimension): $m$</p></li><li><p>Slow-time (Doppler dimension): $n$</p></li><li><p>Antenna (spatial dimension): $p$</p></li></ul><hr><h2 id=range-doppler-processing>Range-Doppler Processing<a hidden class=anchor aria-hidden=true href=#range-doppler-processing>#</a></h2><p>Why they are called range FFT and doppler FFT (Appendix.V)</p><p><strong>Range FFT</strong>:
We apply an M-point FFT along the fast-time dimension to transform from time samples to frequency (range) domain:</p>$$X_{\text{range}}[k,n,p] = \sum_{m=0}^{M-1} x[m,n,p] e^{-j\frac{2\pi k m}{M}}, \quad k=0,\dots,M-1$$<p>Each k-index corresponds to a particular range bin.</p><p><strong>Doppler FFT</strong>:
Then, we apply an N-point FFT along the slow-time (chirp) dimension to extract Doppler information:</p>$$X_{\text{RD}}[k,l,p] = \sum_{n=0}^{N-1} X_{\text{range}}[k,n,p] e^{-j\frac{2\pi l n}{N}}, \quad l=0,\dots,N-1$$<p>Each l-index corresponds to a Doppler bin (velocity).</p><p>This produces a Range-Doppler (RD) map for each antenna $p$.</p><hr><h2 id=angle-estimation-spatial-fft-or-beamforming>Angle Estimation (Spatial FFT or Beamforming)<a hidden class=anchor aria-hidden=true href=#angle-estimation-spatial-fft-or-beamforming>#</a></h2><p>To estimate angle, we use the antenna array. If the p-th antenna element is located at $d_p = p \cdot d$, the received signal for a target at angle $\theta$ has a phase progression:</p>$$X_{\text{RDA}}[k,l,\theta] = \sum_{p=0}^{P-1} X_{\text{RD}}[k,l,p] w_p(\theta) e^{-j \frac{2\pi}{\lambda} d_p \sin(\theta)}$$<p>Here:</p><ul><li><p>$w_p(\theta)$ are optional beamforming weights.</p></li><li><p>By performing an P-point FFT over p instead of a sum over a continuous angle, we discretize angles into angular bins. For a uniform linear array (ULA):</p></li></ul>$$X_{\text{RDA}}[k,l,q] = \sum_{p=0}^{P-1} X_{\text{RD}}[k,l,p] e^{-j\frac{2\pi}{P} p q}$$<p>where q indexes discrete angle bins. Similar extensions are made for elevation using a 2D antenna array, resulting in a 4D cube: (Range, Doppler, Azimuth, Elevation).</p><hr><h2 id=cfar-detection>CFAR Detection<a hidden class=anchor aria-hidden=true href=#cfar-detection>#</a></h2><p>A Constant False Alarm Rate (CFAR) detector sets a threshold based on local noise statistics. For each cell $(k,l,q)$ in the RDA cube, we estimate noise power from a neighboring window and set a threshold:</p>$$T(k,l,q) = \alpha \cdot \hat{\sigma}^2(k,l,q)$$<p>where $\hat{\sigma}^2$ is the estimated noise variance and $\alpha$ a scaling factor based on desired false alarm probability. A detection occurs if:</p>$$|X_{\text{RDA}}[k,l,q]|^2 > T(k,l,q)$$<hr><h2 id=digital-beamforming-dbfx20>Digital Beamforming (DBF) <a hidden class=anchor aria-hidden=true href=#digital-beamforming-dbfx20>#</a></h2><p>(Appendix.VIII)</p><p>If we use a weighting vector $\mathbf{w}$ (e.g., minimum variance distortionless response (MVDR) or other beamformer):</p>$$X_{\text{RDA}}[k,l,\theta] = \mathbf{w}^H(\theta) \mathbf{X}_{\text{RD}}[k,l]$$<p>where $\mathbf{X}_{\text{RD}}[k,l]$ is the vector of RD samples across antennas (Appendix.IX) and $\mathbf{w}(\theta)$ is chosen to form a beam in the direction $\theta$.</p><hr><h2 id=point-cloud-generation>Point Cloud Generation<a hidden class=anchor aria-hidden=true href=#point-cloud-generation>#</a></h2><p>After detection, we convert range $R_k$, angle $\theta_q$ (and $\phi$ if elevation is considered), and Doppler $v_l$ bins into Cartesian coordinates:</p>$$x = R_k \cos(\theta_q) \cos(\phi), \quad y = R_k \sin(\theta_q) \cos(\phi), \quad z = R_k \sin(\phi)$$<p>Velocity can be derived from Doppler frequency ():</p>$$v = \frac{\lambda l}{2N T_c}$$<p>Each detected cell forms a point in the 3D space with an associated velocity, resulting in a point cloud:</p>$$\mathcal{P} = \{(x_i, y_i, z_i, v_i) \mid \text{CFAR detection holds}\}$$<hr><h2 id=in-summary><strong>In summary</strong><a hidden class=anchor aria-hidden=true href=#in-summary>#</a></h2><ol><li><p><strong>Transmission & Reception:</strong> Defined by chirp signals and their reflections.</p></li><li><p><strong>Mixing & Downconversion:</strong> Produces IF signals with range-Doppler information encoded as beat frequencies and slow-time phase shifts.</p></li><li>$$x[m,n,p]$$<p>samples form a 3D tensor.</p></li><li><p><strong>Range & Doppler FFTs:</strong> Convert time-domain samples into range-Doppler spectra: $X_{\text{RD}}[k,l,p]$.</p></li><li><p><strong>Angle Estimation:</strong> Spatial processing (FFT or beamforming) yields $X_{\text{RDA}}[k,l,q]$, a 4D data cube (range, Doppler, azimuth, elevation).</p></li><li><p><strong>CFAR Detection:</strong> Sets thresholds and identifies target cells.</p></li><li><p><strong>Point Cloud Generation:</strong> Converts detected bins into Cartesian coordinates and velocities.</p></li></ol><h1 id=extend-to-mimo-systemx20>Extend to MIMO System <a hidden class=anchor aria-hidden=true href=#extend-to-mimo-systemx20>#</a></h1><p>When extended to MIMO system, the signal transmitted via different antennas are orthogonal. So, problem will be simplified into the trans-receiver pair problem as we have discussed before.</p><h1 id=appendix>Appendix<a hidden class=anchor aria-hidden=true href=#appendix>#</a></h1><h2 id=i-the-transmitted-signal>I: The transmitted signal<a hidden class=anchor aria-hidden=true href=#i-the-transmitted-signal>#</a></h2><p>The factor $\frac{B}{2T_c}$ appears in the <strong>phase term</strong> of the transmitted FMCW signal because of the integral relationship between frequency and phase.</p><h3 id=detailed-explanation><strong>Detailed Explanation:</strong><a hidden class=anchor aria-hidden=true href=#detailed-explanation>#</a></h3><ol><li><strong>Instantaneous Frequency vs. Phase:</strong> A linear frequency-modulated (chirp) signal sweeps from a starting frequency $f_c$ to $f_c + B$ over a duration $T_c$. The instantaneous frequency $f(t)$ of such a chirp is usually defined as:</li></ol>$$f(t) = f_c + \frac{B}{T_c} t \quad \text{for } 0 \leq t \leq T_c$$<ul><li><strong>From Frequency to Phase:</strong> The transmitted signal $$s_{\text{TX}}(t)$$ in complex exponential form can be written as:</li></ul>$$s_{\text{TX}}(t) = A_{\text{TX}} e^{j \phi(t)}$$<p>Since $f(t) = f_c + \frac{B}{T_c} t$, the angular frequency is:</p>$$\omega(t) = 2 \pi \left( f_c + \frac{B}{T_c} t \right)$$<ul><li><strong>Integrating to Get Phase:</strong> The phase $\phi(t)$ is given by:</li></ul>$$\phi(t) = \int_0^t \omega(\tau) d\tau = \int_0^t 2\pi \left( f_c + \frac{B}{T_c}\tau \right) d\tau.$$<p>Performing the integration:</p>$$\phi(t) = 2\pi \left( f_c t + \frac{B}{T_c} \frac{t^2}{2} \right) = 2\pi f_c t + 2\pi \frac{B}{2T_c} t^2$$<ul><li><strong>Resulting Phase Expression:</strong> After integration, the phase term associated with the chirp’s frequency sweep has a quadratic component $\frac{B}{2T_c} t^2$, not $\frac{B}{T_c} t^2$. The factor of $\frac{1}{2}$ emerges naturally from the integral of a linear function.</li></ul><p>Thus the transmitted signal is:</p>$$s_{\text{TX}}(t) = A_{\text{TX}} e^{j2\pi \left( f_c t + \frac{B}{2T_c} t^2 \right)}$$<h3 id=in-summary-1><strong>In summary</strong><a hidden class=anchor aria-hidden=true href=#in-summary-1>#</a></h3><ul><li><p>The slope of the frequency is $\frac{B}{T_c}$.</p></li><li><p>The phase is the integral of frequency over time.</p></li><li><p>Integrating a linearly increasing frequency (which goes as $f(t) = f_c + (B/T_c) t$) introduces a factor of $1/2$ in front of the $t^2$ term.</p></li></ul><p>This is why the phase term has $\frac{B}{2T_c}$ rather than $\frac{B}{T_c}$.</p><h2 id=ii-the-received-amplitude>II: The received amplitude<a hidden class=anchor aria-hidden=true href=#ii-the-received-amplitude>#</a></h2><p>In the context of the received radar signal model, $A_\ell$ represents the complex amplitude corresponding to the $\ell$-th target’s reflected signal. Specifically, it encapsulates all the gain, attenuation, and reflectivity factors associated with that particular target, including:</p><ol><li><p><strong>Target Reflectivity (Radar Cross Section, RCS):</strong>
Different targets reflect radar waves differently depending on their shape, orientation, and material properties. A larger or more reflective target will contribute a higher amplitude return.</p></li><li><p><strong>Propagation Losses:</strong>
The signal undergoes attenuation while traveling to the target and back. The amplitude decreases with range and is also influenced by atmospheric conditions.</p></li><li><p><strong>Antenna Gain Patterns:</strong>
The gain of the transmitting and receiving antennas in the direction of the target affects the amplitude of the received signal. Targets that lie in the main lobe of the antenna pattern will produce larger amplitude returns than those in sidelobes.</p></li><li><p><strong>Channel and System Factors:</strong>
The receiver’s front-end gain, noise figure, and other hardware elements also factor into the effective amplitude captured in $A_\ell$.</p></li></ol><p>In essence, $A_\ell$ combines all these effects into a single complex scalar that, when multiplied by the phase term of the $\ell$-th target’s return, gives the overall contribution of that target’s echo to the received signal.</p><h2 id=iii-intermediate-frequency>III: Intermediate Frequency<a hidden class=anchor aria-hidden=true href=#iii-intermediate-frequency>#</a></h2><p>&ldquo;IF&rdquo; stands for <strong>Intermediate Frequency;</strong> in radar and other RF systems, the signal received at the antenna is typically at the original (or a very high) carrier frequency. Before it is sampled or digitized, it is mixed with a locally generated reference signal to shift it down to a lower, more manageable frequency range called the intermediate frequency. This process simplifies subsequent signal processing steps such as filtering, amplification, and analog-to-digital conversion.</p><p>So, $s_{IF}(t)$ refers to the received radar signal after it has been mixed (downconverted) from the original RF (radio frequency) carrier down to an intermediate frequency.</p><h2 id=iv-simplify-the-intermediate-signal>IV: Simplify the intermediate signal<a hidden class=anchor aria-hidden=true href=#iv-simplify-the-intermediate-signal>#</a></h2><p>When deriving the IF signal and inserting the time delay $\tau_\ell$ and Doppler term $f_{D,\ell}$, the expression initially appears complicated because of the quadratic term in $2(t-\tau_\ell)^2$. The phrase &ldquo;assuming $\tau_\ell$ and Doppler are small relative to the chirp period&rdquo; refers to making reasonable approximations that drop very small second-order terms, leaving only the dominant, physically meaningful components.</p><p><strong>Step-by-Step Detail:</strong></p><ol><li><strong>Starting Point:</strong> After mixing the received signal with the local oscillator (LO), we had something like:</li></ol>$$s_{\text{IF}}(t) = \sum_{\ell} A_{\ell} \exp\left\{ j2\pi \left[ f_c (t-\tau_\ell) + \tfrac{B}{2T_c}(t-\tau_\ell)^2 + f_{D,\ell} t - \left(f_c t + \tfrac{B}{2T_c} t^2\right) \right] \right\}$$<ul><li><strong>Expand the Quadratic Term:</strong> Expand $(t - \tau_\ell)^2 = t^2 - 2t\tau_\ell + \tau_\ell^2$. Substituting this in gives:</li></ul>$$f_c(t-\tau_\ell) + \tfrac{B}{2T_c}(t-\tau_\ell)^2 = f_c t - f_c \tau_\ell + \tfrac{B}{2T_c}(t^2 - 2t\tau_\ell + \tau_\ell^2)$$<ul><li><strong>Combine Terms:</strong> Now, the exponent inside the summation becomes:</li></ul>$$f_c t - f_c \tau_\ell + \frac{B}{2T_c}(t^2 - 2t\tau_\ell + \tau_\ell^2) + f_{D,\ell} t - f_c t - \frac{B}{2T_c} t^2$$<p>Notice that $f_c t$ and $-f_c t$ cancel. Also, $\frac{B}{2T_c} t^2$ and $-\frac{B}{2T_c} t^2$ cancel. After these cancellations, we have:</p>$$- f_c \tau_\ell + \frac{B}{2T_c}(- 2t\tau_\ell + \tau_\ell^2) + f_{D,\ell} t$$<p>his simplifies to:</p>$$- f_c \tau_\ell - \frac{B}{T_c} t \tau_\ell + \frac{B}{2T_c}\tau_\ell^2 + f_{D,\ell} t$$<ul><li><p><strong>Applying the &ldquo;Small&rdquo; Assumptions:</strong> The main assumptions are:</p><ul><li><p>$\tau_\ell = \frac{2R_\ell}{c}$ is small compared to the chirp duration $T_c$. This means $\tau_\ell^2$ (a second-order small term) is even smaller and can be neglected.</p></li><li><p>The Doppler frequency $f_{D,\ell}$ is typically much smaller than the chirp’s instantaneous bandwidth spread $\frac{B}{T_c}$, so its influence within a single chirp period is limited to a nearly linear phase term $f_{D,\ell} t$.</p></li></ul></li></ul><p>By neglecting $\tau_\ell^2$, we discard:</p>$$\frac{B}{2T_c}\tau_\ell^2 \approx 0$$<p>Thus, we have:</p>$$s_{\text{IF}}(t) \approx \sum_{\ell} A_{\ell} e^{j2\pi \left(- f_c \tau_\ell - \frac{B}{T_c} t \tau_\ell + f_{D,\ell} t \right)}$$<p>This can be rearranged as:</p>$$s_{\text{IF}}(t) \approx \sum_{\ell} A_{\ell} e^{-j2\pi f_c \tau_\ell} e^{-j2\pi \left( \frac{B}{T_c} \tau_\ell \right) t} e^{j2\pi f_{D,\ell} t}$$<ul><li><strong>Defining the Range Frequency </strong>$f_{R,\ell}$:</li></ul><p>Recall that $\tau_\ell = \frac{2 R_\ell}{c}$. By defining:</p>$$f_{R,\ell} = \frac{B}{T_c}\tau_\ell = \frac{B}{T_c}\cdot \frac{2R_\ell}{c}$$<p>we identify the term $\frac{B}{T_c}\tau_\ell$ as the &ldquo;beat frequency&rdquo; associated with the target’s range. Now the equation becomes:</p>$$s_{\text{IF}}(t) \approx \sum_{\ell} A_{\ell} e^{-j2\pi f_c \tau_\ell} e^{-j2\pi f_{R,\ell} t} e^{j2\pi f_{D,\ell} t}$$<ul><li><strong>Absorbing Constant Phase into Amplitude:</strong></li></ul><p>The factor $e^{-j2\pi f_c \tau_\ell}$ is a constant phase term (does not depend on t). Such a constant phase can be absorbed into the amplitude $A_{\ell}$ since amplitudes in complex notation can carry both magnitude and phase information. Define:</p>$$A_{\ell}' = A_{\ell} e^{-j2\pi f_c \tau_\ell}$$<p>With this redefinition, we have:</p>$$s_{\text{IF}}(t) \approx \sum_{\ell} A_{\ell}' e^{-j2\pi f_{R,\ell} t} e^{j2\pi f_{D,\ell} t}$$<ul><li><strong>Final Form:</strong></li></ul><p>Combining the exponential terms for range and Doppler, we arrive at:</p>$$s_{\text{IF}}(t) \approx \sum_{\ell} A_{\ell}' e^{-j2\pi f_{R,\ell} t} e^{j2\pi f_{D,\ell} t}$$<h2 id=v-rang-and-doppler-fft>V: Rang and doppler FFT<a hidden class=anchor aria-hidden=true href=#v-rang-and-doppler-fft>#</a></h2><p><strong>Why &ldquo;Range FFT&rdquo;?</strong>
The first FFT, commonly referred to as the <strong>Range FFT</strong>, is performed along the fast-time axis (the time samples within a single chirp). In an FMCW radar system, each chirp sweeps linearly in frequency over a bandwidth B. When this transmitted chirp is reflected by a target at some range R, the received echo is time-delayed by $\tau = \frac{2R}{c}$. Mixing the received signal with the transmitted chirp produces a beat frequency $f_{b}$ proportional to that delay, and hence proportional to the target’s range. Specifically, the relationship is:</p>$$f_{b} \approx \frac{2B}{cT_c} R$$<p>where $c$ is the speed of light and $T_c$ is the chirp duration.</p><p>When you take a Fourier Transform (FFT) of the time-domain samples of the IF (intermediate frequency) signal within one chirp, you convert these samples from time domain into frequency domain. Each frequency bin corresponds to a potential beat frequency $f_{b}$, and thus directly maps to a range bin. Hence, the first FFT is called the <strong>Range FFT</strong> because performing it reveals the target’s range information.</p><p><strong>Why &ldquo;Doppler FFT&rdquo;?</strong>
The second FFT, known as the <strong>Doppler FFT</strong>, is applied along the slow-time axis. Slow-time refers to the sequence of successive chirps within a radar frame. If a target is moving, the small changes in the echo’s phase or frequency from one chirp to the next encode the Doppler shift $f_{D}$. The Doppler shift is related to the target’s radial velocity $v$ as:</p>$$f_{D} = \frac{2v}{\lambda}$$<p>where $\lambda$ is the radar wavelength.</p><p>By taking an FFT across multiple chirps (the slow-time dimension), you transform from the time domain (sequence of returns over chirps) into the Doppler frequency domain. Each bin in this Doppler spectrum corresponds to a different velocity. Thus, the second FFT is called the <strong>Doppler FFT</strong>, as performing it reveals the velocity (Doppler) information of the targets.</p><h3 id=how-range-and-doppler-are-encoded><strong>How Range and Doppler Are Encoded:</strong><a hidden class=anchor aria-hidden=true href=#how-range-and-doppler-are-encoded>#</a></h3><ol><li><p><strong>Range Encoding (Fast-Time Dimension):</strong>
Within a single chirp, the time delay to a target introduces a beat frequency after mixing. This beat frequency is directly tied to the target’s range. Thus, the &ldquo;fast-time&rdquo; samples encode range information. Taking the FFT along this axis converts time samples into frequency bins that represent different ranges.</p></li><li><p><strong>Doppler Encoding (Slow-Time Dimension):</strong>
Across multiple chirps, a moving target causes a slight phase shift in each subsequent echo. Over many chirps, these phase changes manifest as a sinusoidal variation in the slow-time domain. Taking an FFT across the slow-time samples converts these variations into a Doppler frequency. This Doppler frequency bin corresponds to the target’s radial velocity. Thus, the &ldquo;slow-time&rdquo; samples encode Doppler (velocity) information.</p></li></ol><h3 id=in-summary-2><strong>In Summary</strong><a hidden class=anchor aria-hidden=true href=#in-summary-2>#</a></h3><ul><li><p>The first FFT (&ldquo;Range FFT&rdquo;) extracts range by turning per-chirp time-domain samples into a frequency spectrum where each frequency bin corresponds to a certain range.</p></li><li><p>The second FFT (&ldquo;Doppler FFT&rdquo;) extracts velocity by turning the sequence of echoes over multiple chirps into a frequency spectrum where each frequency bin corresponds to a certain radial velocity.</p></li></ul><h2 id=vi-velocity-derivation>VI: Velocity Derivation<a hidden class=anchor aria-hidden=true href=#vi-velocity-derivation>#</a></h2><p>$v = \frac{\lambda l}{2N T_c}$
relates the target’s radial velocity $v$ to the Doppler bin index $l$, where $\lambda$ is the radar wavelength, $N$ is the number of chirps per frame used in the Doppler FFT, and $T_c$ is the chirp duration (or the pulse repetition interval when considering one chirp per interval).</p><h3 id=derivation-steps><strong>Derivation Steps</strong><a hidden class=anchor aria-hidden=true href=#derivation-steps>#</a></h3><ol><li><strong>Definition of Doppler Frequency:</strong>
A moving target induces a Doppler frequency shift $f_D$ in the radar signal. For a target moving directly along the radar’s line-of-sight, the Doppler frequency is given by:</li></ol>$$f_D = \frac{2v}{\lambda}$$<p>Here, $v$ is the target’s radial velocity and $\lambda$ is the radar wavelength. The factor of 2 comes from the round-trip nature of the radar measurement (signal going to the target and reflecting back).</p><ul><li><strong>Doppler FFT and Frequency Bins:</strong>
The Doppler FFT is typically computed over $N$ chirps in a frame. The time between consecutive chirps is $T_c$. Thus, the total frame duration for Doppler processing is approximately:</li></ul>$$T_{\text{frame}} = N T_c$$<p>When you take an N-point FFT over these N slow-time samples, the Doppler frequency resolution (the spacing between adjacent Doppler frequency bins) is:</p>$$\Delta f_D = \frac{1}{N T_c}$$<p>This means that each Doppler bin index $l$ (ranging from $l = 0, 1, \ldots, N-1$) corresponds to a Doppler frequency:</p>$$f_{D,l} = l \Delta f_D = \frac{l}{N T_c}$$<ul><li><strong>Relating Doppler Frequency to Velocity</strong></li></ul><p>Since $f_D = \frac{2v}{\lambda}$, we have:</p>$$\frac{2v}{\lambda} = f_{D,l} = \frac{l}{N T_c}$$<p>Solving for $v$:</p>$$v = \frac{\lambda}{2} \cdot \frac{l}{N T_c}$$<ul><li><strong>Final Relationship:</strong> Thus, we get:</li></ul>$$v = \frac{\lambda l}{2N T_c}$$<h3 id=intuition><strong>Intuition</strong><a hidden class=anchor aria-hidden=true href=#intuition>#</a></h3><ul><li><p>Each Doppler bin $l$ corresponds to a certain Doppler frequency shift $f_{D,l}$.</p></li><li><p>The Doppler frequency resolution $\Delta f_D$ depends on the total slow-time observation window $N T_c$. Longer observation time (more chirps) yields finer Doppler resolution.</p></li><li><p>Mapping the Doppler frequency back to velocity uses the fundamental radar Doppler equation $f_D = 2v/\lambda$.</p></li></ul><p>In summary, the formula is derived by first determining the Doppler frequency per FFT bin, then using the Doppler-velocity relationship to convert frequency into a corresponding radial velocity.</p><h2 id=vii-why-5a-6a-and-5b-6b-in-two-different-paths>VII: Why (5a, 6a) and (5b, 6b) in two different paths<a hidden class=anchor aria-hidden=true href=#vii-why-5a-6a-and-5b-6b-in-two-different-paths>#</a></h2><p>In many radar processing architectures, there are two general approaches to extracting angle information and detecting targets. The diagram you are referring to likely shows two parallel paths labeled as (5a, 6a) and (5b, 6b) to represent these different possible processing sequences:</p><ol><li><p><strong>Path (5a, 6a)</strong>: <strong>Angle Estimation Before Detection</strong></p><ul><li><p><strong>(5a) Angle/Spatial FFT:</strong> After the Range-Doppler (RD) processing, the data still contains all range-Doppler bins, including noise, clutter, and potential targets. Applying an angle estimation step (such as a spatial FFT across antennas) at this stage produces a full Range-Doppler-Angle (RDA) cube.</p></li><li><p><strong>(6a) CFAR Detection in 3D/4D Space:</strong> Once you have the RDA cube, you run CFAR detection in this higher-dimensional space. The targets are detected directly in the RDA domain. This approach ensures that angle estimation is done on all data before detection, potentially increasing computational load since you’re performing angle estimation for every bin, even if most are noise.</p></li></ul></li><li><p><strong>Path (5b, 6b)</strong>: <strong>Detection Before Angle Estimation</strong></p><ul><li><p><strong>(5b) CFAR Detection in Range-Doppler Domain:</strong> In this path, you first detect the presence of potential targets in the Range-Doppler map using CFAR before doing any angle estimation. The CFAR process identifies a small number of “candidate” bins as potential targets.</p></li><li><p><strong>(6b) Angle Estimation Only for Detected Points:</strong> Instead of computing angle for every bin, you only apply angle estimation techniques (spatial FFT, beamforming, or other angle finding methods) to those bins that have passed the detection threshold. This greatly reduces the computational burden since angle estimation is done only for a handful of detected target bins rather than for the entire RD map.</p></li></ul></li></ol><h3 id=why-two-paths>Why Two Paths?<a hidden class=anchor aria-hidden=true href=#why-two-paths>#</a></h3><p>These two paths represent different trade-offs and system design choices:</p><ul><li><p><strong>Path (5a, 6a) - Angle First, Then Detect:</strong></p><ul><li><p>Pros: You have complete angle information at the time of detection, potentially yielding more accurate detections since you know the angular distribution of returns.</p></li><li><p>Cons: More computationally expensive because angle processing is done on all cells, the majority of which may be noise.</p></li></ul></li><li><p><strong>Path (5b, 6b) - Detect First, Then Angle:</strong></p><ul><li><p>Pros: More computationally efficient since you narrow down candidate target cells first and only then do the more complex angle estimation.</p></li><li><p>Cons: You must be careful that your detection in just the Range-Doppler domain is robust enough that you don’t miss weak targets that could have been more easily identified after angle processing.</p></li></ul></li></ul><h3 id=in-summary-3>In summary<a hidden class=anchor aria-hidden=true href=#in-summary-3>#</a></h3><p>The diagram shows these two paths separately to illustrate different possible workflows in radar signal processing. They are not necessarily both used simultaneously; rather, they represent two common methodologies: either you perform angle estimation before detection (Path 5a, 6a) or you perform detection first and then angle estimation only for detected targets (Path 5b, 6b).</p><h2 id=viii-digital-beamforming>VIII: Digital beamforming<a hidden class=anchor aria-hidden=true href=#viii-digital-beamforming>#</a></h2><p><strong>Digital Beamforming (DBF)</strong> is the process by which signals received from multiple antennas are combined with carefully chosen complex weights to form a beam that is “steered” toward a desired angle (or set of angles). It’s a key technique in radar and wireless communications that leverages antenna arrays and advanced signal processing to improve directional selectivity, enhance signal-to-noise ratio (SNR) for targets of interest, and suppress interference.</p><h3 id=what-is-mathbfwtheta>What is $\mathbf{w}(\theta)$?<a hidden class=anchor aria-hidden=true href=#what-is-mathbfwtheta>#</a></h3><p>$\mathbf{w}(\theta)$ is a vector of complex weights applied to the signals from each element of the antenna array to focus the radar’s sensitivity in a particular direction specified by the angle $\theta$. Consider an array of $P$ antenna elements. At a given time or frequency bin, you have a vector of received signals:</p>$$\mathbf{x} = \begin{bmatrix} x_0 \\ x_1 \\ \vdots \\ x_{P-1} \end{bmatrix}$$<p>where $x_p$ is the signal from the p-th antenna element.</p><p>A beamformer output $y(\theta)$ that &ldquo;looks&rdquo; or &ldquo;points&rdquo; in direction $\theta$ is formed by taking a weighted sum of these antenna signals:</p>$$y(\theta) = \mathbf{w}(\theta)^H \mathbf{x} = \sum_{p=0}^{P-1} w_p(\theta) x_p$$<h3 id=interpreting-the-weight-mathbfwtheta>Interpreting the Weight $\mathbf{w}(\theta)$<a hidden class=anchor aria-hidden=true href=#interpreting-the-weight-mathbfwtheta>#</a></h3><ol><li><strong>Array Geometry and Phase Shifts:</strong>
If you know the geometry of your antenna array (e.g., a Uniform Linear Array), the signal arriving from angle $\theta$ at each element will have a different phase due to the path length difference. By choosing:</li></ol>$$w_p(\theta) = e^{-j2\pi \frac{d_p}{\lambda} \sin(\theta)}$$<ul><li><p>where $d_p$ is the position of the $p$-th antenna element, you can align (or “steer”) the phases so that a signal arriving from $\theta$ adds constructively across all elements. This is the simplest form of beamformer weight selection (often called a delay-and-sum or conventional beamformer).</p></li><li><p><strong>Weight Optimization Criteria:</strong>
More sophisticated beamforming techniques optimize $\mathbf{w}(\theta)$ based on criteria such as:</p><ul><li><p><strong>Maximal Signal-to-Noise Ratio (SNR):</strong>
Choose weights that maximize the SNR for signals from direction $\theta$.</p></li><li><p><strong>Minimize Interference:</strong>
Choose weights to null out signals from known interference angles.</p></li><li><p><strong>Minimum Variance Distortionless Response (MVDR) or Capon Beamformer:</strong>
Solve an optimization problem that minimizes output power subject to maintaining a distortionless response in the desired direction. This leads to: $\mathbf{w}_{\text{MVDR}}(\theta) = \frac{\mathbf{R}^{-1}\mathbf{a}(\theta)}{\mathbf{a}(\theta)^H \mathbf{R}^{-1} \mathbf{a}(\theta)}$, where $\mathbf{R}$ is the noise-plus-interference covariance matrix and $\mathbf{a}(\theta)$ is the array steering vector (the expected signal response of the array from angle $\theta$).</p></li></ul></li><li><p><strong>Array Steering Vector $\mathbf{a}(\theta)$</strong>
The vector $\mathbf{a}(\theta)$ describes how a plane wave from direction $\theta$ is received at the array elements:</p></li></ul>$$\mathbf{a}(\theta) = \begin{bmatrix} e^{-j2\pi \frac{d_0}{\lambda}\sin(\theta)} \\[6pt] e^{-j2\pi \frac{d_1}{\lambda}\sin(\theta)} \\[6pt] \vdots \\[6pt] e^{-j2\pi \frac{d_{P-1}}{\lambda}\sin(\theta)} \end{bmatrix}$$<ul><li><strong>Result of Applying&</strong>$\mathbf{w}(\theta)$:
By applying the chosen beamformer weights, the antenna array focuses its sensitivity. Signals from the desired angle $\theta$ add coherently, boosting their amplitude, while signals from other angles add less coherently or are actively suppressed. This directional sensitivity is what improves angular resolution and target detection capability in radar systems.</li></ul><p><strong>In Short:</strong></p><ul><li><p>$\mathbf{w}(\theta)$ is a vector of complex filter coefficients applied to the array elements.</p></li><li><p>It’s determined by the desired beam direction and any optimization criteria for improved SNR, reduced interference, or super-resolution angle estimation.</p></li><li><p>The choice of $\mathbf{w}(\theta)$ transforms a simple multi-antenna receive pattern into a powerful tool for focusing on specific directions in space, hence the name “digital beamforming.”</p></li></ul><h2 id=ix-the-rd-sample>IX: The RD sample<a hidden class=anchor aria-hidden=true href=#ix-the-rd-sample>#</a></h2><p>$\mathbf{X}_{\text{RD}}[k,l]$ represents the vector of complex signal samples from the antenna array at a specific range bin $k$ and Doppler bin $l$, after the Range and Doppler FFTs have been performed but before angle estimation or beamforming.</p><p><strong>More Detailed Explanation:</strong></p><ol><li><p>Context of $\mathbf{X}_{\text{RD}}[k,l]:$
When processing radar data, we first perform the Range FFT along the fast-time dimension and the Doppler FFT along the slow-time dimension. This yields a two-dimensional grid (or map) of complex values for each antenna element. Each point $(k,l)$ in this grid corresponds to a particular range bin $k$ and Doppler bin $l$.</p></li><li><p>However, the radar typically has multiple receive antennas (or multiple virtual channels after combining Tx/Rx pairs in a MIMO setup). Thus, at each $(k,l)$ coordinate, we don’t have just a single complex number; we have one complex number per antenna element. Collecting these values from all $P$ antenna elements at the same $(k,l)$ forms a vector:</p></li></ol>$$\mathbf{X}_{\text{RD}}[k,l] = \begin{bmatrix} X_{\text{RD}}[k,l,0] \\[6pt] X_{\text{RD}}[k,l,1] \\[6pt] \vdots \\[6pt] X_{\text{RD}}[k,l,P-1] \end{bmatrix}$$<ul><li><p>Why a Vector?
Representing the data across all antennas at a given range-Doppler coordinate as a vector is convenient for applying linear algebra-based operations like beamforming. Beamforming often involves multiplying this vector by a weight vector $\mathbf{w}(\theta)$ to form a beam in direction $\theta$.</p></li><li><p>Using $\mathbf{X}_{\text{RD}}[k,l]$ in Beamforming: Once you have $\mathbf{X}_{\text{RD}}[k,l]$, the beamformed output $Y_{k,l}(\theta)$ looking toward angle $\theta$ can be written as:</p></li></ul>$$Y_{k,l}(\theta) = \mathbf{w}(\theta)^H \mathbf{X}_{\text{RD}}[k,l]$$<p>In Summary:</p><ul><li><p>$\mathbf{X}_{\text{RD}}[k,l]$ is the “snapshot” of the received signal across all antenna elements after performing the Range and Doppler FFTs.</p></li><li><p>It is this vector form that allows digital beamforming algorithms to easily apply spatial filtering, steering, and combining operations.</p></li></ul><h2 id=x-radar-parameters>X: Radar parameters<a hidden class=anchor aria-hidden=true href=#x-radar-parameters>#</a></h2><p>Several key system parameters directly influence the radar’s precision (accuracy) and resolution (ability to distinguish close targets in range, velocity, or angle). Expressing these influences mathematically helps clarify their roles:</p><h3 id=range-resolution>Range Resolution<a hidden class=anchor aria-hidden=true href=#range-resolution>#</a></h3><p>Definition: The range resolution ($\Delta R$) is the minimum distinguishable separation between two targets along the radar’s line-of-sight.</p><p>Mathematical Relationship:</p>$$\Delta R \approx \frac{c}{2B}$$<p>where:</p><ul><li><p>$c$ is the speed of light,</p></li><li><p>$B$ is the signal bandwidth.</p></li></ul><p>Interpretation:</p><ul><li><p>Increasing $B$ (the chirp bandwidth) improves range resolution.</p></li><li><p>If $B$ is larger, $\Delta R$ is smaller, meaning the radar can better resolve two closely spaced targets in range.</p></li></ul><h3 id=doppler-velocity-resolution>Doppler (Velocity) Resolution<a hidden class=anchor aria-hidden=true href=#doppler-velocity-resolution>#</a></h3><p>Definition: The Doppler resolution ($\Delta v$) determines how well the radar can distinguish targets moving at slightly different radial velocities.</p><p>Mathematical Relationship:
First, the Doppler frequency resolution is:</p>$$\Delta f_D = \frac{1}{N T_c}$$<p>where:</p><ul><li><p>$N$ is the number of chirps (slow-time samples) used in the Doppler FFT,</p></li><li><p>$T_c$ is the chirp repetition interval (or the time between consecutive chirps used for Doppler processing).</p></li></ul><p>Since Doppler frequency $f_D = \frac{2v}{\lambda}$, we have:</p>$$\Delta v = \frac{\lambda}{2} \Delta f_D = \frac{\lambda}{2 N T_c}$$<p><strong>Interpretation:</strong></p><ul><li><p>Increasing $N$ (the number of integrated chirps) reduces $\Delta f_D$, thus improving Doppler resolution.</p></li><li><p>A longer observation time (larger $N T_c$) allows finer velocity discrimination.</p></li><li><p>Using a smaller wavelength $\lambda$ (higher frequency radar) also improves velocity resolution, though this usually is a given system parameter.</p></li></ul><h3 id=angular-resolution>Angular Resolution<a hidden class=anchor aria-hidden=true href=#angular-resolution>#</a></h3><p>Definition: The angular resolution ($\Delta \theta$) describes how well the radar can distinguish two targets at the same range and velocity but separated in angle.</p><p>Mathematical Relationship (For a Uniform Linear Array):
For a linear array of length LL (or an effective virtual aperture length), the angular resolution is approximately:</p>$$\Delta \theta \approx \frac{\lambda}{L}$$<p>or, if the array consists of $P$ elements spaced by $d$:</p>$$L = (P-1)d, \quad \Delta \theta \approx \frac{\lambda}{(P-1)d}$$<p>Interpretation:</p><ul><li><p>Increasing the physical aperture $L$ (more antenna elements $P$ or wider spacing $d$) improves angular resolution.</p></li><li><p>A smaller wavelength $\lambda$ also improves angular resolution (but this typically is fixed by the radar frequency band).</p></li></ul><h3 id=precision-influences>Precision Influences<a hidden class=anchor aria-hidden=true href=#precision-influences>#</a></h3><p>Precision in measurement (the accuracy of estimating the exact range, velocity, or angle) is often influenced by:</p><ul><li><p><strong>Signal-to-Noise Ratio (SNR)</strong>: Higher SNR generally leads to more precise estimates.</p></li><li><p><strong>Windowing and FFT Points</strong>: The use of window functions and interpolation in the FFT domain can improve the precision of peak location estimation, thus refining range or Doppler measurements.</p></li></ul><p>For Doppler, for example, if we interpolate the FFT or use super-resolution techniques (like MUSIC or ESPRIT), we can achieve velocity estimates more precise than the basic Doppler bin spacing $\Delta v$.</p><p>In general, the precision (in terms of standard deviation of the estimation error) for parameters such as range or velocity often follows a Cramér-Rao lower bound (CRLB), which depends on SNR and waveform parameters.</p><h3 id=example-range-precision>Example (Range Precision)<a hidden class=anchor aria-hidden=true href=#example-range-precision>#</a></h3><p>The theoretical limit on range estimation precision $\sigma_R$ (standard deviation) can be approximated by:</p>$$\sigma_R \propto \frac{c}{\sqrt{2 \cdot \text{SNR}} \cdot B}$$<p>Here, increasing SNR or increasing bandwidth $B$ reduces the standard deviation of the range estimate, improving precision.</p><h3 id=summary-of-parameter-influences>Summary of Parameter Influences<a hidden class=anchor aria-hidden=true href=#summary-of-parameter-influences>#</a></h3><ul><li><p><strong>Bandwidth $B$</strong>:</p><ul><li><p>Inversely affects range resolution ($\Delta R \sim 1/B$).</p></li><li><p>Improves range estimation precision as it increases.</p></li></ul></li><li><p><strong>Number of Chirps $N$ and Chirp Repetition Interval $T_c$</strong>:</p><ul><li><p>Determine Doppler resolution ($\Delta v \sim 1/(N T_c)$).</p></li><li><p>More chirps or longer integration time improves velocity resolution and precision.</p></li></ul></li><li><p><strong>Antenna Array Size (Number of Elements $P$ and Spacing $d$)</strong>:</p><ul><li><p>Determines angular resolution ($\Delta \theta \sim \lambda/(P d)$).</p></li><li><p>More elements or a larger aperture improves angular resolution.</p></li></ul></li><li><p><strong>Wavelength $\lambda$</strong>:</p><ul><li><p>Smaller $\lambda$ improves both Doppler and angular resolution for the same array size.</p></li><li><p>Usually fixed by the radar operating frequency band.</p></li></ul></li><li><p><strong>SNR and Signal Processing Techniques</strong>:</p><ul><li>Higher SNR and advanced signal processing methods lead to better precision in estimating these parameters beyond the basic resolution limits.</li></ul></li></ul><h1 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h1><p>[1] Z. Han <em>et al.</em>, “4D Millimeter-Wave Radar in Autonomous Driving: A Survey,” Apr. 26, 2024, <em>arXiv</em>: arXiv:2306.04242. Accessed: Nov. 19, 2024. [Online]. Available: <a href=http://arxiv.org/abs/2306.04242>http://arxiv.org/abs/2306.04242</a></p></div><footer class=post-footer><ul class=post-tags><li><a href=https://livey.github.io/tags/radar/>Radar</a></li><li><a href=https://livey.github.io/tags/signal-processing/>Signal Processing</a></li><li><a href=https://livey.github.io/tags/tutorial/>Tutorial</a></li></ul><nav class=paginav><a class=prev href=https://livey.github.io/posts/2024-12-icp/><span class=title>« Prev</span><br><span>Iterative Closest Point Uncovered: Mathematical Foundations and Applications</span>
</a><a class=next href=https://livey.github.io/posts/2024-12-pose-tracking/><span class=title>Next »</span><br><span>Pose Tracking with Iterative Extended Kalman Filter</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Radar Signal Processing: A Tutorial on x" href="https://x.com/intent/tweet/?text=Radar%20Signal%20Processing%3a%20A%20Tutorial&amp;url=https%3a%2f%2flivey.github.io%2fposts%2f2024-12-radar-processing%2f&amp;hashtags=Radar%2cSignalProcessing%2cTutorial"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Radar Signal Processing: A Tutorial on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2flivey.github.io%2fposts%2f2024-12-radar-processing%2f&amp;title=Radar%20Signal%20Processing%3a%20A%20Tutorial&amp;summary=Radar%20Signal%20Processing%3a%20A%20Tutorial&amp;source=https%3a%2f%2flivey.github.io%2fposts%2f2024-12-radar-processing%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Radar Signal Processing: A Tutorial on reddit" href="https://reddit.com/submit?url=https%3a%2f%2flivey.github.io%2fposts%2f2024-12-radar-processing%2f&title=Radar%20Signal%20Processing%3a%20A%20Tutorial"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Radar Signal Processing: A Tutorial on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2flivey.github.io%2fposts%2f2024-12-radar-processing%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Radar Signal Processing: A Tutorial on whatsapp" href="https://api.whatsapp.com/send?text=Radar%20Signal%20Processing%3a%20A%20Tutorial%20-%20https%3a%2f%2flivey.github.io%2fposts%2f2024-12-radar-processing%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Radar Signal Processing: A Tutorial on telegram" href="https://telegram.me/share/url?text=Radar%20Signal%20Processing%3a%20A%20Tutorial&amp;url=https%3a%2f%2flivey.github.io%2fposts%2f2024-12-radar-processing%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Radar Signal Processing: A Tutorial on ycombinator" href="https://news.ycombinator.com/submitlink?t=Radar%20Signal%20Processing%3a%20A%20Tutorial&u=https%3a%2f%2flivey.github.io%2fposts%2f2024-12-radar-processing%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://livey.github.io/>Fuwei's Tech Notes</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>
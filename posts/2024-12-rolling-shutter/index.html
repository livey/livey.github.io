<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Rolling Shutter Camera Projection | Fuwei's Tech Notes</title>
<meta name=keywords content="autonomous driving,signal processing,rolling shutter camera"><meta name=description content="How to project LiDAR points onto a rolling shutter camera."><meta name=author content="Fuwei Li"><link rel=canonical href=https://livey.github.io><link crossorigin=anonymous href=/assets/css/stylesheet.d6fcd20a4fb86efa4dfac8ec95da60244cc8871042183da1ef28e3a762ad79c8.css integrity="sha256-1vzSCk+4bvpN+sjsldpgJEzIhxBCGD2h7yjjp2Ktecg=" rel="preload stylesheet" as=style><link rel=icon href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://livey.github.io/posts/2024-12-rolling-shutter/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="index, follow"><meta name=author content="Fuwei Li"><meta name=description content="How to project LiDAR points onto a rolling shutter camera."><meta property="og:type" content="article"><meta property="og:url" content="https://livey.github.io/posts/2024-12-rolling-shutter/"><meta property="og:title" content="Rolling Shutter Camera Projection"><meta property="og:description" content="How to project LiDAR points onto a rolling shutter camera."><meta property="og:image" content="https://livey.github.io/images/site-preview.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="Rolling Shutter Camera Projection"><meta name=twitter:description content="How to project LiDAR points onto a rolling shutter camera."><meta name=twitter:image content="https://livey.github.io/images/site-preview.jpg"><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css integrity=sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js integrity=sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><meta property="og:url" content="https://livey.github.io/posts/2024-12-rolling-shutter/"><meta property="og:site_name" content="Fuwei's Tech Notes"><meta property="og:title" content="Rolling Shutter Camera Projection"><meta property="og:description" content="How to project LiDAR points onto a rolling shutter camera."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-11-25T00:00:00+00:00"><meta property="article:modified_time" content="2024-11-25T00:00:00+00:00"><meta property="article:tag" content="Autonomous Driving"><meta property="article:tag" content="Signal Processing"><meta property="article:tag" content="Rolling Shutter Camera"><meta property="og:image" content="https://livey.github.io/posts/2024-12-rolling-shutter/%3Cimage%20path/url%3E"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://livey.github.io/posts/2024-12-rolling-shutter/%3Cimage%20path/url%3E"><meta name=twitter:title content="Rolling Shutter Camera Projection"><meta name=twitter:description content="How to project LiDAR points onto a rolling shutter camera."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://livey.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Rolling Shutter Camera Projection","item":"https://livey.github.io/posts/2024-12-rolling-shutter/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Rolling Shutter Camera Projection","name":"Rolling Shutter Camera Projection","description":"How to project LiDAR points onto a rolling shutter camera.","keywords":["autonomous driving","signal processing","rolling shutter camera"],"articleBody":"Unlike global shutter cameras that capture the entire frame at once, rolling shutter cameras capture each row sequentially, leading to image distortions when there is motion. This paper discusses the rolling shutter effect in cameras and methods to handle it.\nFundamentals of Rolling Shutter Camera Global Shutter Camera v.s. Rolling Shutter Camera. (a) Global Shutter Camera. (b) Rolling Shutter Camera. (figure from [6]) To efficiently capture and read the image, the time constraints for rolling shutter camera are:\nThe read-out time for each row is the same\nThe exposure time for each row is the same\nThe start of the read-out time of each row begins instantly after the end of the previous row’s read-out time\nThe exposure should start after the readout of the last frame\nWarping Transformation for Undistortion The warping transformation for undistorting is based on the same depth assumption [1].\nThe pixel of $^{c_n}\\mathbf{q}_k$ captured by the rolling shutter camera at row $N$ can be transformed to the imaginary global shutter camera at the first row as follows:\n$$^{c_0}\\mathbf{q}_k = \\frac{z_{c_n}}{z_{c_0}} \\mathbf{K} \\cdot {}^{c_0}\\mathbf{T}_{c(n)} \\cdot \\mathbf{K}^{-1} \\cdot {}^{c_n}\\mathbf{q}_k$$Usually, it is assumed that $z_{c_0} = z_{c_n}$, which simplifies above equation as follows:\n$$^{c_0}\\mathbf{q}_k = \\mathbf{K} {}^{c_0}\\mathbf{T}_{c(n)} \\mathbf{K}^{-1} \\cdot {}^{c_n}\\mathbf{q}_k \\tag{1}$$This can be seen as a type of warp operation:\n$$^{c_0}\\mathbf{A}_{c(n)} = \\mathbf{K} {}^{c_0}\\mathbf{T}_{c(n)} \\mathbf{K}^{-1}$$and the equation (1) can be written as:\n$$^{c_0}\\mathbf{q}_k = {}^{c_0}\\mathbf{A}_{c(n)} \\cdot {}^{c_n}\\mathbf{q}_k $$where, the $^{c_0}\\mathbf{A}_{c(n)}$ denotes the warp matrix projecting the pixel from the $c_{(n)}$ (exposure at time of line $n$) to the $c_0$ (exposure at time of line 0).\nRolling Shutter Projection Problem formulation description of the problem from [4] In [4], it says this estimation problem is a convex optimization problem. Let us break it down and figure out how to reach the conclusion.\nSuppose a constant velocity, $v$, and angular velocity $w$ camera pose, then the pixel pose at time, $t$, relative to a pose, $\\mathbf{T}_0$, is (using $T(3)\\times SO(3)$ to represent the pose, $SE(3)$) [5]\n$$\\begin{aligned} \\mathbf{T}_c(\\delta t) \u0026=\\mathbf{T}_0\\boxplus \\mathbf{\\tau}(\\delta t)\\\\ \u0026=\\mathbf{T}_0 \\begin{bmatrix} e^{[\\delta t*w]_\\times} \u0026 \\delta t*v\\\\ 0 \u0026 1 \\end{bmatrix} \\end{aligned}$$We can project a point, $\\mathbf{p}$, into the image plane and get its row numbers, $v$, as (here we use the pinhole camera model)\n$$ \\begin{bmatrix} x^c\\\\ y^c\\\\ z^c \\end{bmatrix} = \\mathbf{T}_c^{-1} \\begin{bmatrix} x\\\\ y\\\\ z \\end{bmatrix} ,\\quad \\begin{bmatrix} u\\\\ v\\\\ 1 \\end{bmatrix} = \\mathbf{K} \\begin{bmatrix} x^c/z^c\\\\ y^c/z^c\\\\ 1 \\end{bmatrix} $$and the readout time at line $v$ is $t^\\prime = t_0+v\\Delta t$, where $t_0$ is the time in the first row and $\\Delta t$ the readout time of each row. Minimizing the estimated time and the assumption time we get the problem formulation\n$$ \\underset{t}{\\text{argmin}}\\, \\|t - t^\\prime \\left(K, \\mathbf{T}(t), \\mathbf{p}\\right) \\|^2 \\tag{2} $$where, $t$, can be interpreted as the relative time to the start of the first row.\nConvexity check Let the LiDAR points, $\\mathbf{p}$, undistorted to the time of the first row as, $\\mathbf{x}$, we have, $\\mathbf{x} = \\mathbf{T}_0^{-1}\\mathbf{p}$\nThen points in the camera coordinate is,\n$$\\mathbf{x}^c = \\begin{bmatrix} e^{[wt]_\\times} \u0026 vt\\\\ 0 \u0026 1 \\end{bmatrix}^{-1} \\mathbf{x}$$where $t$ is the relative time to first row. Here\n$$\\begin{bmatrix} e^{[wt]_\\times} \u0026 vt\\\\ 0 \u0026 1 \\end{bmatrix}^{-1}$$can be approximated as\n$$\\begin{bmatrix} e^{[-wt]_\\times} \u0026 -vt\\\\ 0 \u0026 1 \\end{bmatrix}$$if we treat $SE(3)$ as composite of $\\left\u003c SO(3), \\mathbb{R}^3 \\right\u003e$. Failed to prove it is convex. Can find the table below [3].\nDifferent assumptions on the motion lead to different types of solutions for tc and the projection q(tc). The Iterative Solution We can also write the rolling shutter projection problem as a root finding problem [3]:\n$$ t = t^\\prime\\left(K, \\mathbf{T}(t), \\mathbf{p}\\right).\\tag{3} $$Then, we can resort to iterative algorithm by doing\n$$ t_{k+1} = t^\\prime\\left(K, \\mathbf{T}(t_k), \\mathbf{p}\\right). $$The gap between problem (2) and (3) is that, the $t^\\prime$ involves some integer operation, e.g., the projection on the pixel coordinate.\nThen, the only problem is to prove the convergence of the iterative algorithm.\nConvergence proof: Contraction operator To prove the solution of the iterative algorithm to problem (3) always exists and is unique, we can prove the operator, $t^\\prime$, in problem (3) is a contraction mapping accroding to the Banach fixed-point theorem,i.e.,\n$$\\exist\\,q\\in[0,1) \\text{ such that } \\|t^\\prime(t_1)-t^\\prime(t_2)\\| \u003c q\\|t_1-t_2\\|$$For simplicity, we assume $w=0$ and $v=[0, v_y, 0,]$, then we have (using the pinhole camera model)\n$$\\|t^\\prime(t_1) - t^\\prime(t_2)\\| = \\|f_y \\frac{(t_1-t_2)v_y}{z}\\Delta t\\|$$where $f_y$ is the vertical component of the focal length in the camera intrinsic matrix and $\\Delta t$ is the time delay between the readout of two consecutive rows (the row readout time). In the following, we will give an example to show that the operator is a contraction operator.\nSo, we only need to establish $\\|f_y \\frac{(t_1-t_2)v_y}{z}\\Delta t\\| \u003c \\|t_1-t_2\\|$, which is equivalent to $f_y\\frac{|v_y\\Delta t|}{z}\u003c1$, For a 4K resolution image, we have $f_y=1920$, $\\Delta t = 1/(20*2160)$. For a typical car on the highway, the maximal velocity may be $v_y=80$. So, $f_y*|v_y*\\Delta t| \u003c 1920*80/20/2160 = 3.5$. Thus, for objects with $z\u003e3.5$. It is a contraction operator. In a real scenario, $v_y$ will be much smaller. So, most of the conditions are satisfied except for extremely close points.\nThough the simplified problem, it gives us enough insights into why the iterative algorithm works. However, we should note that, the convergence is not guanranteed in special cases, e.g., when the object is extremely close to the camera.\nExperiments Projecting the LiDAR points onto the image plane: left is without rolling shutter compensation, right is with rolling shutter compensation. In this experiment, we project the LiDAR points onto the image plane with and without rolling shutter compensation [7]. From the figure, we can see that with rolling shutter compensation, the LiDAR points are more aligned with the image. However, we still need to compensate the exposure time to get more accurate results.\nReferences [1] S. Hong, C. Zheng, H. Yin and S. Shen, “Rollvox: Real-Time and High-Quality LiDAR Colorization with Rolling Shutter Camera,” 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 7195-7201, doi: 10.1109/IROS55552.2023.10342172.\n[2] Li, You. “Spatial-Temporal Measurement Alignment of Rolling Shutter Camera and LiDAR.” IEEE Sensors Letters 6.12 (2022): 1-4.\n[3] Meingast, Marci, Christopher Geyer, and Shankar Sastry. “Geometric models of rolling-shutter cameras.” arXiv preprint cs/0503076 (2005).\n[4] Sun, Pei, et al. “Scalability in perception for autonomous driving: Waymo open dataset.” Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2020.\n[5] Sola, Joan, Jeremie Deray, and Dinesh Atchuthan. “A micro Lie theory for state estimation in robotics.” arXiv preprint arXiv:1812.01537 (2018).\n[6] Li, Jingyi, and Weipeng Guan. 2018. “The Optical Barcode Detection and Recognition Method Based on Visible Light Communication Using Machine Learning” Applied Sciences 8, no. 12: 2425.\n[7] Mao, Jiageng, Minzhe Niu, Chenhan Jiang, Hanxue Liang, Jingheng Chen, Xiaodan Liang, Yamin Li et al. “One million scenes for autonomous driving: Once dataset.” arXiv preprint arXiv:2106.11037 (2021).\n","wordCount":"1132","inLanguage":"en","image":"https://livey.github.io/posts/2024-12-rolling-shutter/%3Cimage%20path/url%3E","datePublished":"2024-11-25T00:00:00Z","dateModified":"2024-11-25T00:00:00Z","author":{"@type":"Person","name":"Fuwei Li"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://livey.github.io/posts/2024-12-rolling-shutter/"},"publisher":{"@type":"Organization","name":"Fuwei's Tech Notes","logo":{"@type":"ImageObject","url":"https://livey.github.io/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://livey.github.io/ accesskey=h title="Home (Alt + H)"><img src=https://livey.github.io/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://livey.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://livey.github.io/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://livey.github.io/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://livey.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://livey.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Rolling Shutter Camera Projection</h1><div class=post-description>How to project LiDAR points onto a rolling shutter camera.</div><div class=post-meta><span title='2024-11-25 00:00:00 +0000 UTC'>November 25, 2024</span>&nbsp;·&nbsp;6 min&nbsp;·&nbsp;1132 words&nbsp;·&nbsp;Fuwei Li&nbsp;|&nbsp;<a href=https://github.com/livey/livey.github.io/issues/new rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#fundamentals-of-rolling-shutter-camera aria-label="Fundamentals of Rolling Shutter Camera">Fundamentals of Rolling Shutter Camera</a></li><li><a href=#warping-transformation-for-undistortion aria-label="Warping Transformation for Undistortion">Warping Transformation for Undistortion</a></li><li><a href=#rolling-shutter-projection aria-label="Rolling Shutter Projection">Rolling Shutter Projection</a><ul><li><a href=#problem-formulation aria-label="Problem formulation">Problem formulation</a></li><li><a href=#convexity-check aria-label="Convexity check">Convexity check</a></li><li><a href=#the-iterative-solution aria-label="The Iterative Solution">The Iterative Solution</a><ul><li><a href=#convergence-proof-contraction-operator aria-label="Convergence proof: Contraction operator">Convergence proof: Contraction operator</a></li></ul></li></ul></li><li><a href=#experiments aria-label=Experiments>Experiments</a></li><li><a href=#references aria-label=References>References</a></li></ul></div></details></div><div class=post-content><p>Unlike global shutter cameras that capture the entire frame at once, rolling shutter cameras capture each row sequentially, leading to image distortions when there is motion.
This paper discusses the rolling shutter effect in cameras and methods to handle it.</p><h1 id=fundamentals-of-rolling-shutter-camera>Fundamentals of Rolling Shutter Camera<a hidden class=anchor aria-hidden=true href=#fundamentals-of-rolling-shutter-camera>#</a></h1><figure style=text-align:center><img src=./resources/global-rolling.png alt="global shutter camera v.s. rolling shutter camera" style="width:100%;margin:0 auto;display:block"><figcaption style=font-weight:400>Global Shutter Camera v.s. Rolling Shutter Camera. (a) Global Shutter Camera. (b) Rolling Shutter Camera. (figure from [6])</figcaption></figure><p>To efficiently capture and read the image, the time constraints for rolling shutter camera are:</p><ol><li><p>The read-out time for each row is the same</p></li><li><p>The exposure time for each row is the same</p></li><li><p>The start of the read-out time of each row begins instantly after the end of the previous row&rsquo;s read-out time</p></li><li><p>The exposure should start after the readout of the last frame</p></li></ol><h1 id=warping-transformation-for-undistortion>Warping Transformation for Undistortion<a hidden class=anchor aria-hidden=true href=#warping-transformation-for-undistortion>#</a></h1><p>The warping transformation for undistorting is based on the same depth assumption [1].</p><p>The pixel of $^{c_n}\mathbf{q}_k$ captured by the rolling shutter camera at row $N$ can be transformed to the imaginary global shutter camera at the first row as follows:</p>$$^{c_0}\mathbf{q}_k = \frac{z_{c_n}}{z_{c_0}} \mathbf{K} \cdot {}^{c_0}\mathbf{T}_{c(n)} \cdot \mathbf{K}^{-1} \cdot {}^{c_n}\mathbf{q}_k$$<p>Usually, it is assumed that $z_{c_0} = z_{c_n}$, which simplifies above equation as follows:</p>$$^{c_0}\mathbf{q}_k = \mathbf{K} {}^{c_0}\mathbf{T}_{c(n)} \mathbf{K}^{-1} \cdot {}^{c_n}\mathbf{q}_k \tag{1}$$<p>This can be seen as a type of warp operation:</p>$$^{c_0}\mathbf{A}_{c(n)} = \mathbf{K} {}^{c_0}\mathbf{T}_{c(n)} \mathbf{K}^{-1}$$<p>and the equation (1) can be written as:</p>$$^{c_0}\mathbf{q}_k = {}^{c_0}\mathbf{A}_{c(n)} \cdot {}^{c_n}\mathbf{q}_k $$<p>where, the $^{c_0}\mathbf{A}_{c(n)}$ denotes the warp matrix projecting the pixel from the $c_{(n)}$ (exposure at time of line $n$) to the $c_0$ (exposure at time of line 0).</p><h1 id=rolling-shutter-projection>Rolling Shutter Projection<a hidden class=anchor aria-hidden=true href=#rolling-shutter-projection>#</a></h1><h2 id=problem-formulation>Problem formulation<a hidden class=anchor aria-hidden=true href=#problem-formulation>#</a></h2><figure style=text-align:center><img src=./resources/rolling-shutter-problem.png alt="screen shot of the problem description from the waymo paper" style="width:70%;margin:0 auto;display:block"><figcaption style=font-weight:400>description of the problem from [4]</figcaption></figure><p>In [4], it says this estimation problem is a convex optimization problem. Let us break it down and figure out how to reach the conclusion.</p><p>Suppose a constant velocity, $v$, and angular velocity $w$ camera pose, then the pixel pose at time, $t$, relative to a pose, $\mathbf{T}_0$, is (using $T(3)\times SO(3)$ to represent the pose, $SE(3)$) [5]</p>$$\begin{aligned}
\mathbf{T}_c(\delta t)
&=\mathbf{T}_0\boxplus \mathbf{\tau}(\delta t)\\
&=\mathbf{T}_0
\begin{bmatrix}
e^{[\delta t*w]_\times} & \delta t*v\\
0 & 1
\end{bmatrix}
\end{aligned}$$<p>We can project a point, $\mathbf{p}$, into the image plane and get its row numbers, $v$, as (here we use the pinhole camera model)</p>$$
\begin{bmatrix}
x^c\\
y^c\\
z^c
\end{bmatrix} =
\mathbf{T}_c^{-1}
\begin{bmatrix}
x\\
y\\
z
\end{bmatrix}
,\quad
\begin{bmatrix}
u\\
v\\
1
\end{bmatrix} =
\mathbf{K}
\begin{bmatrix}
x^c/z^c\\
y^c/z^c\\
1
\end{bmatrix}
$$<p>and the readout time at line $v$ is $t^\prime = t_0+v\Delta t$, where $t_0$ is the time in the first row and $\Delta t$ the readout time of each row. Minimizing the estimated time and the assumption time we get the problem formulation</p>$$
\underset{t}{\text{argmin}}\, \|t - t^\prime \left(K, \mathbf{T}(t), \mathbf{p}\right) \|^2 \tag{2}
$$<p>where, $t$, can be interpreted as the relative time to the start of the first row.</p><h2 id=convexity-check>Convexity check<a hidden class=anchor aria-hidden=true href=#convexity-check>#</a></h2><p>Let the LiDAR points, $\mathbf{p}$, undistorted to the time of the first row as, $\mathbf{x}$, we have, $\mathbf{x} = \mathbf{T}_0^{-1}\mathbf{p}$</p><p>Then points in the camera coordinate is,</p>$$\mathbf{x}^c =
\begin{bmatrix}
e^{[wt]_\times} & vt\\
0 & 1
\end{bmatrix}^{-1}
\mathbf{x}$$<p>where $t$ is the relative time to first row. Here</p>$$\begin{bmatrix}
e^{[wt]_\times} & vt\\
0 & 1
\end{bmatrix}^{-1}$$<p>can be approximated as</p>$$\begin{bmatrix}
e^{[-wt]_\times} & -vt\\
0 & 1
\end{bmatrix}$$<p>if we treat $SE(3)$ as composite of $\left< SO(3), \mathbb{R}^3 \right>$. <strong>Failed to prove it is convex</strong>. Can find the table below [3].</p><figure style=text-align:center><img src=./resources/image-4.png alt="screen shot of the problem description from the waymo paper" style="width:100%;margin:0 auto;display:block"><figcaption style=font-weight:400>Different assumptions on the motion lead to different types of solutions for tc and the projection q(tc).</figcaption></figure><h2 id=the-iterative-solution>The Iterative Solution<a hidden class=anchor aria-hidden=true href=#the-iterative-solution>#</a></h2><p>We can also write the rolling shutter projection problem as a root finding problem [3]:</p>$$
t = t^\prime\left(K, \mathbf{T}(t), \mathbf{p}\right).\tag{3}
$$<p>Then, we can resort to iterative algorithm by doing</p>$$
t_{k+1} = t^\prime\left(K, \mathbf{T}(t_k), \mathbf{p}\right).
$$<p>The gap between problem (2) and (3) is that, the $t^\prime$ involves some integer operation, e.g., the projection on the pixel coordinate.</p><p>Then, the only problem is to prove the convergence of the iterative algorithm.</p><h3 id=convergence-proof-contraction-operator>Convergence proof: Contraction operator<a hidden class=anchor aria-hidden=true href=#convergence-proof-contraction-operator>#</a></h3><p>To prove the solution of the iterative algorithm to problem (3) always exists and is unique, we can prove the operator, $t^\prime$, in problem (3) is a contraction mapping accroding to the <strong>Banach fixed-point theorem</strong>,i.e.,</p>$$\exist\,q\in[0,1) \text{ such that } \|t^\prime(t_1)-t^\prime(t_2)\| < q\|t_1-t_2\|$$<p>For simplicity, we assume $w=0$ and $v=[0, v_y, 0,]$, then we have (using the pinhole camera model)</p>$$\|t^\prime(t_1) - t^\prime(t_2)\| = \|f_y \frac{(t_1-t_2)v_y}{z}\Delta t\|$$<p>where $f_y$ is the vertical component of the focal length in the camera intrinsic matrix and $\Delta t$ is the time delay between the readout of two consecutive rows (the row readout time). In the following, we will give an example to show that the operator is a contraction operator.</p><p>So, we only need to establish $\|f_y \frac{(t_1-t_2)v_y}{z}\Delta t\| < \|t_1-t_2\|$, which is equivalent to $f_y\frac{|v_y\Delta t|}{z}<1$, For a 4K resolution image, we have $f_y=1920$, $\Delta t = 1/(20*2160)$. For a typical car on the highway, the maximal velocity may be $v_y=80$. So, $f_y*|v_y*\Delta t| < 1920*80/20/2160 = 3.5$. Thus, for objects with $z>3.5$. It is a contraction operator. In a real scenario, $v_y$ will be much smaller. So, most of the conditions are satisfied except for extremely close points.</p><p>Though the simplified problem, it gives us enough insights into why the iterative algorithm works. However, we should note that, the convergence is not guanranteed in special cases, e.g., when the object is extremely close to the camera.</p><h1 id=experiments>Experiments<a hidden class=anchor aria-hidden=true href=#experiments>#</a></h1><figure style=text-align:center><div style=display:flex;justify-content:center;gap:20px><img src=./resources/no-rolling-shutter-com.png alt="projection result without rolling shutter compensation" style=width:48%>
<img src=./resources/with-rs-comp.png alt="projection result with rolling shutter compensation" style=width:48%></div><figcaption style=font-weight:400>Projecting the LiDAR points onto the image plane: left is without rolling shutter compensation, right is with rolling shutter compensation.</figcaption></figure><p>In this experiment, we project the LiDAR points onto the image plane with and without rolling shutter compensation [7]. From the figure, we can see that with rolling shutter compensation, the LiDAR points are more aligned with the image. However, we still need to compensate the exposure time to get more accurate results.</p><h1 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h1><p>[1] S. Hong, C. Zheng, H. Yin and S. Shen, &ldquo;Rollvox: Real-Time and High-Quality LiDAR Colorization with Rolling Shutter Camera,&rdquo; 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 7195-7201, doi: 10.1109/IROS55552.2023.10342172.</p><p>[2] Li, You. &ldquo;Spatial-Temporal Measurement Alignment of Rolling Shutter Camera and LiDAR.&rdquo; <em>IEEE Sensors Letters</em> 6.12 (2022): 1-4.</p><p>[3] Meingast, Marci, Christopher Geyer, and Shankar Sastry. &ldquo;Geometric models of rolling-shutter cameras.&rdquo; <em>arXiv preprint cs/0503076</em> (2005).</p><p>[4] Sun, Pei, et al. &ldquo;Scalability in perception for autonomous driving: Waymo open dataset.&rdquo; <em>Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>. 2020.</p><p>[5] Sola, Joan, Jeremie Deray, and Dinesh Atchuthan. &ldquo;A micro Lie theory for state estimation in robotics.&rdquo; <em>arXiv preprint arXiv:1812.01537</em> (2018).</p><p>[6] Li, Jingyi, and Weipeng Guan. 2018. &ldquo;The Optical Barcode Detection and Recognition Method Based on Visible Light Communication Using Machine Learning&rdquo; Applied Sciences 8, no. 12: 2425.</p><p>[7] Mao, Jiageng, Minzhe Niu, Chenhan Jiang, Hanxue Liang, Jingheng Chen, Xiaodan Liang, Yamin Li et al. &ldquo;One million scenes for autonomous driving: Once dataset.&rdquo; arXiv preprint arXiv:2106.11037 (2021).</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://livey.github.io/tags/autonomous-driving/>Autonomous Driving</a></li><li><a href=https://livey.github.io/tags/signal-processing/>Signal Processing</a></li><li><a href=https://livey.github.io/tags/rolling-shutter-camera/>Rolling Shutter Camera</a></li></ul><nav class=paginav><a class=prev href=https://livey.github.io/posts/2024-12-angle-filter/><span class=title>« Prev</span><br><span>Angle Kalman Filter</span>
</a><a class=next href=https://livey.github.io/posts/2024-12-camera-frustum/><span class=title>Next »</span><br><span>Camera Projection via View Frustum Culling</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Rolling Shutter Camera Projection on x" href="https://x.com/intent/tweet/?text=Rolling%20Shutter%20Camera%20Projection&amp;url=https%3a%2f%2flivey.github.io%2fposts%2f2024-12-rolling-shutter%2f&amp;hashtags=autonomousdriving%2csignalprocessing%2crollingshuttercamera"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Rolling Shutter Camera Projection on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2flivey.github.io%2fposts%2f2024-12-rolling-shutter%2f&amp;title=Rolling%20Shutter%20Camera%20Projection&amp;summary=Rolling%20Shutter%20Camera%20Projection&amp;source=https%3a%2f%2flivey.github.io%2fposts%2f2024-12-rolling-shutter%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Rolling Shutter Camera Projection on reddit" href="https://reddit.com/submit?url=https%3a%2f%2flivey.github.io%2fposts%2f2024-12-rolling-shutter%2f&title=Rolling%20Shutter%20Camera%20Projection"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Rolling Shutter Camera Projection on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2flivey.github.io%2fposts%2f2024-12-rolling-shutter%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Rolling Shutter Camera Projection on whatsapp" href="https://api.whatsapp.com/send?text=Rolling%20Shutter%20Camera%20Projection%20-%20https%3a%2f%2flivey.github.io%2fposts%2f2024-12-rolling-shutter%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Rolling Shutter Camera Projection on telegram" href="https://telegram.me/share/url?text=Rolling%20Shutter%20Camera%20Projection&amp;url=https%3a%2f%2flivey.github.io%2fposts%2f2024-12-rolling-shutter%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Rolling Shutter Camera Projection on ycombinator" href="https://news.ycombinator.com/submitlink?t=Rolling%20Shutter%20Camera%20Projection&u=https%3a%2f%2flivey.github.io%2fposts%2f2024-12-rolling-shutter%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://livey.github.io/>Fuwei's Tech Notes</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>
<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>End of Line Camera Calibration | Fuwei's Tech Notes</title>
<meta name=keywords content="Autonomous Driving,Camera Calibration,EOL,BEV"><meta name=description content="This post is about end-of-line (EOL) camera calibration, especially for camera bird's-eye view (BEV) extrinsic calibration."><meta name=author content="Fuwei Li"><link rel=canonical href=https://livey.github.io><link crossorigin=anonymous href=/assets/css/stylesheet.d6fcd20a4fb86efa4dfac8ec95da60244cc8871042183da1ef28e3a762ad79c8.css integrity="sha256-1vzSCk+4bvpN+sjsldpgJEzIhxBCGD2h7yjjp2Ktecg=" rel="preload stylesheet" as=style><link rel=icon href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://livey.github.io/posts/2025-02-eol-calib/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="index, follow"><meta name=author content="Fuwei Li"><meta name=description content="This post is about end-of-line (EOL) camera calibration, especially for camera bird's-eye view (BEV) extrinsic calibration."><meta property="og:type" content="article"><meta property="og:url" content="https://livey.github.io/posts/2025-02-eol-calib/"><meta property="og:title" content="End of Line Camera Calibration"><meta property="og:description" content="This post is about end-of-line (EOL) camera calibration, especially for camera bird's-eye view (BEV) extrinsic calibration."><meta property="og:image" content="https://livey.github.io/images/site-preview.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="End of Line Camera Calibration"><meta name=twitter:description content="This post is about end-of-line (EOL) camera calibration, especially for camera bird's-eye view (BEV) extrinsic calibration."><meta name=twitter:image content="https://livey.github.io/images/site-preview.jpg"><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css integrity=sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js integrity=sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><meta property="og:url" content="https://livey.github.io/posts/2025-02-eol-calib/"><meta property="og:site_name" content="Fuwei's Tech Notes"><meta property="og:title" content="End of Line Camera Calibration"><meta property="og:description" content="This post is about end-of-line (EOL) camera calibration, especially for camera bird's-eye view (BEV) extrinsic calibration."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-02-03T00:00:00+00:00"><meta property="article:modified_time" content="2025-02-03T00:00:00+00:00"><meta property="article:tag" content="Autonomous Driving"><meta property="article:tag" content="Camera Calibration"><meta property="article:tag" content="EOL"><meta property="article:tag" content="BEV"><meta property="og:image" content="https://livey.github.io/posts/2025-02-eol-calib/%3Cimage%20path/url%3E"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://livey.github.io/posts/2025-02-eol-calib/%3Cimage%20path/url%3E"><meta name=twitter:title content="End of Line Camera Calibration"><meta name=twitter:description content="This post is about end-of-line (EOL) camera calibration, especially for camera bird's-eye view (BEV) extrinsic calibration."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://livey.github.io/posts/"},{"@type":"ListItem","position":2,"name":"End of Line Camera Calibration","item":"https://livey.github.io/posts/2025-02-eol-calib/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"End of Line Camera Calibration","name":"End of Line Camera Calibration","description":"This post is about end-of-line (EOL) camera calibration, especially for camera bird's-eye view (BEV) extrinsic calibration.","keywords":["Autonomous Driving","Camera Calibration","EOL","BEV"],"articleBody":"In this post, we will discuss the end-of-line (EOL) camera calibration, especially for camera bird’s-eye view (BEV) extrinsic calibration.\nSuggested Pipeline Do single camera intrinsic calibration\nMeasure each corner in the world coordinate\nRefine the corners’ coordinates according to board constraints (plane, parallel, equally spaced)\nFind the plane equation in the world coordinate\nInitialize each camera’s extrinsic parameters by solving the perspective and point (PnP) problem\nEstimate the 3D coordinates by the intersection of the image ray and board plane\nConstruct the objective loss function (consistency of different cameras with common seen points and single camera’s observation)\nRefine the Corner’s Coordinates by the Board Constraints Assume the center of the board is located at the origin of a local coordinate, $(0,0,0)^\\top$, the corner coordinate is located at $\\{\\mathbf{x}_i\\}^N_{i=1}$, then the board normal is $(0,0,1)^\\top$. Assume the board is transformed to the world coordinate by rotation, $\\mathbf{R}$, and translation, $\\mathbf{t}$. We have the observed coordinates $\\{\\hat{\\mathbf{y}}_i\\}$. Then we minimize the objectives:\n$$\\{\\mathbf{y}_i^*, \\mathbf{R}^*, \\mathbf{t}^*\\} = \\underset{\\mathbf{y}_i,\\mathbf{R}, \\mathbf{t}}{\\arg\\min}\\sum_i \\|\\hat{\\mathbf{y}}_i -\\mathbf{y}_i\\|^2\\\\ \\text{s.t. } \\mathbf{y}_i = \\mathbf{R}\\mathbf{x}_i + \\mathbf{t} $$This problem can be easily solved since it is a simple Iterative Closest Point (ICP) problem.\nThen we can get the center of the board as $\\mathbf{x}_0=\\mathbf{t}^*$, and the normal of the board is $\\mathbf{R}^*[0, 0, 1]^\\top$.\nNow we have refined board corners in the world coordinates, i.e., $\\{\\mathbf{y}_i^*\\}^N_{i=1}$.\nUnknown Board Dimension If we do not have the board dimension, then we can directly fit the plane using the measured corners, $\\{\\mathbf{x}_i\\}^N_{i=1}$ (with a slight abuse of notation). Assume the plane equation is $\\mathbf{n}^\\top \\mathbf{x} - c = 0$ (with unit normal vector, i.e., $\\|\\mathbf{n}\\| = 1$). Then we can solve for $\\mathbf{n}$ and $c$ by minimizing the following objective:\n$$ \\underset{\\mathbf{n}, c}{\\text{argmin}} \\frac{1}{N}\\sum_i \\|\\mathbf{n}^\\top \\mathbf{x}_i - c\\|^2 \\\\ \\text{s.t. } \\|\\mathbf{n}\\| = 1 $$For any fixed $\\mathbf{n}$, taking derivative with respect to $c$ and setting it to zero, we have:\n$$ c = \\frac{1}{N} \\sum_i \\mathbf{n}^\\top \\mathbf{x}_i = \\mathbf{n}^\\top \\bar{\\mathbf{x}} $$where $\\bar{\\mathbf{x}} = \\frac{1}{N} \\sum_i \\mathbf{x}_i$ is the mean of the measured corners.\nSo, the objective function becomes:\n$$ \\begin{aligned} \u0026\\frac{1}{N}\\sum_i \\|\\mathbf{n}^\\top (\\mathbf{x}_i - \\bar{\\mathbf{x}})\\|^2 \\\\ \u0026= \\frac{1}{N}\\mathbf{n}^\\top \\left(\\sum_i (\\mathbf{x}_i - \\bar{\\mathbf{x}})(\\mathbf{x}_i - \\bar{\\mathbf{x}})^\\top\\right) \\mathbf{n} \\\\ \u0026 = \\mathbf{n}^\\top \\mathbf{\\Sigma}_x \\mathbf{n} \\end{aligned} $$where $\\mathbf{\\Sigma}_x = \\frac{1}{N} \\sum_i (\\mathbf{x}_i - \\bar{\\mathbf{x}})(\\mathbf{x}_i - \\bar{\\mathbf{x}})^\\top$ is the biased sample covariance matrix of the measured corners.\nConsidering $\\|\\mathbf{n}\\| = 1$, $\\mathbf{n}$ is the eigenvector of $\\mathbf{\\Sigma}_x$ corresponding to its smallest eigenvalue.\nThe refined corners’ coordinates are the projection of the measured corners on the plane, which can be written as:\n$$ \\mathbf{y}_i = \\mathbf{x}_i - \\mathbf{n}^\\top (\\mathbf{x}_i - \\bar{\\mathbf{x}}) \\mathbf{n} = \\mathbf{x}_i - (\\mathbf{n}^\\top\\mathbf{x}_i -c)\\mathbf{n}. $$which has clear geometric meaning: the measured corners minus the projection on the plane normal.\nThe Intersection of the Image Ray and Board Plane We are given a 3D plane:\n$$\\mathbf{n}^\\top \\mathbf{x} + c = 0,$$and a camera model with the projection equation:\n$$d\\, \\mathbf{u} = \\mathbf{K} (\\mathbf{R}\\, \\mathbf{x} + \\mathbf{t}),$$where:\n$\\mathbf{u} \\in \\mathbb{R}^3$ is the homogeneous image coordinate (usually $\\mathbf{u} = [u, v, 1]^\\top$) $d$ is an unknown scale (depth) factor $\\mathbf{K}$ is the camera intrinsic matrix $\\mathbf{R}$ and $\\mathbf{t}$ are the rotation and translation (extrinsic parameters) of the camera $\\mathbf{x} \\in \\mathbb{R}^3$ is the 3D point we wish to recover Our goal is to find $\\mathbf{x}$ in terms of the known quantities $\\mathbf{u}, \\mathbf{K}, \\mathbf{R}, \\mathbf{t}, \\mathbf{n},$ and $c$.\nRewrite the Projection Equation\n$$\\mathbf{x} = \\mathbf{R}^\\top \\left(d\\,\\mathbf{K}^{-1} \\mathbf{u} - \\mathbf{t}\\right).$$However, the scale factor $d$ is still unknown.\nUse the Plane Constraint to Solve for $d$\nSince $\\mathbf{x}$ lies on the plane, it must satisfy:\n$$\\mathbf{n}^\\top \\mathbf{x} + c = 0.$$Substitute the expression we just found for $\\mathbf{x}$:\n$$\\mathbf{n}^\\top \\Bigl(\\mathbf{R}^\\top (d\\,\\mathbf{K}^{-1} \\mathbf{u} - \\mathbf{t})\\Bigr) + c = 0.$$Because the scalar product is invariant under transposition, we can write:\nNow, solve for $d$:\n$$d = \\frac{\\mathbf{n}^\\top \\mathbf{R}^\\top \\mathbf{t} - c}{\\mathbf{n}^\\top \\mathbf{R}^\\top \\mathbf{K}^{-1} \\mathbf{u}}.$$ $$\\mathbf{n}^\\top \\mathbf{R}^\\top \\mathbf{K}^{-1} \\mathbf{u} \\neq 0$$ so that the division is valid (this means that the back-projected ray is not parallel to the plane).\nWrite the Final Expression for $\\mathbf{x}$\nSubstitute the expression for $d$ back into the equation for $\\mathbf{x}$:\n$$\\mathbf{x} = \\mathbf{R}^\\top \\left( \\frac{\\mathbf{n}^\\top \\mathbf{R}^\\top \\mathbf{t} - c}{\\mathbf{n}^\\top \\mathbf{R}^\\top \\mathbf{K}^{-1} \\mathbf{u}}\\, \\mathbf{K}^{-1} \\mathbf{u} - \\mathbf{t} \\right).$$Solve the Intersection Problem as an Optimization Problem We wish to solve\n$$ \\min_{\\mathbf{x}} \\Big\\| \\mathbf{u} - \\frac{\\mathbf{R}\\mathbf{x} + \\mathbf{t}}{\\mathbf{e}^\\top (\\mathbf{R}\\mathbf{x} + \\mathbf{t})} \\Big\\|^2\\tag{1} $$subject to the plane constraint\n$$ \\mathbf{n}^\\top \\mathbf{x} + c = 0, $$where: •\t$\\mathbf{R}$ is the rotation matrix, •\t$\\mathbf{t}$ is the translation vector, •\t$\\mathbf{n}$ is the normal of the plane, •\t$c$ is a constant, and •\t$\\mathbf{e} = \\begin{pmatrix} 0 \\ 0 \\ 1 \\end{pmatrix}$ (which selects the depth coordinate).\nEven when the measured image coordinate $\\mathbf{u} \\in \\mathbb{R}^2$ is noisy, the pinhole camera model combined with the plane constraint induces a projective mapping (a homography) from the plane to the image. In other words, for any $\\mathbf{u}$ there exists an entire ray of points $\\mathbf{x}$ that project exactly to $\\mathbf{u}$. The plane constraint then selects one unique point on that ray.\nParameterizing the Back‐Projection Ray Any 3D point $\\mathbf{x}$ whose projection is $\\mathbf{u}$ must satisfy\n$$ \\frac{\\mathbf{R}\\mathbf{x} + \\mathbf{t}}{\\mathbf{e}^\\top (\\mathbf{R}\\mathbf{x} + \\mathbf{t})} = \\begin{pmatrix} \\mathbf{u} \\\\ 1 \\end{pmatrix}. $$This implies that there exists a scalar $\\lambda$ such that\n$$ \\mathbf{R}\\mathbf{x} + \\mathbf{t} = \\lambda \\begin{pmatrix} \\mathbf{u} \\\\ 1 \\end{pmatrix}. $$Solving for $\\mathbf{x}$ gives\n$$ \\mathbf{x} = \\mathbf{R}^{-1} \\Bigl( \\lambda \\begin{pmatrix} \\mathbf{u} \\\\ 1 \\end{pmatrix} - \\mathbf{t} \\Bigr). $$It is convenient to define the camera center in world coordinates as\n$$ \\mathbf{x}_c = -\\mathbf{R}^{-1}\\mathbf{t}, $$and to introduce the direction vector\n$$ \\mathbf{d} = \\mathbf{R}^{-1}\\begin{pmatrix} \\mathbf{u} \\\\ 1 \\end{pmatrix}. $$Thus, the 3D point $\\mathbf{x}$ can be written as\n$$ \\mathbf{x} = \\mathbf{x}_c + \\lambda \\mathbf{d}. $$All points of this form project exactly to $\\mathbf{u}$, which means the optimal value of Eq. (1) is zero\nEnforcing the Plane Constraint Since $\\mathbf{x}$ must lie on the plane, we impose\n$$ \\mathbf{n}^\\top \\mathbf{x} + c = 0. $$Substitute $\\mathbf{x} = \\mathbf{x}_c + \\lambda\\mathbf{d}$ into the plane equation:\n$$ \\mathbf{n}^\\top \\Bigl( \\mathbf{x}_c + \\lambda\\mathbf{d} \\Bigr) + c = 0. $$Expanding, we obtain\n$$ \\mathbf{n}^\\top \\mathbf{x}_c + \\lambda \\mathbf{n}^\\top \\mathbf{d} + c = 0. $$Recalling that $\\mathbf{x}_c = -\\mathbf{R}^{-1}\\mathbf{t}$, the equation becomes\n$$ \\mathbf{n}^\\top \\mathbf{R}^{-1}\\mathbf{t} + \\lambda \\mathbf{n}^\\top \\mathbf{d} + c = 0. $$Solving for $\\lambda$, we have\n$$ \\lambda \\mathbf{n}^\\top \\mathbf{d} = \\mathbf{n}^\\top \\mathbf{R}^{-1}\\mathbf{t} - c, $$or equivalently,\n$$ \\lambda = \\frac{\\mathbf{n}^\\top \\mathbf{R}^{-1}\\mathbf{t} - c}{\\mathbf{n}^\\top \\mathbf{d}} = \\frac{\\mathbf{n}^\\top \\mathbf{R}^{-1}\\mathbf{t} - c}{\\mathbf{n}^\\top \\mathbf{R}^{-1}\\begin{pmatrix} \\mathbf{u} \\ 1 \\end{pmatrix}}, $$provided that $\\mathbf{n}^\\top \\mathbf{d} \\neq 0$.\nThe Final Solution Substitute the value of $\\lambda$ back into the expression for $\\mathbf{x}$:\n$$ \\mathbf{x} = -\\mathbf{R}^{-1}\\mathbf{t} + \\frac{\\mathbf{n}^\\top \\mathbf{R}^{-1}\\mathbf{t} - c}{\\mathbf{n}^\\top \\mathbf{R}^{-1}\\begin{pmatrix} \\mathbf{u} \\\\ 1 \\end{pmatrix}} \\mathbf{R}^{-1}\\begin{pmatrix} \\mathbf{u} \\\\ 1 \\end{pmatrix}. $$This is the unique 3D point on the plane $\\mathbf{n}^\\top \\mathbf{x} + c = 0$ that minimizes the reprojection error, even when $\\mathbf{u}$ is noisy.\nSummary a. Back‐Projection: The projection model\n$$ \\mathbf{x} \\mapsto \\frac{\\mathbf{R}\\mathbf{x} + \\mathbf{t}}{\\mathbf{e}^\\top (\\mathbf{R}\\mathbf{x} + \\mathbf{t})} $$is a homography when restricted to the plane. Hence, every point along the ray\n$$ \\mathcal{R}(\\mathbf{u}) = \\Bigl\\{ \\mathbf{x} = -\\mathbf{R}^{-1}\\mathbf{t} + \\lambda \\mathbf{R}^{-1}\\begin{pmatrix} \\mathbf{u} \\\\ 1 \\end{pmatrix} : \\lambda \\in \\mathbb{R} \\Bigr\\} $$projects to $\\mathbf{u}$.\nb. Plane Intersection: The plane constraint $\\mathbf{n}^\\top \\mathbf{x} + c = 0$ uniquely determines the scalar $\\lambda$, and hence the unique point $\\mathbf{x}$.\nThus, the final answer is\n$$ \\boxed{ \\mathbf{x} = -\\mathbf{R}^{-1}\\mathbf{t} + \\frac{\\mathbf{n}^\\top \\mathbf{R}^{-1}\\mathbf{t} - c}{\\mathbf{n}^\\top \\mathbf{R}^{-1}\\begin{pmatrix} \\mathbf{u} \\\\ 1 \\end{pmatrix}} \\mathbf{R}^{-1}\\begin{pmatrix} \\mathbf{u} \\\\ 1 \\end{pmatrix}. } $$Solve Step 3 and 6 Jointly as a Bundle Adjustment Problem Suppose the board’s markers coordinate in the board’s frame are $\\{ \\mathbf{x}_i^g \\}_{i=1}^N$ in the board’s frame. The measured marker points in the world frame are $\\{ \\mathbf{x}_i^o \\}_{i=1}^N$. The observed image markers in camera 1 are $\\{ \\mathbf{u}_i^1 \\}_{i=1}^{N_1}$ and the observed image markers in the second camera are $\\{ \\mathbf{u}_i^2 \\}_{i=1}^{N_2}$.\nWe construct the loss as:\n$$ \\begin{aligned} \\mathcal{L} \u0026= \\sum_i \\ell_{\\mathbf{T}_0, \\mathbf{x}_i} (\\mathbf{x}_i^g, \\mathbf{x}_i) + \\sum_i \\ell_{\\mathbf{x}_i} (\\mathbf{x}_i^o, \\mathbf{x}_i) \\\\ \u0026 + \\sum_i \\ell_{\\mathbf{x}_i, \\mathbf{T}_0, \\mathbf{T}_1} \\Big( \\pi^{-1}(\\mathbf{u}_i^1), \\mathbf{x}_i \\Big) + \\sum_i \\ell_{\\mathbf{x}_i, \\mathbf{T}_0, \\mathbf{T}_2} \\Big( \\pi^{-1}(\\mathbf{u}_i^2), \\mathbf{x}_i \\Big) \\\\ \u0026+ \\sum_{i \\in C_{1,2}} \\ell_{\\mathbf{T}_0, \\mathbf{T}_1, \\mathbf{T}_2} \\Big( \\pi^{-1}(\\mathbf{u}_i^1), \\pi^{-1}(\\mathbf{u}_i^2) \\Big) \\end{aligned} $$Where:\nthe transformation from the local board to the world board, $\\mathbf{T}_0$; The world coordinates of the board, $\\{\\mathbf{x}_i\\}$; The transformation from the cameras to the world board, $\\mathbf{T}_i$, where $i = 1, 2$; $C_{1,2}$ is the marker set commonly seen by camera 1 and camera 2; $\\pi(\\cdot)$ is the intersection of the camera ray and the world plane. In the first part, we put a hard constraint that the true 3D position of the points should be a rigid transformation of the board.\n$$\\sum_i \\ell_{\\mathbf{T}_0, \\mathbf{x}_i}(\\mathbf{x}_i^g, \\mathbf{x}_i) = \\sum_i I_{\\infty}(\\mathbf{x}_i - \\mathbf{T}_0 \\mathbf{x}_i^g)\\tag{2}$$where $I_\\infty(x)= \\begin{cases} 0, \\text{ if } x=0, \\\\ \\infty, \\text{otherwise} \\end{cases}$.\nThe second part of the loss is the difference between the observations of 3D points and the true position.\n$$\\sum_i \\ell_{\\mathbf{x}_i}(\\mathbf{x}_i, \\mathbf{x}_i^o) = \\sum_i \\|\\mathbf{x}_i - \\mathbf{x}_i^o\\|^2 \\tag{3}$$The third part is the perspective and point loss\n$$\\sum_{i\\in C_1} \\ell_{\\mathbf{x}_i, \\mathbf{T}_0,\\mathbf{T}_1}\\left(\\pi^{-1}(\\mathbf{u}_i^1), \\mathbf{x}_i \\right) = \\sum_{i\\in C_1} \\| \\pi^{-1}(\\mathbf{u}_i^1) - \\mathbf{x}_i \\|^2\\tag{4}$$$$\\sum_{i\\in C_2} \\ell_{\\mathbf{x}_i, \\mathbf{T}_0,\\mathbf{T}_2}\\left(\\pi^{-1}(\\mathbf{u}_i^2), \\mathbf{x}_i \\right) = \\sum_{i\\in C_2} \\| \\pi^{-1}(\\mathbf{u}_i^2) - \\mathbf{x}_i \\|^2\\tag{5}$$The last one is the consistency loss. Here, we can simply put the $\\ell_2$ loss on the points. Other losses are possible, e.g., image similarity loss, etc.\n$$\\sum_{i \\in C_{1,2}} \\ell_{\\mathbf{T}_0, \\mathbf{T}_1, \\mathbf{T}_2}\\left(\\pi^{-1}(\\mathbf{u}_i^1),\\, \\pi^{-1}(\\mathbf{u}_i^2)\\right) = \\sum_{i\\in C_{1,2}} \\|\\pi^{-1}(\\mathbf{u}_i^1) - \\pi^{-1}(\\mathbf{u}_i^2)\\|^2 \\tag{6}$$Simulations We construct a 8x8 chessboard with each square’s size be of 1m. We set the the origin as the center of the board. We place the board in the world coordinate with extrinsic:\n$$\\begin{pmatrix} 1 \u0026 0 \u0026 0 \u0026 0 \\\\ 0 \u0026 1 \u0026 0 \u0026 0 \\\\ 0 \u0026 0 \u0026 1 \u0026 8 \\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\end{pmatrix} $$which means the normal of the board plane is $[0, 0, 1]^\\top$.\nWe add Gaussian noise on the corners coordinates with noise zero mean and $0.005$ standard deviation.\nWith the noisy corners’ coordinates, we can get the optimized board’s extrinsic according to step 3. The optimized normal is $[1.38*10^{-3}, -2.16*10^{-5}, 9.999*10^{-1}]^\\top$. That is already very close the ground truth.\nThen we simulate two cameras with the same intrinsic matrix: $f_x =800$, $c_x = 500$, $f_y = 800$, $c_y=400$, and $H=800$, $W=1000$. We rotate the first camera along the z-axis $10$ degrees and the second $-10$ degrees, and translate the first camera along the x-axis $2$ meters and the second $-2$ meters. Then the images of the chessboard in the two cameras are shown in the figure below.\nThe original images. Then, we apply Gaussian blur on the observed images and add Gaussian noise on them. The new images are shown in the figure below.\nThe simulated observed images. After that, we use opencv “findChessboardCorners” and find the rough corners and then use “cornerSubPix” to refine the corners’ coordinates. The refined corners are shown in the figure below.\nThe detected corners. Pay attention to the sequence of the detected corners. (The detected corners start from the blue one and end with the green one in the above figure.) Rearrange the detected corners according to the refined chessboard corners. Using the “solvePnP” function with method “SQPNP”, which is a global optimization method, we can find the estimated extrinsic of the two cameras. We record the errors of the estimation using the original measurements of the chessboard corners and the refined ones.\nCamera Corners Rotation Error (degrees) Translation Error (meters) Camera 1 Original 0.260 0.0372 Camera 1 Refined 0.0732 0.0117 Camera 2 Original 0.247 0.0318 Camera 2 Refined 0.0750 0.0118 The translation error is the norm of the difference between the estimated and the ground truth translation. The rotation error is defined as the norm of $\\text{Log}(\\mathbf{R}_1 \\boxminus \\mathbf{R}_2)$.\nAs shown in the table, the refined measurements result in lower errors for both rotation and translation, demonstrating the effectiveness of the corner refinement process.\nIn the final step, we do jointly optimization. We warp the image in camera 1 with parameters before and after jointly optimization. The results are shown in the figure below.\nThe warped images (blended with the image in camera 2) before and after jointly optimization. In the above figure, we can hardly tell which one is better. The translation error is $0.0298$ and $0.0257$ meters for camera 1 and camera 2 respectively. The rotation error is $0.204$ and $0.199$ degrees for camera 1 and camera 2 respectively. That is expected increased error for single camera calibration however more consistent for the two cameras.\nDetect Corners on the Warped Image Corner detection often becomes challenging on original images due to severe distortion or extreme viewing angles. To address this limitation, we can create a virtual camera with an optimized viewpoint. By warping the original image onto this virtual camera’s image plane, we can simulate a more frontal view of the chessboard. This transformation adjusts the perspective so that the chessboard appears as if viewed head-on, significantly improving corner detection reliability. We can then accurately detect the corners on this warped image rather than struggling with the difficult perspective of the original.\nThe figure below illustrates this approach. On the left is the original image where the severe viewing angle prevents the standard algorithm from successfully detecting the corners. On the right is the perspective-corrected warped image, where we can successfully identify and locate all corners.\nLeft shows the original observed image. Right shows the warped image and the detected corners. ","wordCount":"2240","inLanguage":"en","image":"https://livey.github.io/posts/2025-02-eol-calib/%3Cimage%20path/url%3E","datePublished":"2025-02-03T00:00:00Z","dateModified":"2025-02-03T00:00:00Z","author":{"@type":"Person","name":"Fuwei Li"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://livey.github.io/posts/2025-02-eol-calib/"},"publisher":{"@type":"Organization","name":"Fuwei's Tech Notes","logo":{"@type":"ImageObject","url":"https://livey.github.io/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://livey.github.io/ accesskey=h title="Home (Alt + H)"><img src=https://livey.github.io/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://livey.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://livey.github.io/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://livey.github.io/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://livey.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://livey.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">End of Line Camera Calibration</h1><div class=post-description>This post is about end-of-line (EOL) camera calibration, especially for camera bird's-eye view (BEV) extrinsic calibration.</div><div class=post-meta><span title='2025-02-03 00:00:00 +0000 UTC'>February 3, 2025</span>&nbsp;·&nbsp;11 min&nbsp;·&nbsp;2240 words&nbsp;·&nbsp;Fuwei Li&nbsp;|&nbsp;<a href=https://github.com/livey/livey.github.io/issues/new rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#suggested-pipeline aria-label="Suggested Pipeline">Suggested Pipeline</a><ul><li><a href=#refine-the-corners-coordinates-by-the-board-constraints aria-label="Refine the Corner&rsquo;s Coordinates by the Board Constraints">Refine the Corner&rsquo;s Coordinates by the Board Constraints</a><ul><li><a href=#unknown-board-dimension aria-label="Unknown Board Dimension">Unknown Board Dimension</a></li></ul></li><li><a href=#the-intersection-of-the-image-ray-and-board-plane aria-label="The Intersection of the Image Ray and Board Plane">The Intersection of the Image Ray and Board Plane</a></li><li><a href=#solve-the-intersection-problem-as-an-optimization-problem aria-label="Solve the Intersection Problem as an Optimization Problem">Solve the Intersection Problem as an Optimization Problem</a></li><li><a href=#solve-step-3-and-6-jointly-as-a-bundle-adjustment-problem aria-label="Solve Step 3 and 6 Jointly as a Bundle Adjustment Problem">Solve Step 3 and 6 Jointly as a Bundle Adjustment Problem</a></li></ul></li><li><a href=#simulations aria-label=Simulations>Simulations</a><ul><li><a href=#detect-corners-on-the-warped-image aria-label="Detect Corners on the Warped Image">Detect Corners on the Warped Image</a></li></ul></li></ul></div></details></div><div class=post-content><p>In this post, we will discuss the end-of-line (EOL) camera calibration, especially for camera bird&rsquo;s-eye view (BEV) extrinsic calibration.</p><h1 id=suggested-pipeline>Suggested Pipeline<a hidden class=anchor aria-hidden=true href=#suggested-pipeline>#</a></h1><ol><li><p>Do single camera intrinsic calibration</p></li><li><p>Measure each corner in the world coordinate</p></li><li><p>Refine the corners&rsquo; coordinates according to board constraints (plane, parallel, equally spaced)</p></li><li><p>Find the plane equation in the world coordinate</p></li><li><p>Initialize each camera&rsquo;s extrinsic parameters by solving the perspective and point (PnP) problem</p></li><li><p>Estimate the 3D coordinates by the intersection of the image ray and board plane</p></li><li><p>Construct the objective loss function (consistency of different cameras with common seen points and single camera&rsquo;s observation)</p></li></ol><h2 id=refine-the-corners-coordinates-by-the-board-constraints>Refine the Corner&rsquo;s Coordinates by the Board Constraints<a hidden class=anchor aria-hidden=true href=#refine-the-corners-coordinates-by-the-board-constraints>#</a></h2><p>Assume the center of the board is located at the origin of a local coordinate, $(0,0,0)^\top$, the corner coordinate is located at $\{\mathbf{x}_i\}^N_{i=1}$, then the board normal is $(0,0,1)^\top$. Assume the board is transformed to the world coordinate by rotation, $\mathbf{R}$, and translation, $\mathbf{t}$. We have the observed coordinates $\{\hat{\mathbf{y}}_i\}$. Then we minimize the objectives:</p>$$\{\mathbf{y}_i^*, \mathbf{R}^*, \mathbf{t}^*\} = \underset{\mathbf{y}_i,\mathbf{R}, \mathbf{t}}{\arg\min}\sum_i \|\hat{\mathbf{y}}_i -\mathbf{y}_i\|^2\\
\text{s.t. } \mathbf{y}_i = \mathbf{R}\mathbf{x}_i + \mathbf{t} $$<p>This problem can be easily solved since it is a simple <a href=https://livey.github.io/posts/2024-12-icp/>Iterative Closest Point (ICP) problem</a>.</p><p>Then we can get the center of the board as $\mathbf{x}_0=\mathbf{t}^*$, and the normal of the board is $\mathbf{R}^*[0, 0, 1]^\top$.</p><p>Now we have refined board corners in the world coordinates, i.e., $\{\mathbf{y}_i^*\}^N_{i=1}$.</p><h3 id=unknown-board-dimension>Unknown Board Dimension<a hidden class=anchor aria-hidden=true href=#unknown-board-dimension>#</a></h3><p>If we do not have the board dimension, then we can directly fit the plane using the measured corners, $\{\mathbf{x}_i\}^N_{i=1}$ (with a slight abuse of notation). Assume the plane equation is $\mathbf{n}^\top \mathbf{x} - c = 0$ (with unit normal vector, i.e., $\|\mathbf{n}\| = 1$). Then we can solve for $\mathbf{n}$ and $c$ by minimizing the following objective:</p>$$
\underset{\mathbf{n}, c}{\text{argmin}} \frac{1}{N}\sum_i \|\mathbf{n}^\top \mathbf{x}_i - c\|^2 \\
\text{s.t. } \|\mathbf{n}\| = 1
$$<p>For any fixed $\mathbf{n}$, taking derivative with respect to $c$ and setting it to zero, we have:</p>$$
c = \frac{1}{N} \sum_i \mathbf{n}^\top \mathbf{x}_i
= \mathbf{n}^\top \bar{\mathbf{x}}
$$<p>where $\bar{\mathbf{x}} = \frac{1}{N} \sum_i \mathbf{x}_i$ is the mean of the measured corners.</p><p>So, the objective function becomes:</p>$$
\begin{aligned}
&\frac{1}{N}\sum_i \|\mathbf{n}^\top (\mathbf{x}_i - \bar{\mathbf{x}})\|^2 \\
&= \frac{1}{N}\mathbf{n}^\top \left(\sum_i (\mathbf{x}_i - \bar{\mathbf{x}})(\mathbf{x}_i - \bar{\mathbf{x}})^\top\right) \mathbf{n} \\
& = \mathbf{n}^\top \mathbf{\Sigma}_x \mathbf{n}
\end{aligned}
$$<p>where $\mathbf{\Sigma}_x = \frac{1}{N} \sum_i (\mathbf{x}_i - \bar{\mathbf{x}})(\mathbf{x}_i - \bar{\mathbf{x}})^\top$ is the biased sample covariance matrix of the measured corners.</p><p>Considering $\|\mathbf{n}\| = 1$, $\mathbf{n}$ is the eigenvector of $\mathbf{\Sigma}_x$ corresponding to its smallest eigenvalue.</p><p>The refined corners&rsquo; coordinates are the projection of the measured corners on the plane, which can be written as:</p>$$
\mathbf{y}_i = \mathbf{x}_i - \mathbf{n}^\top (\mathbf{x}_i - \bar{\mathbf{x}}) \mathbf{n} = \mathbf{x}_i - (\mathbf{n}^\top\mathbf{x}_i -c)\mathbf{n}.
$$<p>which has clear geometric meaning: the measured corners minus the projection on the plane normal.</p><h2 id=the-intersection-of-the-image-ray-and-board-plane>The Intersection of the Image Ray and Board Plane<a hidden class=anchor aria-hidden=true href=#the-intersection-of-the-image-ray-and-board-plane>#</a></h2><p>We are given a 3D plane:</p>$$\mathbf{n}^\top \mathbf{x} + c = 0,$$<p>and a camera model with the projection equation:</p>$$d\, \mathbf{u} = \mathbf{K} (\mathbf{R}\, \mathbf{x} + \mathbf{t}),$$<p>where:</p><ul><li>$\mathbf{u} \in \mathbb{R}^3$ is the homogeneous image coordinate (usually $\mathbf{u} = [u, v, 1]^\top$)</li><li>$d$ is an unknown scale (depth) factor</li><li>$\mathbf{K}$ is the camera intrinsic matrix</li><li>$\mathbf{R}$ and $\mathbf{t}$ are the rotation and translation (extrinsic parameters) of the camera</li><li>$\mathbf{x} \in \mathbb{R}^3$ is the 3D point we wish to recover</li></ul><p>Our goal is to find $\mathbf{x}$ in terms of the known quantities $\mathbf{u}, \mathbf{K}, \mathbf{R}, \mathbf{t}, \mathbf{n},$ and $c$.</p><p><strong>Rewrite the Projection Equation</strong></p>$$\mathbf{x} = \mathbf{R}^\top \left(d\,\mathbf{K}^{-1} \mathbf{u} - \mathbf{t}\right).$$<p>However, the scale factor $d$ is still unknown.</p><p><strong>Use the Plane Constraint to Solve for $d$</strong></p><p>Since $\mathbf{x}$ lies on the plane, it must satisfy:</p>$$\mathbf{n}^\top \mathbf{x} + c = 0.$$<p>Substitute the expression we just found for $\mathbf{x}$:</p>$$\mathbf{n}^\top \Bigl(\mathbf{R}^\top (d\,\mathbf{K}^{-1} \mathbf{u} - \mathbf{t})\Bigr) + c = 0.$$<p>Because the scalar product is invariant under transposition, we can write:</p><p>Now, solve for $d$:</p>$$d = \frac{\mathbf{n}^\top \mathbf{R}^\top \mathbf{t} - c}{\mathbf{n}^\top \mathbf{R}^\top \mathbf{K}^{-1} \mathbf{u}}.$$<blockquote>$$\mathbf{n}^\top \mathbf{R}^\top \mathbf{K}^{-1} \mathbf{u} \neq 0$$<p>so that the division is valid (this means that the back-projected ray is not parallel to the plane).</p></blockquote><p><strong>Write the Final Expression for $\mathbf{x}$</strong></p><p>Substitute the expression for $d$ back into the equation for $\mathbf{x}$:</p>$$\mathbf{x} = \mathbf{R}^\top \left( \frac{\mathbf{n}^\top \mathbf{R}^\top \mathbf{t} - c}{\mathbf{n}^\top \mathbf{R}^\top \mathbf{K}^{-1} \mathbf{u}}\, \mathbf{K}^{-1} \mathbf{u} - \mathbf{t} \right).$$<h2 id=solve-the-intersection-problem-as-an-optimization-problem>Solve the Intersection Problem as an Optimization Problem<a hidden class=anchor aria-hidden=true href=#solve-the-intersection-problem-as-an-optimization-problem>#</a></h2><p>We wish to solve</p>$$
\min_{\mathbf{x}} \Big\| \mathbf{u} - \frac{\mathbf{R}\mathbf{x} + \mathbf{t}}{\mathbf{e}^\top (\mathbf{R}\mathbf{x} + \mathbf{t})} \Big\|^2\tag{1}
$$<p>subject to the plane constraint</p>$$
\mathbf{n}^\top \mathbf{x} + c = 0,
$$<p>where:
• $\mathbf{R}$ is the rotation matrix,
• $\mathbf{t}$ is the translation vector,
• $\mathbf{n}$ is the normal of the plane,
• $c$ is a constant, and
• $\mathbf{e} = \begin{pmatrix} 0 \ 0 \ 1 \end{pmatrix}$ (which selects the depth coordinate).</p><p>Even when the measured image coordinate $\mathbf{u} \in \mathbb{R}^2$ is noisy, the pinhole camera model combined with the plane constraint induces a projective mapping (a homography) from the plane to the image. In other words, for any $\mathbf{u}$ there exists an entire ray of points $\mathbf{x}$ that project exactly to $\mathbf{u}$. The plane constraint then selects one unique point on that ray.</p><ol><li>Parameterizing the Back‐Projection Ray</li></ol><p>Any 3D point $\mathbf{x}$ whose projection is $\mathbf{u}$ must satisfy</p>$$
\frac{\mathbf{R}\mathbf{x} + \mathbf{t}}{\mathbf{e}^\top (\mathbf{R}\mathbf{x} + \mathbf{t})} =
\begin{pmatrix} \mathbf{u} \\
1
\end{pmatrix}.
$$<p>This implies that there exists a scalar $\lambda$ such that</p>$$
\mathbf{R}\mathbf{x} + \mathbf{t} =
\lambda \begin{pmatrix} \mathbf{u} \\ 1 \end{pmatrix}.
$$<p>Solving for $\mathbf{x}$ gives</p>$$
\mathbf{x} = \mathbf{R}^{-1} \Bigl( \lambda \begin{pmatrix} \mathbf{u} \\ 1 \end{pmatrix} - \mathbf{t} \Bigr).
$$<p>It is convenient to define the camera center in world coordinates as</p>$$
\mathbf{x}_c = -\mathbf{R}^{-1}\mathbf{t},
$$<p>and to introduce the direction vector</p>$$
\mathbf{d} = \mathbf{R}^{-1}\begin{pmatrix} \mathbf{u} \\ 1 \end{pmatrix}.
$$<p>Thus, the 3D point $\mathbf{x}$ can be written as</p>$$
\mathbf{x} = \mathbf{x}_c + \lambda \mathbf{d}.
$$<p>All points of this form project exactly to $\mathbf{u}$, <span style=color:red>which means the optimal value of Eq. (1) is zero</span></p><ol start=2><li>Enforcing the Plane Constraint</li></ol><p>Since $\mathbf{x}$ must lie on the plane, we impose</p>$$
\mathbf{n}^\top \mathbf{x} + c = 0.
$$<p>Substitute $\mathbf{x} = \mathbf{x}_c + \lambda\mathbf{d}$ into the plane equation:</p>$$
\mathbf{n}^\top \Bigl( \mathbf{x}_c + \lambda\mathbf{d} \Bigr) + c = 0.
$$<p>Expanding, we obtain</p>$$
\mathbf{n}^\top \mathbf{x}_c + \lambda \mathbf{n}^\top \mathbf{d} + c = 0.
$$<p>Recalling that $\mathbf{x}_c = -\mathbf{R}^{-1}\mathbf{t}$, the equation becomes</p>$$
\mathbf{n}^\top \mathbf{R}^{-1}\mathbf{t} + \lambda \mathbf{n}^\top \mathbf{d} + c = 0.
$$<p>Solving for $\lambda$, we have</p>$$
\lambda \mathbf{n}^\top \mathbf{d} = \mathbf{n}^\top \mathbf{R}^{-1}\mathbf{t} - c,
$$<p>or equivalently,</p>$$
\lambda = \frac{\mathbf{n}^\top \mathbf{R}^{-1}\mathbf{t} - c}{\mathbf{n}^\top \mathbf{d}} = \frac{\mathbf{n}^\top \mathbf{R}^{-1}\mathbf{t} - c}{\mathbf{n}^\top \mathbf{R}^{-1}\begin{pmatrix} \mathbf{u} \ 1 \end{pmatrix}},
$$<p>provided that $\mathbf{n}^\top \mathbf{d} \neq 0$.</p><ol start=3><li>The Final Solution</li></ol><p>Substitute the value of $\lambda$ back into the expression for $\mathbf{x}$:</p>$$
\mathbf{x} = -\mathbf{R}^{-1}\mathbf{t} + \frac{\mathbf{n}^\top \mathbf{R}^{-1}\mathbf{t} - c}{\mathbf{n}^\top \mathbf{R}^{-1}\begin{pmatrix} \mathbf{u} \\ 1 \end{pmatrix}} \mathbf{R}^{-1}\begin{pmatrix} \mathbf{u} \\ 1 \end{pmatrix}.
$$<p>This is the unique 3D point on the plane $\mathbf{n}^\top \mathbf{x} + c = 0$ that minimizes the reprojection error, even when $\mathbf{u}$ is noisy.</p><ol start=4><li>Summary</li></ol><p>a. Back‐Projection: The projection model</p>$$
\mathbf{x} \mapsto \frac{\mathbf{R}\mathbf{x} + \mathbf{t}}{\mathbf{e}^\top (\mathbf{R}\mathbf{x} + \mathbf{t})}
$$<p>is a homography when restricted to the plane. Hence, every point along the ray</p>$$
\mathcal{R}(\mathbf{u}) = \Bigl\{ \mathbf{x} = -\mathbf{R}^{-1}\mathbf{t} + \lambda \mathbf{R}^{-1}\begin{pmatrix} \mathbf{u} \\ 1 \end{pmatrix} : \lambda \in \mathbb{R} \Bigr\}
$$<p>projects to $\mathbf{u}$.</p><p>b. Plane Intersection: The plane constraint $\mathbf{n}^\top \mathbf{x} + c = 0$ uniquely determines the scalar $\lambda$, and hence the unique point $\mathbf{x}$.</p><p>Thus, the final answer is</p>$$
\boxed{
\mathbf{x} = -\mathbf{R}^{-1}\mathbf{t} + \frac{\mathbf{n}^\top \mathbf{R}^{-1}\mathbf{t} - c}{\mathbf{n}^\top \mathbf{R}^{-1}\begin{pmatrix} \mathbf{u} \\ 1 \end{pmatrix}} \mathbf{R}^{-1}\begin{pmatrix} \mathbf{u} \\ 1 \end{pmatrix}.
}
$$<h2 id=solve-step-3-and-6-jointly-as-a-bundle-adjustment-problem>Solve Step 3 and 6 Jointly as a Bundle Adjustment Problem<a hidden class=anchor aria-hidden=true href=#solve-step-3-and-6-jointly-as-a-bundle-adjustment-problem>#</a></h2><p>Suppose the board&rsquo;s markers coordinate in the board&rsquo;s frame are $\{ \mathbf{x}_i^g \}_{i=1}^N$ in the board&rsquo;s frame. The measured marker points in the world frame are $\{ \mathbf{x}_i^o \}_{i=1}^N$. The observed image markers in camera 1 are $\{ \mathbf{u}_i^1 \}_{i=1}^{N_1}$ and the observed image markers in the second camera are $\{ \mathbf{u}_i^2 \}_{i=1}^{N_2}$.</p><p>We construct the loss as:</p>$$
\begin{aligned}
\mathcal{L}
&= 
\sum_i \ell_{\mathbf{T}_0, \mathbf{x}_i} (\mathbf{x}_i^g, \mathbf{x}_i)
+
\sum_i \ell_{\mathbf{x}_i} (\mathbf{x}_i^o, \mathbf{x}_i) \\
& +
\sum_i \ell_{\mathbf{x}_i, \mathbf{T}_0, \mathbf{T}_1} \Big( \pi^{-1}(\mathbf{u}_i^1), \mathbf{x}_i \Big)
+
\sum_i \ell_{\mathbf{x}_i, \mathbf{T}_0, \mathbf{T}_2} \Big( \pi^{-1}(\mathbf{u}_i^2), \mathbf{x}_i \Big) \\
&+
\sum_{i \in C_{1,2}} \ell_{\mathbf{T}_0, \mathbf{T}_1, \mathbf{T}_2} \Big( \pi^{-1}(\mathbf{u}_i^1), \pi^{-1}(\mathbf{u}_i^2) \Big)
\end{aligned}
$$<p>Where:</p><ul><li>the transformation from the local board to the world board, $\mathbf{T}_0$;</li><li>The world coordinates of the board, $\{\mathbf{x}_i\}$;</li><li>The transformation from the cameras to the world board, $\mathbf{T}_i$, where $i = 1, 2$;</li><li>$C_{1,2}$ is the marker set commonly seen by camera 1 and camera 2;</li><li>$\pi(\cdot)$ is the intersection of the camera ray and the world plane.</li></ul><p>In the first part, we put a hard constraint that the true 3D position of the points should be a rigid transformation of the board.</p>$$\sum_i \ell_{\mathbf{T}_0, \mathbf{x}_i}(\mathbf{x}_i^g, \mathbf{x}_i) = \sum_i I_{\infty}(\mathbf{x}_i - \mathbf{T}_0 \mathbf{x}_i^g)\tag{2}$$<p>where $I_\infty(x)=
\begin{cases}
0, \text{ if } x=0, \\
\infty, \text{otherwise}
\end{cases}$.</p><p>The second part of the loss is the difference between the observations of 3D points and the true position.</p>$$\sum_i \ell_{\mathbf{x}_i}(\mathbf{x}_i, \mathbf{x}_i^o) = \sum_i \|\mathbf{x}_i - \mathbf{x}_i^o\|^2 \tag{3}$$<p>The third part is the perspective and point loss</p>$$\sum_{i\in C_1} \ell_{\mathbf{x}_i, \mathbf{T}_0,\mathbf{T}_1}\left(\pi^{-1}(\mathbf{u}_i^1), \mathbf{x}_i \right) = \sum_{i\in C_1} \| \pi^{-1}(\mathbf{u}_i^1) - \mathbf{x}_i \|^2\tag{4}$$$$\sum_{i\in C_2} \ell_{\mathbf{x}_i, \mathbf{T}_0,\mathbf{T}_2}\left(\pi^{-1}(\mathbf{u}_i^2), \mathbf{x}_i \right) = \sum_{i\in C_2} \| \pi^{-1}(\mathbf{u}_i^2) - \mathbf{x}_i \|^2\tag{5}$$<p>The last one is the consistency loss. Here, we can simply put the $\ell_2$ loss on the points. Other losses are possible, e.g., image similarity loss, etc.</p>$$\sum_{i \in C_{1,2}}
\ell_{\mathbf{T}_0, \mathbf{T}_1, \mathbf{T}_2}\left(\pi^{-1}(\mathbf{u}_i^1),\, \pi^{-1}(\mathbf{u}_i^2)\right) =
\sum_{i\in C_{1,2}} \|\pi^{-1}(\mathbf{u}_i^1) - \pi^{-1}(\mathbf{u}_i^2)\|^2 \tag{6}$$<h1 id=simulations>Simulations<a hidden class=anchor aria-hidden=true href=#simulations>#</a></h1><p>We construct a 8x8 chessboard with each square&rsquo;s size be of 1m. We set the the origin as the center of the board. We place the board in the world coordinate with extrinsic:</p>$$\begin{pmatrix}
1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 & 1 & 8 \\ 0 & 0 & 0 & 1 
\end{pmatrix}
$$<p>which means the normal of the board plane is $[0, 0, 1]^\top$.</p><p>We add Gaussian noise on the corners coordinates with noise zero mean and $0.005$ standard deviation.</p><p>With the noisy corners&rsquo; coordinates, we can get the optimized board&rsquo;s extrinsic according to step 3. The optimized normal is $[1.38*10^{-3}, -2.16*10^{-5}, 9.999*10^{-1}]^\top$. That is already very close the ground truth.</p><p>Then we simulate two cameras with the same intrinsic matrix: $f_x =800$, $c_x = 500$, $f_y = 800$, $c_y=400$, and $H=800$, $W=1000$.
We rotate the first camera along the z-axis $10$ degrees and the second $-10$ degrees, and translate the first camera along the x-axis $2$ meters and the second $-2$ meters. Then the images of the chessboard in the two cameras are shown in the figure below.</p><figure style=text-align:center><img src=./resources/original_observed.png alt="original observe" style="width:100%;margin:0 auto;display:block"><figcaption style=font-weight:400>The original images.</figcaption></figure><p>Then, we apply Gaussian blur on the observed images and add Gaussian noise on them. The new images are shown in the figure below.</p><figure style=text-align:center><img src=./resources/noise_observed.png alt="blur observe" style="width:100%;margin:0 auto;display:block"><figcaption style=font-weight:400>The simulated observed images.</figcaption></figure><p>After that, we use opencv &ldquo;findChessboardCorners&rdquo; and find the rough corners and then use &ldquo;cornerSubPix&rdquo; to refine the corners&rsquo; coordinates. The refined corners are shown in the figure below.</p><figure style=text-align:center><img src=./resources/chess_corners_observed.png alt="refined corners" style="width:100%;margin:0 auto;display:block"><figcaption style=font-weight:400>The detected corners.</figcaption></figure><p>Pay attention to the sequence of the detected corners. (The detected corners start from the blue one and end with the green one in the above figure.) Rearrange the detected corners according to the refined chessboard corners. Using the &ldquo;solvePnP&rdquo; function with method &ldquo;SQPNP&rdquo;, which is a global optimization method, we can find the estimated extrinsic of the two cameras. We record the errors of the estimation using the original measurements of the chessboard corners and the refined ones.</p><table><thead><tr><th>Camera</th><th>Corners</th><th>Rotation Error (degrees)</th><th>Translation Error (meters)</th></tr></thead><tbody><tr><td>Camera 1</td><td>Original</td><td>0.260</td><td>0.0372</td></tr><tr><td>Camera 1</td><td>Refined</td><td>0.0732</td><td>0.0117</td></tr><tr><td>Camera 2</td><td>Original</td><td>0.247</td><td>0.0318</td></tr><tr><td>Camera 2</td><td>Refined</td><td>0.0750</td><td>0.0118</td></tr></tbody></table><p>The translation error is the norm of the difference between the estimated and the ground truth translation. The rotation error is defined as the norm of $\text{Log}(\mathbf{R}_1 \boxminus \mathbf{R}_2)$.</p><p>As shown in the table, the refined measurements result in lower errors for both rotation and translation, demonstrating the effectiveness of the corner refinement process.</p><p>In the final step, we do jointly optimization. We warp the image in camera 1 with parameters before and after jointly optimization. The results are shown in the figure below.</p><figure style=text-align:center><img src=./resources/optimized_warped_image.png alt="The warped images using before and after jointly optimization" style="width:100%;margin:0 auto;display:block"><figcaption style=font-weight:400>The warped images (blended with the image in camera 2) before and after jointly optimization.</figcaption></figure><p>In the above figure, we can hardly tell which one is better. The translation error is $0.0298$ and $0.0257$ meters for camera 1 and camera 2 respectively. The rotation error is $0.204$ and $0.199$ degrees for camera 1 and camera 2 respectively. That is expected increased error for single camera calibration however more consistent for the two cameras.</p><h2 id=detect-corners-on-the-warped-image>Detect Corners on the Warped Image<a hidden class=anchor aria-hidden=true href=#detect-corners-on-the-warped-image>#</a></h2><p>Corner detection often becomes challenging on original images due to severe distortion or extreme viewing angles. To address this limitation, we can create a virtual camera with an optimized viewpoint. By warping the original image onto this virtual camera&rsquo;s image plane, we can simulate a more frontal view of the chessboard. This transformation adjusts the perspective so that the chessboard appears as if viewed head-on, significantly improving corner detection reliability. We can then accurately detect the corners on this warped image rather than struggling with the difficult perspective of the original.</p><p>The figure below illustrates this approach. On the left is the original image where the severe viewing angle prevents the standard algorithm from successfully detecting the corners. On the right is the perspective-corrected warped image, where we can successfully identify and locate all corners.</p><figure style=text-align:center><img src=./resources/warped_image_corners.png alt="The original and warped images" style="width:100%;margin:0 auto;display:block"><figcaption style=font-weight:400>Left shows the original observed image. Right shows the warped image and the detected corners.</figcaption></figure></div><footer class=post-footer><ul class=post-tags><li><a href=https://livey.github.io/tags/autonomous-driving/>Autonomous Driving</a></li><li><a href=https://livey.github.io/tags/camera-calibration/>Camera Calibration</a></li><li><a href=https://livey.github.io/tags/eol/>EOL</a></li><li><a href=https://livey.github.io/tags/bev/>BEV</a></li></ul><nav class=paginav><a class=prev href=https://livey.github.io/posts/2025-02-07-coordinate/><span class=title>« Prev</span><br><span>Coordinate Systems</span>
</a><a class=next href=https://livey.github.io/posts/2024-12-3dgs/><span class=title>Next »</span><br><span>3D Gaussian Splatting</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share End of Line Camera Calibration on x" href="https://x.com/intent/tweet/?text=End%20of%20Line%20Camera%20Calibration&amp;url=https%3a%2f%2flivey.github.io%2fposts%2f2025-02-eol-calib%2f&amp;hashtags=AutonomousDriving%2cCameraCalibration%2cEOL%2cBEV"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share End of Line Camera Calibration on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2flivey.github.io%2fposts%2f2025-02-eol-calib%2f&amp;title=End%20of%20Line%20Camera%20Calibration&amp;summary=End%20of%20Line%20Camera%20Calibration&amp;source=https%3a%2f%2flivey.github.io%2fposts%2f2025-02-eol-calib%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share End of Line Camera Calibration on reddit" href="https://reddit.com/submit?url=https%3a%2f%2flivey.github.io%2fposts%2f2025-02-eol-calib%2f&title=End%20of%20Line%20Camera%20Calibration"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share End of Line Camera Calibration on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2flivey.github.io%2fposts%2f2025-02-eol-calib%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share End of Line Camera Calibration on whatsapp" href="https://api.whatsapp.com/send?text=End%20of%20Line%20Camera%20Calibration%20-%20https%3a%2f%2flivey.github.io%2fposts%2f2025-02-eol-calib%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share End of Line Camera Calibration on telegram" href="https://telegram.me/share/url?text=End%20of%20Line%20Camera%20Calibration&amp;url=https%3a%2f%2flivey.github.io%2fposts%2f2025-02-eol-calib%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share End of Line Camera Calibration on ycombinator" href="https://news.ycombinator.com/submitlink?t=End%20of%20Line%20Camera%20Calibration&u=https%3a%2f%2flivey.github.io%2fposts%2f2025-02-eol-calib%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://livey.github.io/>Fuwei's Tech Notes</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>
<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Perspective-n-Point (PnP) Problem | Fuwei's Tech Notes</title>
<meta name=keywords content="Signal Processing,Calibration,Autonomous Driving,Perspective-n-Point,PnP,Perspective-n-Point Problem"><meta name=description content="An introduction to the Perspective-n-Point (PnP) problem."><meta name=author content="Fuwei Li"><link rel=canonical href=https://livey.github.io><link crossorigin=anonymous href=/assets/css/stylesheet.d6fcd20a4fb86efa4dfac8ec95da60244cc8871042183da1ef28e3a762ad79c8.css integrity="sha256-1vzSCk+4bvpN+sjsldpgJEzIhxBCGD2h7yjjp2Ktecg=" rel="preload stylesheet" as=style><link rel=icon href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://livey.github.io/posts/2025-05-15-pnp/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="index, follow"><meta name=author content="Fuwei Li"><meta name=description content="An introduction to the Perspective-n-Point (PnP) problem."><meta property="og:type" content="article"><meta property="og:url" content="https://livey.github.io/posts/2025-05-15-pnp/"><meta property="og:title" content="Perspective-n-Point (PnP) Problem"><meta property="og:description" content="An introduction to the Perspective-n-Point (PnP) problem."><meta property="og:image" content="https://livey.github.io/images/site-preview.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="Perspective-n-Point (PnP) Problem"><meta name=twitter:description content="An introduction to the Perspective-n-Point (PnP) problem."><meta name=twitter:image content="https://livey.github.io/images/site-preview.jpg"><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css integrity=sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js integrity=sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><meta property="og:url" content="https://livey.github.io/posts/2025-05-15-pnp/"><meta property="og:site_name" content="Fuwei's Tech Notes"><meta property="og:title" content="Perspective-n-Point (PnP) Problem"><meta property="og:description" content="An introduction to the Perspective-n-Point (PnP) problem."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-07-19T00:00:00+00:00"><meta property="article:modified_time" content="2025-07-19T00:00:00+00:00"><meta property="article:tag" content="Signal Processing"><meta property="article:tag" content="Calibration"><meta property="article:tag" content="Autonomous-Driving"><meta property="article:tag" content="Perspective-N-Point"><meta property="article:tag" content="PnP"><meta property="article:tag" content="Perspective-N-Point Problem"><meta property="og:image" content="https://livey.github.io/posts/2025-05-15-pnp/%3Cimage%20path/url%3E"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://livey.github.io/posts/2025-05-15-pnp/%3Cimage%20path/url%3E"><meta name=twitter:title content="Perspective-n-Point (PnP) Problem"><meta name=twitter:description content="An introduction to the Perspective-n-Point (PnP) problem."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://livey.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Perspective-n-Point (PnP) Problem","item":"https://livey.github.io/posts/2025-05-15-pnp/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Perspective-n-Point (PnP) Problem","name":"Perspective-n-Point (PnP) Problem","description":"An introduction to the Perspective-n-Point (PnP) problem.","keywords":["Signal Processing","Calibration","Autonomous Driving","Perspective-n-Point","PnP","Perspective-n-Point Problem"],"articleBody":"In this post, we will discuss the perspective-n-point (PnP) problem. We will start with the problem definition. Then, gradient-based optimization methods will be introduced. Finally, we will discuss two global optimization methods.\nProblem Formulation The core task of the Perspective-n-Point (PnP) problem is to determine the pose—specifically, the rotation and translation—of a calibrated camera in 3D space. This is achieved by using a set of known 3D points in the world and their corresponding 2D projections observed on the camera’s image sensor.\nGoal Given a set of n 3D points and their 2D image projections, the goal is to compute the rotation R and translation t of the camera, which together define its pose. This pose describes the transformation from the world coordinate system to the camera’s coordinate system.\nKnowns (Inputs) A set of n 3D points in the world coordinate frame:\n$$ P_i = (X_i, Y_i, Z_i)^T \\quad \\text{for } i = 1, \\dots, n $$ Corresponding 2D projections of these points on the image plane:\n$$ p_i = (u_i, v_i)^T \\quad \\text{for } i = 1, \\dots, n $$ The camera intrinsic matrix K, which is known because the camera is assumed to be calibrated. For modern cameras, we can assume there is no skew, so the matrix simplifies to:\n$$ K = \\begin{pmatrix} f_x \u0026 0 \u0026 c_x \\\\ 0 \u0026 f_y \u0026 c_y \\\\ 0 \u0026 0 \u0026 1 \\end{pmatrix} $$where $(f_x, f_y)$ are the focal lengths in pixels and $(c_x, c_y)$ is the principal point.\nUnknowns (Outputs) The rotation matrix R (a 3x3 matrix), which defines the camera’s orientation. The translation vector t (a 3x1 vector), which defines the camera’s position. Mathematical Formulation The relationship between a 3D world point $P_i$ and its 2D image projection $p_i$ is described by the pinhole camera model:\n$$ s_i \\begin{pmatrix} u_i \\\\ v_i \\\\ 1 \\end{pmatrix} = K [R | t] \\begin{pmatrix} X_i \\\\ Y_i \\\\ Z_i \\\\ 1 \\end{pmatrix} = K (R P_i + t) $$Here, $s_i$ is a non-zero scale factor representing the depth of the point in the camera’s coordinate frame. To see how $s_i$ is determined, let’s expand the term $R P_i + t$. If we denote the rows of the rotation matrix $\\mathbf{R}$ as $r_1^T, r_2^T, r_3^T$, then the transformed point in the camera frame is:\n$$ R P_i + t = \\begin{pmatrix} r_1^T P_i + t_1 \\\\ r_2^T P_i + t_2 \\\\ r_3^T P_i + t_3 \\end{pmatrix} $$From the projection equation, the depth $s_i$ is the third component of this vector:\n$$ s_i = r_3^T P_i + t_3 $$Crucially, this shows that $s_i$ is not an independent variable to be solved for; it is implicitly determined by the pose $(\\mathbf{R}, \\mathbf{t})$ and the 3D point $P_i$.\nThe PnP problem is typically formulated as a non-linear optimization problem. We seek the rotation $\\mathbf{R}$ and translation $\\mathbf{t}$ that minimize the reprojection error. This error is the sum of squared distances between the observed 2D points $p_i$ and the projected 2D points $\\hat{p}_i$, which are calculated by projecting the 3D points $P_i$ using the estimated pose $(\\mathbf{R}, \\mathbf{t})$.\nThe objective function to minimize is:\n$$ \\underset{\\mathbf{R}, \\mathbf{t}}{\\text{argmin}} \\sum_{i=1}^{n} \\left\\| p_i - \\hat{p}_i(\\mathbf{R}, \\mathbf{t}, P_i) \\right\\|^2 $$subject to the constraint that $\\mathbf{R}$ is a valid rotation matrix:\n$$ \\mathbf{R}^T \\mathbf{R} = I, \\quad \\det(\\mathbf{R}) = 1 $$Gradient-Based Optimization Methods Since the PnP objective function is a non-linear least squares problem, it is well-suited to be solved with iterative optimization methods like Gauss-Newton or Levenberg-Marquardt. These algorithms start with an initial guess for the pose $(\\mathbf{R}, \\mathbf{t})$ and iteratively refine it by solving a linearized version of the problem at each step until the solution converges.\nThe core of this process is to compute the Jacobian of the residual function with respect to the pose parameters. The residual for a single point $i$ is the reprojection error:\n$$ r_i(\\mathbf{R}, \\mathbf{t}) = p_i - \\hat{p}_i(\\mathbf{R}, \\mathbf{t}, P_i) $$We need to find the derivative of this residual to update our pose estimate.\nThe Challenge with Differentiating Rotation A standard gradient cannot be directly computed for the rotation matrix $\\mathbf{R}$. This is because rotation matrices belong to a special mathematical group called the special orthogonal group SO(3). This is a manifold, not a simple vector space, so the rules of standard calculus don’t apply. Adding two rotation matrices, for example, does not produce another rotation matrix.\nTo solve this, we optimize over a minimal 6-dimensional representation of the camera pose. This is done by parameterizing the updates in the Lie algebra associated with the pose group.\nLie Group SE(3): The camera pose (rotation $\\mathbf{R}$ and translation $\\mathbf{t}$) belongs to the special Euclidean group SE(3).\n$$ \\xi = (\\omega^\\top, v^\\top)^T $$ Here, $\\omega$ is a 3-vector representing an infinitesimal rotation, and $v$ is a 3-vector representing an infinitesimal translation.\nPerturbation: Instead of updating $\\mathbf{R}$ and $\\mathbf{t}$ directly, we apply a small perturbation $\\delta\\xi$ to the current pose estimate. The pose is updated using the exponential map, which maps an element from the Lie algebra back to the Lie group:\n$$ \\mathbf{T}_{\\text{new}} = \\exp(\\delta\\xi^\\wedge) \\mathbf{T}_{\\text{old}} $$where $\\mathbf{T}$ is the 4x4 transformation matrix and $\\delta\\xi^\\wedge$ is the matrix representation of the Lie algebra vector.\nThis allows us to perform the optimization in a standard vector space (the 6D space of $\\delta\\xi$) while ensuring that the updated rotation matrix $\\mathbf{R}$ remains a valid element of SO(3).\nDeriving the Jacobian Our goal is to compute the Jacobian of the residual $r_i$ with respect to the 6-vector perturbation $\\delta\\xi = (\\delta\\omega^\\top, \\delta v^\\top)^\\top$, where $\\delta\\omega$ is the rotational part and $\\delta v$ is the translational part. We apply the chain rule.\nFirst, let $P'_i = \\mathbf{R} P_i + \\mathbf{t}$ be the 3D point $P_i$ transformed into the camera’s coordinate frame. The projection function is:\n$$ \\hat{p}_i = \\text{proj}(P'_i) = \\begin{pmatrix} f_x \\frac{X'_i}{Z'_i} + c_x \\\\ f_y \\frac{Y'_i}{Z'_i} + c_y \\end{pmatrix} $$The chain rule gives us:\n$$ J_i = \\frac{\\partial r_i}{\\partial \\delta\\xi} = - \\frac{\\partial \\hat{p}_i}{\\partial P'_i} \\frac{\\partial P'_i}{\\partial \\delta\\xi} $$This breaks the problem into three parts:\n1. Jacobian of the Projection Function\nThis is the derivative of the projection function with respect to the 3D point in the camera frame $P'_i = (X'_i, Y'_i, Z'_i)^T$. This is a standard 2x3 matrix, which remains unchanged:\n$$ \\begin{aligned} \\frac{\\partial \\hat{p}_i}{\\partial P'_i} \u0026= \\begin{bmatrix} \\frac{\\partial u_i}{\\partial X'_i} \u0026 \\frac{\\partial u_i}{\\partial Y'_i} \u0026 \\frac{\\partial u_i}{\\partial Z'_i} \\\\ \\frac{\\partial v_i}{\\partial X'_i} \u0026 \\frac{\\partial v_i}{\\partial Y'_i} \u0026 \\frac{\\partial v_i}{\\partial Z'_i} \\end{bmatrix} \\\\ \u0026= \\begin{bmatrix} \\frac{f_x}{Z'_i} \u0026 0 \u0026 -\\frac{f_x X'_i}{(Z'_i)^2} \\\\ 0 \u0026 \\frac{f_y}{Z'_i} \u0026 -\\frac{f_y Y'_i}{(Z'_i)^2} \\end{bmatrix} \\end{aligned} $$2. Derivation of the Transformation Jacobian\nThis section provides a step-by-step derivation of how a small pose perturbation affects a 3D point in the camera’s coordinate frame, leading to the Jacobian of the transformation.\nA camera’s pose is a rigid body transformation, which can be represented by a 4x4 matrix $\\mathbf{T} \\in SE(3)$. This matrix transforms a 3D point $P_i$ from world coordinates to camera coordinates, $P'_i$.\n$$ \\begin{pmatrix} P'_i \\\\ 1 \\end{pmatrix} = \\mathbf{T} \\begin{pmatrix} P_i \\\\ 1 \\end{pmatrix} $$We apply a small perturbation to this pose. This “wiggle” is represented by a 6D vector $\\delta\\xi = (\\delta\\omega^\\top, \\delta v^\\top)^\\top$ from the Lie algebra se(3). To apply this to the pose, we use the exponential map:\n$$ \\mathbf{T}_{\\text{new}} = \\exp(\\delta\\xi^\\wedge) \\mathbf{T}_{\\text{old}} $$For a very small perturbation, we can use the first-order Taylor approximation of the exponential map: $\\exp(\\delta\\xi^\\wedge) \\approx \\mathbf{I} + \\delta\\xi^\\wedge$. This is the key step that linearizes the problem.\n$$ \\begin{aligned} \\begin{pmatrix} P'_{i, \\text{new}} \\\\ 1 \\end{pmatrix} \u0026= \\mathbf{T}_{\\text{new}} \\begin{pmatrix} P_i \\\\ 1 \\end{pmatrix} \\\\ \u0026\\approx (\\mathbf{I} + \\delta\\xi^\\wedge) \\mathbf{T}_{\\text{old}} \\begin{pmatrix} P_i \\\\ 1 \\end{pmatrix} \\end{aligned} $$We can recognize that $\\mathbf{T}_{\\text{old}} \\begin{pmatrix} P_i \\\\ 1 \\end{pmatrix}$ is simply the homogeneous representation of the point already in the camera frame, $\\begin{pmatrix} P'_i \\\\ 1 \\end{pmatrix}$. This allows for a crucial substitution:\n$$ \\begin{pmatrix} P'_{i, \\text{new}} \\\\ 1 \\end{pmatrix} \\approx (\\mathbf{I} + \\delta\\xi^\\wedge) \\begin{pmatrix} P'_i \\\\ 1 \\end{pmatrix} $$This shows that we can calculate the new point by applying the perturbation directly to the old point in the camera frame. Let’s expand the matrix multiplication. The 4x4 matrix form of the perturbation is $\\delta\\xi^\\wedge = \\begin{pmatrix} \\delta\\omega^\\wedge \u0026 \\delta v \\\\ \\mathbf{0} \u0026 0 \\end{pmatrix}$.\n$$ \\begin{aligned} \\begin{pmatrix} P'_{i, \\text{new}} \\\\ 1 \\end{pmatrix} \u0026\\approx \\begin{pmatrix} \\mathbf{I} + \\delta\\omega^\\wedge \u0026 \\delta v \\\\ \\mathbf{0} \u0026 1 \\end{pmatrix} \\begin{pmatrix} P'_i \\\\ 1 \\end{pmatrix} \\\\ \u0026= \\begin{pmatrix} (\\mathbf{I} + \\delta\\omega^\\wedge)P'_i + \\delta v \\\\ 1 \\end{pmatrix} \\end{aligned} $$Converting back to non-homogeneous 3D coordinates, we get the final expression for the perturbed point:\n$$ P'_{i, \\text{new}} \\approx (\\mathbf{I} + \\delta\\omega^\\wedge)P'_i + \\delta v = P'_i + \\delta\\omega^\\wedge P'_i + \\delta v $$Using the cross-product identity $\\delta\\omega^\\wedge P'_i = -(P'_i)^\\wedge \\delta\\omega$, we arrive at the equation used for the derivative calculation:\n$$ P'_{i, \\text{new}} \\approx P'_i - (P'_i)^\\wedge \\delta\\omega + \\delta v $$From this equation, we can directly compute the partial derivatives with respect to the perturbation components $\\delta\\omega$ and $\\delta v$, which form the columns of our 3x6 Jacobian matrix.\n3. The Final Jacobian Matrices\nCombining these parts gives the final Jacobians. The Jacobian of the transformation is now constructed with the rotation component first:\n$$ \\frac{\\partial P'_i}{\\partial \\delta\\xi} = \\begin{bmatrix} \\frac{\\partial P'_{i}}{\\partial \\delta\\omega} \u0026 \\frac{\\partial P'_{i}}{\\partial \\delta v} \\end{bmatrix}= \\begin{bmatrix} -(P'_i)^\\wedge \u0026 \\mathbf{I} \\end{bmatrix}= \\begin{bmatrix} 0 \u0026 Z'_i \u0026 -Y'_i \u0026 1 \u0026 0 \u0026 0 \\\\ -Z'_i \u0026 0 \u0026 X'_i \u0026 0 \u0026 1 \u0026 0 \\\\ Y'_i \u0026 -X'_i \u0026 0 \u0026 0 \u0026 0 \u0026 1 \\end{bmatrix} $$And the complete Jacobian of the residual for a single point is:\n$$ J_i = - \\frac{\\partial \\hat{p}_i}{\\partial P'_i} \\frac{\\partial P'_i}{\\partial \\delta\\xi} $$The Optimization Loop There are various gradient-based optimization methods. Here we will introduce the Gauss-Newton algorithm.\nThe Gauss-Newton algorithm proceeds as follows:\nInitialize: Start with an initial guess for the pose $(\\mathbf{R}_0, \\mathbf{t}_0)$.\nIterate: For each iteration $k$:\na. For every point $i$, compute the residual $r_i(\\mathbf{R}_k, \\mathbf{t}_k)$ and the Jacobian $J_i$.\nb. Construct the overall linear system:\n$$ \\left( \\sum_i J_i^T J_i \\right) \\delta\\xi = - \\sum_i J_i^T r_i $$c. Solve for the 6D update vector $\\delta\\xi = (\\delta\\omega^\\top, \\delta v^\\top)^\\top$.\nd. Update the pose using the exponential map:\n$$ \\mathbf{R}_{k+1} = \\exp(\\delta\\omega^\\wedge) \\mathbf{R}_k \\\\ \\mathbf{t}_{k+1} = \\mathbf{t}_k + \\delta v $$ Terminate: Repeat until the update $\\delta\\xi$ is very small or a maximum number of iterations is reached.\nGlobal Optimization Methods While gradient-based methods are effective, they can get stuck in local minima, especially if the initial guess is poor. Global optimization methods aim to find the single best solution worldwide by reformulating the problem in a way that avoids this issue.\nThe DLS Method (Zheng et al., 2013 [1]) Another foundational approach to global optimization is the Direct Least Squares (DLS) method [1]. This technique tackles the problem by directly finding all the stationary points of the objective function, one of which must be the global minimum.\nKKT Conditions: The method starts with the Karush-Kuhn-Tucker (KKT) conditions, which are the necessary conditions for a solution to be optimal in a constrained optimization problem. Polynomial System: The KKT conditions are transformed into a system of multivariate polynomial equations. Gröbner Basis Solvers: A powerful algebraic geometry tool, the Gröbner basis, is used to solve this system of polynomial equations. This yields a finite number of candidate solutions (stationary points). Global Minimum Selection: Finally, the algorithm evaluates the original objective function for each of these candidate solutions and selects the one with the lowest reprojection error, which is guaranteed to be the global optimum. The DLS method provides a strong theoretical guarantee of optimality and has inspired numerous follow-up works that have improved its speed and stability.\nThe SQPnP Method (Terzakis \u0026 Lourakis, 2020 [2]) One of the leading modern approaches is the SQPnP (Sequential Quadratic Programming for PnP) algorithm [2]. This method offers a consistently fast and globally optimal solution. Its core innovations are:\nQuadratic Programming Formulation: The PnP problem is reformulated as a non-linear quadratic program. The objective function is designed to be quadratic, and the rotation constraint ($\\mathbf{R}^T \\mathbf{R} = I$) is also expressed using quadratic equations. Parameter Space Decomposition: The algorithm cleverly divides the parameter space of possible rotations into a finite number of regions. It provides a guarantee that at least one of these regions contains the global minimum. Sequential Quadratic Programming: Within each of these identified regions, a fast and efficient Sequential Quadratic Programming (SQP) scheme is used to find the unique regional minimum. Global Optimum Guarantee: By comparing the minima found in each region, the algorithm can identify the true global minimum with certainty. A key advantage of SQPnP is its efficiency and robustness. It works for any number of points ($n \\ge 3$), is not affected by coplanar point arrangements, and has been integrated into popular libraries like OpenCV, making it a go-to choice for practical applications.\nReferences [1] Y. Zheng, Y. Kuang, S. Sugimoto, K. Astrom, and M. Okutomi, “Revisiting the PnP problem: A fast, general and optimal solution,” in 2013 IEEE International Conference on Computer Vision, Sydney, Australia: IEEE, Dec. 2013, pp. 2344–2351. doi: 10.1109/ICCV.2013.291.\n[2] G. Terzakis, M. Lourakis, “A consistently fast and globally optimal solution to the perspective-n-point problem,” in Computer Vision – ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part I, 2020, pp. 478–494.\n","wordCount":"2209","inLanguage":"en","image":"https://livey.github.io/posts/2025-05-15-pnp/%3Cimage%20path/url%3E","datePublished":"2025-07-19T00:00:00Z","dateModified":"2025-07-19T00:00:00Z","author":{"@type":"Person","name":"Fuwei Li"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://livey.github.io/posts/2025-05-15-pnp/"},"publisher":{"@type":"Organization","name":"Fuwei's Tech Notes","logo":{"@type":"ImageObject","url":"https://livey.github.io/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://livey.github.io/ accesskey=h title="Home (Alt + H)"><img src=https://livey.github.io/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://livey.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://livey.github.io/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://livey.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://livey.github.io/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://livey.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://livey.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Perspective-n-Point (PnP) Problem</h1><div class=post-description>An introduction to the Perspective-n-Point (PnP) problem.</div><div class=post-meta><span title='2025-07-19 00:00:00 +0000 UTC'>July 19, 2025</span>&nbsp;·&nbsp;11 min&nbsp;·&nbsp;2209 words&nbsp;·&nbsp;Fuwei Li&nbsp;|&nbsp;<a href=https://github.com/livey/livey.github.io/issues/new rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#problem-formulation aria-label="Problem Formulation">Problem Formulation</a><ul><ul><li><a href=#goal aria-label=Goal>Goal</a></li><li><a href=#knowns-inputs aria-label="Knowns (Inputs)">Knowns (Inputs)</a></li><li><a href=#unknowns-outputs aria-label="Unknowns (Outputs)">Unknowns (Outputs)</a></li><li><a href=#mathematical-formulation aria-label="Mathematical Formulation">Mathematical Formulation</a></li></ul></ul></li><li><a href=#gradient-based-optimization-methods aria-label="Gradient-Based Optimization Methods">Gradient-Based Optimization Methods</a><ul><ul><li><a href=#the-challenge-with-differentiating-rotation aria-label="The Challenge with Differentiating Rotation">The Challenge with Differentiating Rotation</a></li><li><a href=#deriving-the-jacobian aria-label="Deriving the Jacobian">Deriving the Jacobian</a></li><li><a href=#the-optimization-loop aria-label="The Optimization Loop">The Optimization Loop</a></li></ul></ul></li><li><a href=#global-optimization-methods aria-label="Global Optimization Methods">Global Optimization Methods</a><ul><li><a href=#the-dls-method-zheng-et-al-2013-1 aria-label="The DLS Method (Zheng et al., 2013 [1])">The DLS Method (Zheng et al., 2013 [1])</a></li><li><a href=#the-sqpnp-method-terzakis--lourakis-2020-2 aria-label="The SQPnP Method (Terzakis & Lourakis, 2020 [2])">The SQPnP Method (Terzakis & Lourakis, 2020 [2])</a></li></ul></li><li><a href=#references aria-label=References>References</a></li></ul></div></details></div><div class=post-content><p>In this post, we will discuss the perspective-n-point (PnP) problem. We will start with the problem definition. Then, gradient-based optimization methods will be introduced. Finally, we will discuss two global optimization methods.</p><h1 id=problem-formulation>Problem Formulation<a hidden class=anchor aria-hidden=true href=#problem-formulation>#</a></h1><p>The core task of the Perspective-n-Point (PnP) problem is to determine the pose—specifically, the rotation and translation—of a calibrated camera in 3D space. This is achieved by using a set of known 3D points in the world and their corresponding 2D projections observed on the camera&rsquo;s image sensor.</p><h3 id=goal>Goal<a hidden class=anchor aria-hidden=true href=#goal>#</a></h3><p>Given a set of n 3D points and their 2D image projections, the goal is to compute the rotation <strong>R</strong> and translation <strong>t</strong> of the camera, which together define its pose. This pose describes the transformation from the world coordinate system to the camera&rsquo;s coordinate system.</p><h3 id=knowns-inputs>Knowns (Inputs)<a hidden class=anchor aria-hidden=true href=#knowns-inputs>#</a></h3><ol><li><p><strong>A set of n 3D points</strong> in the world coordinate frame:</p>$$
P_i = (X_i, Y_i, Z_i)^T \quad \text{for } i = 1, \dots, n
$$</li><li><p><strong>Corresponding 2D projections</strong> of these points on the image plane:</p>$$
p_i = (u_i, v_i)^T \quad \text{for } i = 1, \dots, n
$$</li><li><p><strong>The camera intrinsic matrix K</strong>, which is known because the camera is assumed to be calibrated. For modern cameras, we can assume there is no skew, so the matrix simplifies to:</p>$$
K = \begin{pmatrix} f_x & 0 & c_x \\ 0 & f_y & c_y \\ 0 & 0 & 1 \end{pmatrix}
    $$<p>where $(f_x, f_y)$ are the focal lengths in pixels and $(c_x, c_y)$ is the principal point.</p></li></ol><h3 id=unknowns-outputs>Unknowns (Outputs)<a hidden class=anchor aria-hidden=true href=#unknowns-outputs>#</a></h3><ol><li><strong>The rotation matrix R</strong> (a 3x3 matrix), which defines the camera&rsquo;s orientation.</li><li><strong>The translation vector t</strong> (a 3x1 vector), which defines the camera&rsquo;s position.</li></ol><h3 id=mathematical-formulation>Mathematical Formulation<a hidden class=anchor aria-hidden=true href=#mathematical-formulation>#</a></h3><p>The relationship between a 3D world point $P_i$ and its 2D image projection $p_i$ is described by the pinhole camera model:</p>$$
s_i \begin{pmatrix} u_i \\ v_i \\ 1 \end{pmatrix} = K [R | t] \begin{pmatrix} X_i \\ Y_i \\ Z_i \\ 1 \end{pmatrix} = K (R P_i + t)
$$<p>Here, $s_i$ is a non-zero scale factor representing the depth of the point in the camera&rsquo;s coordinate frame. To see how $s_i$ is determined, let&rsquo;s expand the term $R P_i + t$. If we denote the rows of the rotation matrix $\mathbf{R}$ as $r_1^T, r_2^T, r_3^T$, then the transformed point in the camera frame is:</p>$$
R P_i + t = \begin{pmatrix} r_1^T P_i + t_1 \\ r_2^T P_i + t_2 \\ r_3^T P_i + t_3 \end{pmatrix}
$$<p>From the projection equation, the depth $s_i$ is the third component of this vector:</p>$$
s_i = r_3^T P_i + t_3
$$<p>Crucially, this shows that $s_i$ is not an independent variable to be solved for; it is implicitly determined by the pose $(\mathbf{R}, \mathbf{t})$ and the 3D point $P_i$.</p><p>The PnP problem is typically formulated as a non-linear optimization problem. We seek the rotation $\mathbf{R}$ and translation $\mathbf{t}$ that minimize the <strong>reprojection error</strong>. This error is the sum of squared distances between the observed 2D points $p_i$ and the projected 2D points $\hat{p}_i$, which are calculated by projecting the 3D points $P_i$ using the estimated pose $(\mathbf{R}, \mathbf{t})$.</p><p>The objective function to minimize is:</p>$$
\underset{\mathbf{R}, \mathbf{t}}{\text{argmin}} \sum_{i=1}^{n} \left\| p_i - \hat{p}_i(\mathbf{R}, \mathbf{t}, P_i) \right\|^2
$$<p>subject to the constraint that $\mathbf{R}$ is a valid rotation matrix:</p>$$
\mathbf{R}^T \mathbf{R} = I, \quad \det(\mathbf{R}) = 1
$$<h1 id=gradient-based-optimization-methods>Gradient-Based Optimization Methods<a hidden class=anchor aria-hidden=true href=#gradient-based-optimization-methods>#</a></h1><p>Since the PnP objective function is a non-linear least squares problem, it is well-suited to be solved with iterative optimization methods like Gauss-Newton or Levenberg-Marquardt. These algorithms start with an initial guess for the pose $(\mathbf{R}, \mathbf{t})$ and iteratively refine it by solving a linearized version of the problem at each step until the solution converges.</p><p>The core of this process is to compute the <strong>Jacobian</strong> of the residual function with respect to the pose parameters. The residual for a single point $i$ is the reprojection error:</p>$$
r_i(\mathbf{R}, \mathbf{t}) = p_i - \hat{p}_i(\mathbf{R}, \mathbf{t}, P_i)
$$<p>We need to find the derivative of this residual to update our pose estimate.</p><h3 id=the-challenge-with-differentiating-rotation>The Challenge with Differentiating Rotation<a hidden class=anchor aria-hidden=true href=#the-challenge-with-differentiating-rotation>#</a></h3><p>A standard gradient cannot be directly computed for the rotation matrix $\mathbf{R}$. This is because rotation matrices belong to a special mathematical group called the <strong>special orthogonal group SO(3)</strong>. This is a manifold, not a simple vector space, so the rules of standard calculus don&rsquo;t apply. Adding two rotation matrices, for example, does not produce another rotation matrix.</p><p>To solve this, we optimize over a minimal 6-dimensional representation of the camera pose. This is done by parameterizing the updates in the <strong>Lie algebra</strong> associated with the pose group.</p><ol><li><p><strong>Lie Group SE(3):</strong> The camera pose (rotation $\mathbf{R}$ and translation $\mathbf{t}$) belongs to the special Euclidean group SE(3).</p></li><li>$$
\xi = (\omega^\top, v^\top)^T
$$<p>Here, $\omega$ is a 3-vector representing an infinitesimal rotation, and $v$ is a 3-vector representing an infinitesimal translation.</p></li><li><p><strong>Perturbation:</strong> Instead of updating $\mathbf{R}$ and $\mathbf{t}$ directly, we apply a small perturbation $\delta\xi$ to the current pose estimate. The pose is updated using the exponential map, which maps an element from the Lie algebra back to the Lie group:</p>$$
\mathbf{T}_{\text{new}} = \exp(\delta\xi^\wedge) \mathbf{T}_{\text{old}}
$$<p>where $\mathbf{T}$ is the 4x4 transformation matrix and $\delta\xi^\wedge$ is the matrix representation of the Lie algebra vector.</p></li></ol><p>This allows us to perform the optimization in a standard vector space (the 6D space of $\delta\xi$) while ensuring that the updated rotation matrix $\mathbf{R}$ remains a valid element of SO(3).</p><h3 id=deriving-the-jacobian>Deriving the Jacobian<a hidden class=anchor aria-hidden=true href=#deriving-the-jacobian>#</a></h3><p>Our goal is to compute the Jacobian of the residual $r_i$ with respect to the 6-vector perturbation $\delta\xi = (\delta\omega^\top, \delta v^\top)^\top$, where $\delta\omega$ is the rotational part and $\delta v$ is the translational part. We apply the chain rule.</p><p>First, let $P'_i = \mathbf{R} P_i + \mathbf{t}$ be the 3D point $P_i$ transformed into the camera&rsquo;s coordinate frame. The projection function is:</p>$$
\hat{p}_i = \text{proj}(P'_i) = \begin{pmatrix} f_x \frac{X'_i}{Z'_i} + c_x \\ f_y \frac{Y'_i}{Z'_i} + c_y \end{pmatrix}
$$<p>The chain rule gives us:</p>$$
J_i = \frac{\partial r_i}{\partial \delta\xi} = - \frac{\partial \hat{p}_i}{\partial P'_i} \frac{\partial P'_i}{\partial \delta\xi}
$$<p>This breaks the problem into three parts:</p><p><strong>1. Jacobian of the Projection Function</strong></p><p>This is the derivative of the projection function with respect to the 3D point in the camera frame $P'_i = (X'_i, Y'_i, Z'_i)^T$. This is a standard 2x3 matrix, which remains unchanged:</p>$$
\begin{aligned}
\frac{\partial \hat{p}_i}{\partial P'_i} &=
\begin{bmatrix}
\frac{\partial u_i}{\partial X'_i} & \frac{\partial u_i}{\partial Y'_i} & \frac{\partial u_i}{\partial Z'_i} \\
\frac{\partial v_i}{\partial X'_i} & \frac{\partial v_i}{\partial Y'_i} & \frac{\partial v_i}{\partial Z'_i}
\end{bmatrix} \\
&=
\begin{bmatrix}
\frac{f_x}{Z'_i} & 0 & -\frac{f_x X'_i}{(Z'_i)^2} \\
0 & \frac{f_y}{Z'_i} & -\frac{f_y Y'_i}{(Z'_i)^2}
\end{bmatrix}
\end{aligned}
$$<p><strong>2. Derivation of the Transformation Jacobian</strong></p><p>This section provides a step-by-step derivation of how a small pose perturbation affects a 3D point in the camera&rsquo;s coordinate frame, leading to the Jacobian of the transformation.</p><p>A camera&rsquo;s pose is a rigid body transformation, which can be represented by a 4x4 matrix $\mathbf{T} \in SE(3)$. This matrix transforms a 3D point $P_i$ from world coordinates to camera coordinates, $P'_i$.</p>$$
\begin{pmatrix} P'_i \\ 1 \end{pmatrix} = \mathbf{T} \begin{pmatrix} P_i \\ 1 \end{pmatrix}
$$<p>We apply a small perturbation to this pose. This &ldquo;wiggle&rdquo; is represented by a 6D vector $\delta\xi = (\delta\omega^\top, \delta v^\top)^\top$ from the Lie algebra se(3). To apply this to the pose, we use the exponential map:</p>$$
\mathbf{T}_{\text{new}} = \exp(\delta\xi^\wedge) \mathbf{T}_{\text{old}}
$$<p>For a very small perturbation, we can use the first-order Taylor approximation of the exponential map: $\exp(\delta\xi^\wedge) \approx \mathbf{I} + \delta\xi^\wedge$. This is the key step that linearizes the problem.</p>$$
\begin{aligned}
\begin{pmatrix} P'_{i, \text{new}} \\ 1 \end{pmatrix} &= \mathbf{T}_{\text{new}} \begin{pmatrix} P_i \\ 1 \end{pmatrix} \\
&\approx (\mathbf{I} + \delta\xi^\wedge) \mathbf{T}_{\text{old}} \begin{pmatrix} P_i \\ 1 \end{pmatrix}
\end{aligned}
$$<p>We can recognize that $\mathbf{T}_{\text{old}} \begin{pmatrix} P_i \\ 1 \end{pmatrix}$ is simply the homogeneous representation of the point <em>already in the camera frame</em>, $\begin{pmatrix} P'_i \\ 1 \end{pmatrix}$. This allows for a crucial substitution:</p>$$
\begin{pmatrix} P'_{i, \text{new}} \\ 1 \end{pmatrix} \approx (\mathbf{I} + \delta\xi^\wedge) \begin{pmatrix} P'_i \\ 1 \end{pmatrix}
$$<p>This shows that we can calculate the new point by applying the perturbation directly to the old point in the camera frame. Let&rsquo;s expand the matrix multiplication. The 4x4 matrix form of the perturbation is $\delta\xi^\wedge = \begin{pmatrix} \delta\omega^\wedge & \delta v \\ \mathbf{0} & 0 \end{pmatrix}$.</p>$$
\begin{aligned}
\begin{pmatrix} P'_{i, \text{new}} \\ 1 \end{pmatrix} &\approx \begin{pmatrix} \mathbf{I} + \delta\omega^\wedge & \delta v \\ \mathbf{0} & 1 \end{pmatrix} \begin{pmatrix} P'_i \\ 1 \end{pmatrix} \\
&= \begin{pmatrix} (\mathbf{I} + \delta\omega^\wedge)P'_i + \delta v \\ 1 \end{pmatrix}
\end{aligned}
$$<p>Converting back to non-homogeneous 3D coordinates, we get the final expression for the perturbed point:</p>$$
P'_{i, \text{new}} \approx (\mathbf{I} + \delta\omega^\wedge)P'_i + \delta v = P'_i + \delta\omega^\wedge P'_i + \delta v
$$<p>Using the cross-product identity $\delta\omega^\wedge P'_i = -(P'_i)^\wedge \delta\omega$, we arrive at the equation used for the derivative calculation:</p>$$
P'_{i, \text{new}} \approx P'_i - (P'_i)^\wedge \delta\omega + \delta v
$$<p>From this equation, we can directly compute the partial derivatives with respect to the perturbation components $\delta\omega$ and $\delta v$, which form the columns of our 3x6 Jacobian matrix.</p><p><strong>3. The Final Jacobian Matrices</strong></p><p>Combining these parts gives the final Jacobians. The Jacobian of the transformation is now constructed with the rotation component first:</p>$$
\frac{\partial P'_i}{\partial \delta\xi} =
\begin{bmatrix}
\frac{\partial P'_{i}}{\partial \delta\omega} & \frac{\partial P'_{i}}{\partial \delta v}
\end{bmatrix}=
\begin{bmatrix}
-(P'_i)^\wedge & \mathbf{I}
\end{bmatrix}=
\begin{bmatrix}
0 & Z'_i & -Y'_i & 1 & 0 & 0 \\
-Z'_i & 0 & X'_i & 0 & 1 & 0 \\
Y'_i & -X'_i & 0 & 0 & 0 & 1
\end{bmatrix}
$$<p>And the complete Jacobian of the residual for a single point is:</p>$$
J_i = - \frac{\partial \hat{p}_i}{\partial P'_i} \frac{\partial P'_i}{\partial \delta\xi}
$$<h3 id=the-optimization-loop>The Optimization Loop<a hidden class=anchor aria-hidden=true href=#the-optimization-loop>#</a></h3><p>There are various gradient-based optimization methods. Here we will introduce the Gauss-Newton algorithm.</p><p>The Gauss-Newton algorithm proceeds as follows:</p><ol><li><p><strong>Initialize:</strong> Start with an initial guess for the pose $(\mathbf{R}_0, \mathbf{t}_0)$.</p></li><li><p><strong>Iterate:</strong> For each iteration $k$:</p><p>a. For every point $i$, compute the residual $r_i(\mathbf{R}_k, \mathbf{t}_k)$ and the Jacobian $J_i$.</p><p>b. Construct the overall linear system:</p>$$
\left( \sum_i J_i^T J_i \right) \delta\xi = - \sum_i J_i^T r_i
$$<p>c. Solve for the 6D update vector $\delta\xi = (\delta\omega^\top, \delta v^\top)^\top$.</p><p>d. Update the pose using the exponential map:</p>$$
\mathbf{R}_{k+1} = \exp(\delta\omega^\wedge) \mathbf{R}_k \\
\mathbf{t}_{k+1} = \mathbf{t}_k + \delta v
$$</li><li><p><strong>Terminate:</strong> Repeat until the update $\delta\xi$ is very small or a maximum number of iterations is reached.</p></li></ol><h1 id=global-optimization-methods>Global Optimization Methods<a hidden class=anchor aria-hidden=true href=#global-optimization-methods>#</a></h1><p>While gradient-based methods are effective, they can get stuck in local minima, especially if the initial guess is poor. Global optimization methods aim to find the single best solution worldwide by reformulating the problem in a way that avoids this issue.</p><h2 id=the-dls-method-zheng-et-al-2013-1>The DLS Method (Zheng et al., 2013 [1])<a hidden class=anchor aria-hidden=true href=#the-dls-method-zheng-et-al-2013-1>#</a></h2><p>Another foundational approach to global optimization is the <strong>Direct Least Squares (DLS)</strong> method [1]. This technique tackles the problem by directly finding all the stationary points of the objective function, one of which must be the global minimum.</p><ol><li><strong>KKT Conditions:</strong> The method starts with the Karush-Kuhn-Tucker (KKT) conditions, which are the necessary conditions for a solution to be optimal in a constrained optimization problem.</li><li><strong>Polynomial System:</strong> The KKT conditions are transformed into a system of multivariate polynomial equations.</li><li><strong>Gröbner Basis Solvers:</strong> A powerful algebraic geometry tool, the <strong>Gröbner basis</strong>, is used to solve this system of polynomial equations. This yields a finite number of candidate solutions (stationary points).</li><li><strong>Global Minimum Selection:</strong> Finally, the algorithm evaluates the original objective function for each of these candidate solutions and selects the one with the lowest reprojection error, which is guaranteed to be the global optimum.</li></ol><p>The DLS method provides a strong theoretical guarantee of optimality and has inspired numerous follow-up works that have improved its speed and stability.</p><h2 id=the-sqpnp-method-terzakis--lourakis-2020-2>The SQPnP Method (Terzakis & Lourakis, 2020 [2])<a hidden class=anchor aria-hidden=true href=#the-sqpnp-method-terzakis--lourakis-2020-2>#</a></h2><p>One of the leading modern approaches is the <strong>SQPnP</strong> (Sequential Quadratic Programming for PnP) algorithm [2]. This method offers a consistently fast and globally optimal solution. Its core innovations are:</p><ol><li><strong>Quadratic Programming Formulation:</strong> The PnP problem is reformulated as a non-linear quadratic program. The objective function is designed to be quadratic, and the rotation constraint ($\mathbf{R}^T \mathbf{R} = I$) is also expressed using quadratic equations.</li><li><strong>Parameter Space Decomposition:</strong> The algorithm cleverly divides the parameter space of possible rotations into a finite number of regions. It provides a guarantee that at least one of these regions contains the global minimum.</li><li><strong>Sequential Quadratic Programming:</strong> Within each of these identified regions, a fast and efficient Sequential Quadratic Programming (SQP) scheme is used to find the unique regional minimum.</li><li><strong>Global Optimum Guarantee:</strong> By comparing the minima found in each region, the algorithm can identify the true global minimum with certainty.</li></ol><p>A key advantage of SQPnP is its efficiency and robustness. It works for any number of points ($n \ge 3$), is not affected by coplanar point arrangements, and has been integrated into popular libraries like OpenCV, making it a go-to choice for practical applications.</p><h1 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h1><p>[1] Y. Zheng, Y. Kuang, S. Sugimoto, K. Astrom, and M. Okutomi, “Revisiting the PnP problem: A fast, general and optimal solution,” in 2013 IEEE International Conference on Computer Vision, Sydney, Australia: IEEE, Dec. 2013, pp. 2344–2351. doi: 10.1109/ICCV.2013.291.</p><p>[2] G. Terzakis, M. Lourakis, &ldquo;A consistently fast and globally optimal solution to the perspective-n-point problem,&rdquo; in Computer Vision – ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part I, 2020, pp. 478–494.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://livey.github.io/tags/signal-processing/>Signal Processing</a></li><li><a href=https://livey.github.io/tags/calibration/>Calibration</a></li><li><a href=https://livey.github.io/tags/autonomous-driving/>Autonomous-Driving</a></li><li><a href=https://livey.github.io/tags/perspective-n-point/>Perspective-N-Point</a></li><li><a href=https://livey.github.io/tags/pnp/>PnP</a></li><li><a href=https://livey.github.io/tags/perspective-n-point-problem/>Perspective-N-Point Problem</a></li></ul><nav class=paginav><a class=prev href=https://livey.github.io/posts/2025-02-20-slam/><span class=title>« Prev</span><br><span>LiDAR-SLAM Decoded: From Point Clouds to Precision Maps</span>
</a><a class=next href=https://livey.github.io/posts/2025-04-16-path-genrating/><span class=title>Next »</span><br><span>Connecting Points with Grace: A Study on Natural Path Generation Methods</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Perspective-n-Point (PnP) Problem on x" href="https://x.com/intent/tweet/?text=Perspective-n-Point%20%28PnP%29%20Problem&amp;url=https%3a%2f%2flivey.github.io%2fposts%2f2025-05-15-pnp%2f&amp;hashtags=SignalProcessing%2cCalibration%2cAutonomousDriving%2cPerspective-n-Point%2cPnP%2cPerspective-n-PointProblem"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Perspective-n-Point (PnP) Problem on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2flivey.github.io%2fposts%2f2025-05-15-pnp%2f&amp;title=Perspective-n-Point%20%28PnP%29%20Problem&amp;summary=Perspective-n-Point%20%28PnP%29%20Problem&amp;source=https%3a%2f%2flivey.github.io%2fposts%2f2025-05-15-pnp%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Perspective-n-Point (PnP) Problem on reddit" href="https://reddit.com/submit?url=https%3a%2f%2flivey.github.io%2fposts%2f2025-05-15-pnp%2f&title=Perspective-n-Point%20%28PnP%29%20Problem"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Perspective-n-Point (PnP) Problem on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2flivey.github.io%2fposts%2f2025-05-15-pnp%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Perspective-n-Point (PnP) Problem on whatsapp" href="https://api.whatsapp.com/send?text=Perspective-n-Point%20%28PnP%29%20Problem%20-%20https%3a%2f%2flivey.github.io%2fposts%2f2025-05-15-pnp%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Perspective-n-Point (PnP) Problem on telegram" href="https://telegram.me/share/url?text=Perspective-n-Point%20%28PnP%29%20Problem&amp;url=https%3a%2f%2flivey.github.io%2fposts%2f2025-05-15-pnp%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Perspective-n-Point (PnP) Problem on ycombinator" href="https://news.ycombinator.com/submitlink?t=Perspective-n-Point%20%28PnP%29%20Problem&u=https%3a%2f%2flivey.github.io%2fposts%2f2025-05-15-pnp%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://livey.github.io/>Fuwei's Tech Notes</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>
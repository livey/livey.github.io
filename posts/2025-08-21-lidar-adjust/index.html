<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>LiDAR Extrinsic Parameter Adjustment for SLAM Recalibration | Fuwei's Tech Notes</title>
<meta name=keywords content="LiDAR,SLAM,Calibration,Coordinate-transformation,Autonomous Driving,Mapping"><meta name=description content="Mathematical framework for recalibrating SLAM poses and maps when LiDAR extrinsic parameters change, without rerunning the entire SLAM process while preserving annotations."><meta name=author content="Fuwei Li"><link rel=canonical href=https://livey.github.io><link crossorigin=anonymous href=/assets/css/stylesheet.d6fcd20a4fb86efa4dfac8ec95da60244cc8871042183da1ef28e3a762ad79c8.css integrity="sha256-1vzSCk+4bvpN+sjsldpgJEzIhxBCGD2h7yjjp2Ktecg=" rel="preload stylesheet" as=style><link rel=icon href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://livey.github.io/posts/2025-08-21-lidar-adjust/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="index, follow"><meta name=author content="Fuwei Li"><meta name=description content="Mathematical framework for recalibrating SLAM poses and maps when LiDAR extrinsic parameters change, without rerunning the entire SLAM process while preserving annotations."><meta property="og:type" content="article"><meta property="og:url" content="https://livey.github.io/posts/2025-08-21-lidar-adjust/"><meta property="og:title" content="LiDAR Extrinsic Parameter Adjustment for SLAM Recalibration"><meta property="og:description" content="Mathematical framework for recalibrating SLAM poses and maps when LiDAR extrinsic parameters change, without rerunning the entire SLAM process while preserving annotations."><meta property="og:image" content="https://livey.github.io/images/site-preview.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="LiDAR Extrinsic Parameter Adjustment for SLAM Recalibration"><meta name=twitter:description content="Mathematical framework for recalibrating SLAM poses and maps when LiDAR extrinsic parameters change, without rerunning the entire SLAM process while preserving annotations."><meta name=twitter:image content="https://livey.github.io/images/site-preview.jpg"><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css integrity=sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js integrity=sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><meta property="og:url" content="https://livey.github.io/posts/2025-08-21-lidar-adjust/"><meta property="og:site_name" content="Fuwei's Tech Notes"><meta property="og:title" content="LiDAR Extrinsic Parameter Adjustment for SLAM Recalibration"><meta property="og:description" content="Mathematical framework for recalibrating SLAM poses and maps when LiDAR extrinsic parameters change, without rerunning the entire SLAM process while preserving annotations."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-08-21T00:00:00+00:00"><meta property="article:modified_time" content="2025-08-21T00:00:00+00:00"><meta property="article:tag" content="LiDAR"><meta property="article:tag" content="SLAM"><meta property="article:tag" content="Calibration"><meta property="article:tag" content="Coordinate-Transformation"><meta property="article:tag" content="Autonomous Driving"><meta property="article:tag" content="Mapping"><meta property="og:image" content="https://livey.github.io/posts/2025-08-21-lidar-adjust/%3Cimage%20path/url%3E"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://livey.github.io/posts/2025-08-21-lidar-adjust/%3Cimage%20path/url%3E"><meta name=twitter:title content="LiDAR Extrinsic Parameter Adjustment for SLAM Recalibration"><meta name=twitter:description content="Mathematical framework for recalibrating SLAM poses and maps when LiDAR extrinsic parameters change, without rerunning the entire SLAM process while preserving annotations."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://livey.github.io/posts/"},{"@type":"ListItem","position":2,"name":"LiDAR Extrinsic Parameter Adjustment for SLAM Recalibration","item":"https://livey.github.io/posts/2025-08-21-lidar-adjust/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"LiDAR Extrinsic Parameter Adjustment for SLAM Recalibration","name":"LiDAR Extrinsic Parameter Adjustment for SLAM Recalibration","description":"Mathematical framework for recalibrating SLAM poses and maps when LiDAR extrinsic parameters change, without rerunning the entire SLAM process while preserving annotations.","keywords":["LiDAR","SLAM","Calibration","Coordinate-transformation","Autonomous Driving","Mapping"],"articleBody":"Occasionally, we discover that the LiDAR extrinsic parameters are inaccurate. In such cases, we aim to recalibrate the SLAM poses and maps based on the updated parameters, without the need to rerun the entire SLAM process. By doing so, we can keep the annotations and the original SLAM map, which saves human effort and computational resources.\nRaw Data Given LiDAR points in the LiDAR coordinate system\n$$\\mathbf{p}^{orig} = \\bigcup_{t=0:T}\\{\\mathbf{p}_{t,i}\\}_{i=1}^{N_t}$$Where $t$ is the time index, $i$ is the point index at time $t$, and $N_t$ is the number of points at time $t$.\nTransform to Virtual Coordinate System Transform the LiDAR points into a virtual coordinate system\n$$\\mathbf{p}^v = \\bigcup_{t} \\{\\mathbf{p}^v_{t,i}|\\mathbf{p}^v_{t,i} = \\mathbf{T}_{l\\to v}\\mathbf{p}_{t,i}\\}_{i=1}^{N_t}$$Perform SLAM Perform SLAM on these points to obtain the poses and points\n$$\\bigcup_{t} \\left(pose_t^v, \\{\\mathbf{p}_{t,i}^v\\}_i\\right)$$Align with RTK In the next step, we will align the poses with the RTK poses to obtain their global positions. Here, we only perform the alignment on the x-y plane due to the noisy attitude of the RTK.\nSuppose the RTK poses are $\\{pose_t^{RTK}\\}$, and define $\\mathbf{y}_t \\triangleq pose_t^{RTK}[1:2, 3]$, where $\\mathbf{y}_t$ represents the x-y coordinates of the RTK poses. Define $\\mathbf{x}_t\\triangleq pose_t^v[1:2, 3]$ as the x-y coordinates of the virtual poses.\nAlign the x-y coordinates between virtual poses and RTK by solving the following optimization problem\n$$\\mathbf{R}^*, \\mathbf{t}^* = \\text{argmin}_{\\mathbf R, \\mathbf t}\\sum_t \\|\\mathbf R*\\mathbf{x}_t + \\mathbf{t} -\\mathbf{y}_t \\|_2^2$$Construct the aligned virtual pose as\n$$pose_t^{va} = \\mathbf{Q}*pose_t^v$$where\n$$\\mathbf{Q} \\triangleq \\begin{bmatrix} \\mathbf{R}^*\u0026 0\u0026\\mathbf{t}^*\\\\ 0 \u0026 1 \u0026 0\\\\ 0 \u0026 0 \u0026 1 \\end{bmatrix} $$Thus the x-y-z coordinates of $pose_t^{va}$ will be $[(\\mathbf{R}^**\\mathbf{x}_t+\\mathbf{t}^*)^\\top, z]^\\top$, where $z$ is the original z coordinate of $pose_t^v$. By doing so, the x-y positions are aligned with the RTK position, and z remains unchanged.\nThen, we get the new RTK aligned poses and corresponding points\n$$ \\bigcup_t \\left(pose_{t}^{va}, \\{\\mathbf{p}_{t,i}^v\\}_i\\right). $$If we only care about the local structure of the SLAM map, we can use the first frame as the reference frame. So, we have the poses and points as\n$$ \\bigcup_t \\left((pose_0^{va})^{-1}*pose_t^{va}, \\{\\mathbf{p}_{t,i}^{v}\\}_i\\right). $$Map Annotation We perform annotation on the local SLAM map. The annotated points can be represented as\n$$ \\bigcup_t \\left((pose_0^{va})^{-1}*pose_t^{va}, \\{\\mathbf{p}_{t,i}^v\\}_{i\\in S_t}\\right). $$where $S_t$ is the set of annotated data points at time $t$.\nRelocating and Mapping When another LiDAR car generates LiDAR points and poses as\n$$\\bigcup_\\tau \\left(pose_\\tau^r, \\{\\mathbf{p}_{\\tau,j}^r\\}_j\\right)$$Firstly, we do ICP matching on the RTK aligned maps, $\\bigcup_t \\left(pose_{t}^{va}, \\{\\mathbf{p}_{t,i}^v\\}_i\\right)$, thus we have\n$$ \\{pose_\\tau^r * \\mathbf{p}_{\\tau,j}^r\\}_{\\tau,j} \\approx \\{\\mathbf{T}_{rel}*pose_t^{va}*\\mathbf{p}_{t,i}^v\\}_{t,i} $$where $\\mathbf{T}_{rel}$ is the transformation matrix between the relocated map and RTK annotated map, and the approximation is under the least squares error.\nThen the revised pose can be computed as\n$$ \\widehat{pose}^r_t = \\mathbf{T}_{rel}*pose^r_t $$If $pose^r_t$ indicates the ego pose, then the new ego pose is $\\widehat{pose}^r_t$. Otherwise, we need to do further transformation.\nFirst, compute the ego pose according to (will show later) $$ pose_{t}^{re} = \\mathbf{T}_{e\\to v}^{-1} * pose_{t}^r * \\mathbf{T}_{e\\to v}, $$where $\\mathbf{T}_{e\\to v}$ is the transformation matrix from the ego coordinate to the virtual coordinate.\nCompute the new ego pose $$ \\widehat{pose}^{re}_t = \\mathbf{T}_{rel}*pose^{re}_t=\\mathbf{T}_{rel}*\\mathbf{T}_{e\\to v}^{-1} * pose_{t}^r * \\mathbf{T}_{e\\to v} $$Impact of Change of Virtual Coordinate We will discuss the impact if we change the extrinsic parameters and the correlation of the new poses and the original poses.\nLiDAR SLAM Pose Suppose we change the original points using another transformation matrix, e.g., transform into ego coordinate. We have the new transformed LiDAR points:\n$$ \\bigcup_{t, i} \\{\\mathbf{p}^e_{t,i}|\\mathbf{p}^e_{t,i} = \\mathbf{T}_{l\\to e}\\mathbf{p}_{t,i}\\} $$Using these LiDAR points to perform SLAM, we obtain the new poses and points\n$$ \\bigcup_t \\left(pose_t^e, \\{\\mathbf{p}_{t,i}^e\\}_i\\right) $$Since we only change the reference coordinate system of the ego vehicle, the 3D reconstruction is invariant to rigid body transformations. Thus, we have\n$$ pose^e_{t}*\\mathbf{p}^e_{t,i} = \\mathbf{T}*pose^v_{t}*\\mathbf{p}^v_{t,i}, $$for all $t$ and $i$. This equation leads to\n$$ pose^e_{t}*\\mathbf{T}_{l\\to e}*\\mathbf{p}_{t,i} = \\mathbf{T}*pose^v_{t}*\\mathbf{T}_{l\\to v}*\\mathbf{p}_{t,i} $$Thus we have\n$$ pose^e_{t}*\\mathbf{T}_{l\\to e} = \\mathbf{T}*pose^v_{t}*\\mathbf{T}_{l\\to v} $$where $\\mathbf{T}$ is an unknown rigid body transformation. This means the new and old 3D reconstructions are invariant to rigid body transformations.\nWhen doing SLAM, we initialize the pose with an identity matrix, i.e., $pose_0^e = \\mathbf{I}$ and $pose_0^v = \\mathbf{I}$, we have\n$$ \\mathbf{I}*\\mathbf{T}_{l\\to e} = \\mathbf{T}*\\mathbf{I}*\\mathbf{T}_{l\\to v} $$which results in\n$$ \\mathbf{T} = \\mathbf{T}_{l\\to e}*\\mathbf{T}_{l\\to v}^{-1}, $$and\n$$ pose_{t}^e = \\mathbf{T}_{l\\to e}*\\mathbf{T}_{l\\to v}^{-1} * pose_{t,i}^v * \\left(\\mathbf{T}_{l\\to v}*\\mathbf{T}_{l\\to e}^{-1}\\right) $$Note that $\\mathbf{T}_{l\\to e}^{-1} = \\mathbf{T}_{e\\to l}$, so we have\n$$ \\mathbf{T}_{l\\to v}*\\mathbf{T}_{l\\to e}^{-1} = \\mathbf{T}_{e\\to v}, $$$$ \\begin{aligned} pose_{t}^e \u0026= \\mathbf{T}_{v\\to e} * pose_{t}^v * \\mathbf{T}_{e\\to v}\\\\ \u0026= \\mathbf{T}_{e\\to v}^{-1} * pose_{t}^v * \\mathbf{T}_{e\\to v} \\end{aligned}. $$This tells us that the new pose is not a simple right or left multiplication by any rigid body transformation of the original pose.\nAligned Poses Suppose the new aligned pose transformation matrix is $\\mathbf{Q}^*, \\mathbf{s}^*$, we have\n$$ pose_t^{ea} = \\mathbf{W}*pose_t^e $$where\n$$ \\mathbf{W} \\triangleq \\begin{bmatrix} \\mathbf{Q}^*\u0026 0\u0026\\mathbf{s}^*\\\\ 0 \u0026 1 \u0026 0\\\\ 0 \u0026 0 \u0026 1 \\end{bmatrix} $$Relative Poses $$ \\begin{aligned} (pose_{i}^{ea})^{-1}pose_{j}^{ea} \u0026= (pose_{i}^{e})^{-1}pose_{j}^{e}\\\\ \u0026= T_{e\\to v}^{-1} * (pose_{i}^v)^{-1}* pose_{j}^v* T_{e\\to v}\\\\ \u0026= T_{e\\to v}^{-1} * (pose_{i}^{va})^{-1}* pose_{j}^{va}* T_{e\\to v} \\end{aligned} $$From this equation, we know that the relative poses follow a similar transformation to the individual poses.\nAnnotations Since we perform relocation and re-mapping using the RTK-aligned poses and their corresponding maps, the LiDAR points carry the properties of the target annotations. Any reference coordinate system change does not affect the SLAM map structure, so the annotations remain unchanged.\n","wordCount":"893","inLanguage":"en","image":"https://livey.github.io/posts/2025-08-21-lidar-adjust/%3Cimage%20path/url%3E","datePublished":"2025-08-21T00:00:00Z","dateModified":"2025-08-21T00:00:00Z","author":{"@type":"Person","name":"Fuwei Li"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://livey.github.io/posts/2025-08-21-lidar-adjust/"},"publisher":{"@type":"Organization","name":"Fuwei's Tech Notes","logo":{"@type":"ImageObject","url":"https://livey.github.io/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://livey.github.io/ accesskey=h title="Home (Alt + H)"><img src=https://livey.github.io/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://livey.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://livey.github.io/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://livey.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://livey.github.io/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://livey.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://livey.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">LiDAR Extrinsic Parameter Adjustment for SLAM Recalibration</h1><div class=post-description>Mathematical framework for recalibrating SLAM poses and maps when LiDAR extrinsic parameters change, without rerunning the entire SLAM process while preserving annotations.</div><div class=post-meta><span title='2025-08-21 00:00:00 +0000 UTC'>August 21, 2025</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;893 words&nbsp;·&nbsp;Fuwei Li&nbsp;|&nbsp;<a href=https://github.com/livey/livey.github.io/issues/new rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#raw-data aria-label="Raw Data">Raw Data</a></li><li><a href=#transform-to-virtual-coordinate-system aria-label="Transform to Virtual Coordinate System">Transform to Virtual Coordinate System</a></li><li><a href=#perform-slam aria-label="Perform SLAM">Perform SLAM</a></li><li><a href=#align-with-rtk aria-label="Align with RTK">Align with RTK</a></li><li><a href=#map-annotation aria-label="Map Annotation">Map Annotation</a></li><li><a href=#relocating-and-mapping aria-label="Relocating and Mapping">Relocating and Mapping</a></li><li><a href=#impact-of-change-of-virtual-coordinate aria-label="Impact of Change of Virtual Coordinate">Impact of Change of Virtual Coordinate</a><ul><li><a href=#lidar-slam-pose aria-label="LiDAR SLAM Pose">LiDAR SLAM Pose</a></li><li><a href=#aligned-poses aria-label="Aligned Poses">Aligned Poses</a></li><li><a href=#relative-poses aria-label="Relative Poses">Relative Poses</a></li><li><a href=#annotations aria-label=Annotations>Annotations</a></li></ul></li></ul></div></details></div><div class=post-content><p>Occasionally, we discover that the LiDAR extrinsic parameters are inaccurate. In such cases, we aim to recalibrate the SLAM poses and maps based on the updated parameters, without the need to rerun the entire SLAM process. By doing so, we can keep the annotations and the original SLAM map, which saves human effort and computational resources.</p><h1 id=raw-data>Raw Data<a hidden class=anchor aria-hidden=true href=#raw-data>#</a></h1><p>Given LiDAR points in the LiDAR coordinate system</p>$$\mathbf{p}^{orig} = \bigcup_{t=0:T}\{\mathbf{p}_{t,i}\}_{i=1}^{N_t}$$<p>Where $t$ is the time index, $i$ is the point index at time $t$, and $N_t$ is the number of points at time $t$.</p><h1 id=transform-to-virtual-coordinate-system>Transform to Virtual Coordinate System<a hidden class=anchor aria-hidden=true href=#transform-to-virtual-coordinate-system>#</a></h1><p>Transform the LiDAR points into a virtual coordinate system</p>$$\mathbf{p}^v = \bigcup_{t} \{\mathbf{p}^v_{t,i}|\mathbf{p}^v_{t,i} = \mathbf{T}_{l\to v}\mathbf{p}_{t,i}\}_{i=1}^{N_t}$$<h1 id=perform-slam>Perform SLAM<a hidden class=anchor aria-hidden=true href=#perform-slam>#</a></h1><p>Perform SLAM on these points to obtain the poses and points</p>$$\bigcup_{t} \left(pose_t^v, \{\mathbf{p}_{t,i}^v\}_i\right)$$<h1 id=align-with-rtk>Align with RTK<a hidden class=anchor aria-hidden=true href=#align-with-rtk>#</a></h1><p>In the next step, we will align the poses with the RTK poses to obtain their global positions. Here, we only perform the alignment on the x-y plane due to the noisy attitude of the RTK.</p><p>Suppose the RTK poses are $\{pose_t^{RTK}\}$, and define $\mathbf{y}_t \triangleq pose_t^{RTK}[1:2, 3]$, where $\mathbf{y}_t$ represents the x-y coordinates of the RTK poses. Define $\mathbf{x}_t\triangleq pose_t^v[1:2, 3]$ as the x-y coordinates of the virtual poses.</p><p>Align the x-y coordinates between virtual poses and RTK by solving the following optimization problem</p>$$\mathbf{R}^*, \mathbf{t}^* = \text{argmin}_{\mathbf R, \mathbf t}\sum_t \|\mathbf R*\mathbf{x}_t + \mathbf{t} -\mathbf{y}_t \|_2^2$$<p>Construct the aligned virtual pose as</p>$$pose_t^{va} = \mathbf{Q}*pose_t^v$$<p>where</p>$$\mathbf{Q} \triangleq 
\begin{bmatrix}
\mathbf{R}^*& 0&\mathbf{t}^*\\
0 & 1 & 0\\
0 & 0 & 1
\end{bmatrix}
$$<p>Thus the x-y-z coordinates of $pose_t^{va}$ will be $[(\mathbf{R}^**\mathbf{x}_t+\mathbf{t}^*)^\top, z]^\top$, where $z$ is the original z coordinate of $pose_t^v$. By doing so, the x-y positions are aligned with the RTK position, and z remains unchanged.</p><p>Then, we get the new RTK aligned poses and corresponding points</p>$$
\bigcup_t \left(pose_{t}^{va}, \{\mathbf{p}_{t,i}^v\}_i\right).
$$<p>If we only care about the local structure of the SLAM map, we can use the first frame as the reference frame. So, we have the poses and points as</p>$$
\bigcup_t \left((pose_0^{va})^{-1}*pose_t^{va}, \{\mathbf{p}_{t,i}^{v}\}_i\right).
$$<h1 id=map-annotation>Map Annotation<a hidden class=anchor aria-hidden=true href=#map-annotation>#</a></h1><p>We perform annotation on the local SLAM map. The annotated points can be represented as</p>$$
\bigcup_t \left((pose_0^{va})^{-1}*pose_t^{va}, \{\mathbf{p}_{t,i}^v\}_{i\in S_t}\right).
$$<p>where $S_t$ is the set of annotated data points at time $t$.</p><h1 id=relocating-and-mapping>Relocating and Mapping<a hidden class=anchor aria-hidden=true href=#relocating-and-mapping>#</a></h1><p>When another LiDAR car generates LiDAR points and poses as</p>$$\bigcup_\tau \left(pose_\tau^r, \{\mathbf{p}_{\tau,j}^r\}_j\right)$$<p>Firstly, we do ICP matching on the RTK aligned maps, $\bigcup_t \left(pose_{t}^{va}, \{\mathbf{p}_{t,i}^v\}_i\right)$, thus we have</p>$$
\{pose_\tau^r * \mathbf{p}_{\tau,j}^r\}_{\tau,j} \approx \{\mathbf{T}_{rel}*pose_t^{va}*\mathbf{p}_{t,i}^v\}_{t,i}
$$<p>where $\mathbf{T}_{rel}$ is the transformation matrix between the relocated map and RTK annotated map, and the approximation is under the least squares error.</p><p>Then the revised pose can be computed as</p>$$
\widehat{pose}^r_t = \mathbf{T}_{rel}*pose^r_t
$$<p>If $pose^r_t$ indicates the ego pose, then the new ego pose is $\widehat{pose}^r_t$. Otherwise, we need to do further transformation.</p><ol><li>First, compute the ego pose according to (will show later)</li></ol>$$
pose_{t}^{re} = \mathbf{T}_{e\to v}^{-1} * pose_{t}^r * \mathbf{T}_{e\to v},
$$<p>where $\mathbf{T}_{e\to v}$ is the transformation matrix from the ego coordinate to the virtual coordinate.</p><ol start=2><li>Compute the new ego pose</li></ol>$$
\widehat{pose}^{re}_t = \mathbf{T}_{rel}*pose^{re}_t=\mathbf{T}_{rel}*\mathbf{T}_{e\to v}^{-1} * pose_{t}^r * \mathbf{T}_{e\to v}
$$<h1 id=impact-of-change-of-virtual-coordinate>Impact of Change of Virtual Coordinate<a hidden class=anchor aria-hidden=true href=#impact-of-change-of-virtual-coordinate>#</a></h1><p>We will discuss the impact if we change the extrinsic parameters and the correlation of the new poses and the original poses.</p><h2 id=lidar-slam-pose>LiDAR SLAM Pose<a hidden class=anchor aria-hidden=true href=#lidar-slam-pose>#</a></h2><p>Suppose we change the original points using another transformation matrix, e.g., transform into ego coordinate. We have the new transformed LiDAR points:</p>$$
\bigcup_{t, i} \{\mathbf{p}^e_{t,i}|\mathbf{p}^e_{t,i} = \mathbf{T}_{l\to e}\mathbf{p}_{t,i}\}
$$<p>Using these LiDAR points to perform SLAM, we obtain the new poses and points</p>$$
\bigcup_t \left(pose_t^e, \{\mathbf{p}_{t,i}^e\}_i\right)
$$<p>Since we only change the reference coordinate system of the ego vehicle, the 3D reconstruction is invariant to rigid body transformations. Thus, we have</p>$$
pose^e_{t}*\mathbf{p}^e_{t,i} = \mathbf{T}*pose^v_{t}*\mathbf{p}^v_{t,i},
$$<p>for all $t$ and $i$. This equation leads to</p>$$
pose^e_{t}*\mathbf{T}_{l\to e}*\mathbf{p}_{t,i} = \mathbf{T}*pose^v_{t}*\mathbf{T}_{l\to v}*\mathbf{p}_{t,i}
$$<p>Thus we have</p>$$
pose^e_{t}*\mathbf{T}_{l\to e} = \mathbf{T}*pose^v_{t}*\mathbf{T}_{l\to v}
$$<p>where $\mathbf{T}$ is an unknown rigid body transformation. This means the new and old 3D reconstructions are invariant to rigid body transformations.</p><p>When doing SLAM, we initialize the pose with an identity matrix, i.e., $pose_0^e = \mathbf{I}$ and $pose_0^v = \mathbf{I}$, we have</p>$$
\mathbf{I}*\mathbf{T}_{l\to e} = \mathbf{T}*\mathbf{I}*\mathbf{T}_{l\to v}
$$<p>which results in</p>$$
\mathbf{T} = \mathbf{T}_{l\to e}*\mathbf{T}_{l\to v}^{-1},
$$<p>and</p>$$
pose_{t}^e = \mathbf{T}_{l\to e}*\mathbf{T}_{l\to v}^{-1} * pose_{t,i}^v * \left(\mathbf{T}_{l\to v}*\mathbf{T}_{l\to e}^{-1}\right)
$$<p>Note that $\mathbf{T}_{l\to e}^{-1} = \mathbf{T}_{e\to l}$, so we have</p>$$
\mathbf{T}_{l\to v}*\mathbf{T}_{l\to e}^{-1} = \mathbf{T}_{e\to v},
$$$$
\begin{aligned}
pose_{t}^e &= \mathbf{T}_{v\to e} * pose_{t}^v * \mathbf{T}_{e\to v}\\
&= \mathbf{T}_{e\to v}^{-1} * pose_{t}^v * \mathbf{T}_{e\to v}
\end{aligned}.
$$<p>This tells us that the new pose is not a simple right or left multiplication by any rigid body transformation of the original pose.</p><h2 id=aligned-poses>Aligned Poses<a hidden class=anchor aria-hidden=true href=#aligned-poses>#</a></h2><p>Suppose the new aligned pose transformation matrix is $\mathbf{Q}^*, \mathbf{s}^*$, we have</p>$$
pose_t^{ea} = \mathbf{W}*pose_t^e
$$<p>where</p>$$
\mathbf{W} \triangleq 
\begin{bmatrix}
\mathbf{Q}^*& 0&\mathbf{s}^*\\
0 & 1 & 0\\
0 & 0 & 1
\end{bmatrix}
$$<h2 id=relative-poses>Relative Poses<a hidden class=anchor aria-hidden=true href=#relative-poses>#</a></h2>$$
\begin{aligned}
(pose_{i}^{ea})^{-1}pose_{j}^{ea} 
&= (pose_{i}^{e})^{-1}pose_{j}^{e}\\
&= T_{e\to v}^{-1} * (pose_{i}^v)^{-1}* pose_{j}^v* T_{e\to v}\\
&= T_{e\to v}^{-1} * (pose_{i}^{va})^{-1}* pose_{j}^{va}* T_{e\to v}
\end{aligned}
$$<p>From this equation, we know that the relative poses follow a similar transformation to the individual poses.</p><h2 id=annotations>Annotations<a hidden class=anchor aria-hidden=true href=#annotations>#</a></h2><p>Since we perform relocation and re-mapping using the RTK-aligned poses and their corresponding maps, the LiDAR points carry the properties of the target annotations. Any reference coordinate system change does not affect the SLAM map structure, so the annotations remain unchanged.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://livey.github.io/tags/lidar/>LiDAR</a></li><li><a href=https://livey.github.io/tags/slam/>SLAM</a></li><li><a href=https://livey.github.io/tags/calibration/>Calibration</a></li><li><a href=https://livey.github.io/tags/coordinate-transformation/>Coordinate-Transformation</a></li><li><a href=https://livey.github.io/tags/autonomous-driving/>Autonomous Driving</a></li><li><a href=https://livey.github.io/tags/mapping/>Mapping</a></li></ul><nav class=paginav><a class=prev href=https://livey.github.io/posts/2025-11-22-diffusion/><span class=title>« Prev</span><br><span>A Gentle Introduction to Diffusion Models and Flow Matching</span>
</a><a class=next href=https://livey.github.io/posts/2025-08-20-lidar-post-processing/><span class=title>Next »</span><br><span>Bundle Adjustment for LiDAR SLAM: Mathematical Formulation and Optimization</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share LiDAR Extrinsic Parameter Adjustment for SLAM Recalibration on x" href="https://x.com/intent/tweet/?text=LiDAR%20Extrinsic%20Parameter%20Adjustment%20for%20SLAM%20Recalibration&amp;url=https%3a%2f%2flivey.github.io%2fposts%2f2025-08-21-lidar-adjust%2f&amp;hashtags=LiDAR%2cSLAM%2cCalibration%2cCoordinate-transformation%2cAutonomousDriving%2cMapping"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share LiDAR Extrinsic Parameter Adjustment for SLAM Recalibration on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2flivey.github.io%2fposts%2f2025-08-21-lidar-adjust%2f&amp;title=LiDAR%20Extrinsic%20Parameter%20Adjustment%20for%20SLAM%20Recalibration&amp;summary=LiDAR%20Extrinsic%20Parameter%20Adjustment%20for%20SLAM%20Recalibration&amp;source=https%3a%2f%2flivey.github.io%2fposts%2f2025-08-21-lidar-adjust%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share LiDAR Extrinsic Parameter Adjustment for SLAM Recalibration on reddit" href="https://reddit.com/submit?url=https%3a%2f%2flivey.github.io%2fposts%2f2025-08-21-lidar-adjust%2f&title=LiDAR%20Extrinsic%20Parameter%20Adjustment%20for%20SLAM%20Recalibration"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share LiDAR Extrinsic Parameter Adjustment for SLAM Recalibration on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2flivey.github.io%2fposts%2f2025-08-21-lidar-adjust%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share LiDAR Extrinsic Parameter Adjustment for SLAM Recalibration on whatsapp" href="https://api.whatsapp.com/send?text=LiDAR%20Extrinsic%20Parameter%20Adjustment%20for%20SLAM%20Recalibration%20-%20https%3a%2f%2flivey.github.io%2fposts%2f2025-08-21-lidar-adjust%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share LiDAR Extrinsic Parameter Adjustment for SLAM Recalibration on telegram" href="https://telegram.me/share/url?text=LiDAR%20Extrinsic%20Parameter%20Adjustment%20for%20SLAM%20Recalibration&amp;url=https%3a%2f%2flivey.github.io%2fposts%2f2025-08-21-lidar-adjust%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share LiDAR Extrinsic Parameter Adjustment for SLAM Recalibration on ycombinator" href="https://news.ycombinator.com/submitlink?t=LiDAR%20Extrinsic%20Parameter%20Adjustment%20for%20SLAM%20Recalibration&u=https%3a%2f%2flivey.github.io%2fposts%2f2025-08-21-lidar-adjust%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://livey.github.io/>Fuwei's Tech Notes</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>
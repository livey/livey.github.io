<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Posts | Fuwei's Tech Notes</title>
<meta name=keywords content><meta name=description content="Posts - Fuwei's Tech Notes"><meta name=author content="Fuwei Li"><link rel=canonical href=https://livey.github.io/posts/><link crossorigin=anonymous href=/assets/css/stylesheet.d6fcd20a4fb86efa4dfac8ec95da60244cc8871042183da1ef28e3a762ad79c8.css integrity="sha256-1vzSCk+4bvpN+sjsldpgJEzIhxBCGD2h7yjjp2Ktecg=" rel="preload stylesheet" as=style><link rel=icon href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://livey.github.io/posts/index.xml><link rel=alternate hreflang=en href=https://livey.github.io/posts/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="index, follow"><meta name=author content="Fuwei Li"><meta name=description content="Technical blog covering topics in autonomous driving, computer vision, robotics, optimization, and software engineering"><meta property="og:type" content="article"><meta property="og:url" content="https://livey.github.io/posts/"><meta property="og:title" content="Posts"><meta property="og:description" content="Technical blog covering topics in autonomous driving, computer vision, robotics, optimization, and software engineering"><meta property="og:image" content="https://livey.github.io/images/site-preview.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="Posts"><meta name=twitter:description content="Technical blog covering topics in autonomous driving, computer vision, robotics, optimization, and software engineering"><meta name=twitter:image content="https://livey.github.io/images/site-preview.jpg"><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css integrity=sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js integrity=sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><meta property="og:url" content="https://livey.github.io/posts/"><meta property="og:site_name" content="Fuwei's Tech Notes"><meta property="og:title" content="Posts"><meta property="og:description" content="Technical blog covering topics in autonomous driving, computer vision, robotics, optimization, and software engineering"><meta property="og:locale" content="en"><meta property="og:type" content="website"><meta property="og:image" content="https://livey.github.io/images/site-preview.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://livey.github.io/images/site-preview.jpg"><meta name=twitter:title content="Posts"><meta name=twitter:description content="Technical blog covering topics in autonomous driving, computer vision, robotics, optimization, and software engineering"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://livey.github.io/posts/"}]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://livey.github.io/ accesskey=h title="Home (Alt + H)"><img src=https://livey.github.io/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://livey.github.io/posts/ title=Posts><span class=active>Posts</span></a></li><li><a href=https://livey.github.io/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://livey.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://livey.github.io/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://livey.github.io/>Home</a></div><h1>Posts
<a href=/posts/index.xml title=RSS aria-label=RSS><svg viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" height="23"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></h1></header><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Rethinking Data Augmentation in End-to-End Learning</h2></header><div class=entry-content><p>Suppose the ego position relative to the center lane is denoted as $X$. We do random position augmentation along the lateral direction. Let $Y$ denote the position after augmentation as $Y = X+ Z$, where $Z$ is the random position augmentation. Assume $X\sim p_x$, $Z\sim p_z$ with its probability density function $f_X(x)$ and $f_Z(z)$, respectively. So, the distribution of $Y$ can be computed as below. First, we will compute the accumulated distribution of $Y$, then can compute the density distribution. Let $F_Y(y)$ denote the accumulated distribution of $Y$, then
...</p></div><footer class=entry-footer><span title='2026-01-13 00:00:00 +0000 UTC'>January 13, 2026</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;742 words&nbsp;·&nbsp;Fuwei Li</footer><a class=entry-link aria-label="post link to Rethinking Data Augmentation in End-to-End Learning" href=https://livey.github.io/posts/2026-01-13-data-dist/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>A Gentle Introduction to Diffusion Models and Flow Matching</h2></header><div class=entry-content><p>Diffusion models have emerged as a powerful and flexible class of generative models, underpinning recent breakthroughs in image, audio, and scientific data generation. This article offers a gentle, beginner-friendly overview of diffusion models and the related flow matching framework, demystifying their mathematical foundations and practical training procedures. We will delve into the core concepts, guiding equations, and step-by-step training algorithms, aiming to provide readers with both an intuition for how these models work and a roadmap for implementing them in practice. This article serves as notes on papers [1] and [2].
...</p></div><footer class=entry-footer><span title='2025-11-22 00:00:00 +0000 UTC'>November 22, 2025</span>&nbsp;·&nbsp;16 min&nbsp;·&nbsp;3362 words&nbsp;·&nbsp;Fuwei Li</footer><a class=entry-link aria-label="post link to A Gentle Introduction to Diffusion Models and Flow Matching" href=https://livey.github.io/posts/2025-11-22-diffusion/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>LiDAR Extrinsic Parameter Adjustment for SLAM Recalibration</h2></header><div class=entry-content><p>Occasionally, we discover that the LiDAR extrinsic parameters are inaccurate. In such cases, we aim to recalibrate the SLAM poses and maps based on the updated parameters, without the need to rerun the entire SLAM process. By doing so, we can keep the annotations and the original SLAM map, which saves human effort and computational resources.
Raw Data Given LiDAR points in the LiDAR coordinate system
$$\mathbf{p}^{orig} = \bigcup_{t=0:T}\{\mathbf{p}_{t,i}\}_{i=1}^{N_t}$$Where $t$ is the time index, $i$ is the point index at time $t$, and $N_t$ is the number of points at time $t$.
...</p></div><footer class=entry-footer><span title='2025-08-21 00:00:00 +0000 UTC'>August 21, 2025</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;893 words&nbsp;·&nbsp;Fuwei Li</footer><a class=entry-link aria-label="post link to LiDAR Extrinsic Parameter Adjustment for SLAM Recalibration" href=https://livey.github.io/posts/2025-08-21-lidar-adjust/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Bundle Adjustment for LiDAR SLAM: Mathematical Formulation and Optimization</h2></header><div class=entry-content><p>In this post, we will discuss the post-processing of LiDAR SLAM. We mainly focus on its problem formulation. The content of this post follows papers [1] and [2].
Problem Formulation Factor graph representation of bundle adjustment formulation. (Fig. 1 of [2]) With LiDAR poses, each denoted by $\mathbf{T}_j = (\mathbf{R}_j,\mathbf{t}_j)$ $(j=1,\ldots,M_p)$, the bundle adjustment refers to simultaneously determining all the LiDAR poses (denoted by $\mathbf{T} = (\mathbf{T}_1,\cdots,\mathbf{T}_{M_p})$) and feature parameters (denoted by $\boldsymbol{\pi} = (\pi_1,\cdots,\pi_{M_f})$), such that the reconstructed map agrees with the LiDAR measurements to the best extent. Denote $c(\pi_i,\mathbf{T})$ the map consistency due to the $i$-th feature; a straightforward BA formulation is
...</p></div><footer class=entry-footer><span title='2025-08-20 00:00:00 +0000 UTC'>August 20, 2025</span>&nbsp;·&nbsp;6 min&nbsp;·&nbsp;1078 words&nbsp;·&nbsp;Fuwei Li</footer><a class=entry-link aria-label="post link to Bundle Adjustment for LiDAR SLAM: Mathematical Formulation and Optimization" href=https://livey.github.io/posts/2025-08-20-lidar-post-processing/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Probabilistic Collision Loss: Bounds and Soft Distance Maps for Autonomous Driving</h2></header><div class=entry-content><p>This post explores collision loss design for end-to-end autonomous driving training, focusing on extending PLUTO’s binary occupancy map approach to handle probabilistic maps. The method enables safer autonomous driving by providing smooth, uncertainty-aware collision avoidance while maintaining computational efficiency.
Using Signed Distance Map with Binary Occupancy Map How PLUTO Builds the Loss Map [2] Vehicle Model In PLUTO and other planning algorithms, the vehicle is modelded as a series of overlapping discs.
...</p></div><footer class=entry-footer><span title='2025-08-14 00:00:00 +0000 UTC'>August 14, 2025</span>&nbsp;·&nbsp;15 min&nbsp;·&nbsp;3118 words&nbsp;·&nbsp;Fuwei Li</footer><a class=entry-link aria-label="post link to Probabilistic Collision Loss: Bounds and Soft Distance Maps for Autonomous Driving" href=https://livey.github.io/posts/2025-08-13-collission-loss/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>A State Machine for Object Tracking</h2></header><div class=entry-content><p>This post contains a state machine diagram that illustrates the typical lifecycle of an object in a tracking system.
Object Tracking Management State Machine.</p></div><footer class=entry-footer><span title='2025-07-22 00:00:00 +0000 UTC'>July 22, 2025</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;24 words&nbsp;·&nbsp;Fuwei Li</footer><a class=entry-link aria-label="post link to A State Machine for Object Tracking" href=https://livey.github.io/posts/2025-07-22-track-life/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Wayformer Paper Reading</h2></header><div class=entry-content><p>This post provides a technical deep dive into the Wayformer paper [1], a key publication in the field of motion forecasting.
Training Overview An overview of the deep learning training pipeline, illustrating the data flow and key components involved during model training. Model Overview of the One-Stage E2E model One staged E2E model. Overview of the Two-Stage E2E model Two staged E2E model. Details of the Two-Stage E2E Model Overview of the Wayformer model. Model Structure Overview (a) (b) The left figure shows the encoder and decoder of the Wayformer model. The right figure shows the details of the encoder [1]. Feature Embedding/Feature Projection $$\mathbf{f}\in \mathbb{R}^{T \times N\times D} \to \mathbf{x}_{input} \in \mathbb{R}^{(T \cdot N) \times d}$$Where $T$ is the number of time history, $N$ is the number of entities, $D$ is the number of features, and $d=256$. ...</p></div><footer class=entry-footer><span title='2025-07-21 00:00:00 +0000 UTC'>July 21, 2025</span>&nbsp;·&nbsp;8 min&nbsp;·&nbsp;1529 words&nbsp;·&nbsp;Fuwei Li</footer><a class=entry-link aria-label="post link to Wayformer Paper Reading" href=https://livey.github.io/posts/2025-07-21-wayformer/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>LiDAR-SLAM Decoded: From Point Clouds to Precision Maps</h2></header><div class=entry-content><p>What is SLAM? SLAM demo. SLAM stands for Simultaneous Localization and Mapping. It is a computational problem of constructing or updating a map of an unknown environment while simultaneously keeping track of an agent's location within it. Applications Object Detection Parking Lot Annotation Lane Annotation Lane Reprojection HD Map [source] SLAM has various applications, including:
...</p></div><footer class=entry-footer><span title='2025-07-19 00:00:00 +0000 UTC'>July 19, 2025</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;1001 words&nbsp;·&nbsp;Fuwei Li</footer><a class=entry-link aria-label="post link to LiDAR-SLAM Decoded: From Point Clouds to Precision Maps" href=https://livey.github.io/posts/2025-02-20-slam/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Perspective-n-Point (PnP) Problem</h2></header><div class=entry-content><p>In this post, we will discuss the perspective-n-point (PnP) problem. We will start with the problem definition. Then, gradient-based optimization methods will be introduced. Finally, we will discuss two global optimization methods.
Problem Formulation The core task of the Perspective-n-Point (PnP) problem is to determine the pose—specifically, the rotation and translation—of a calibrated camera in 3D space. This is achieved by using a set of known 3D points in the world and their corresponding 2D projections observed on the camera’s image sensor.
...</p></div><footer class=entry-footer><span title='2025-07-19 00:00:00 +0000 UTC'>July 19, 2025</span>&nbsp;·&nbsp;11 min&nbsp;·&nbsp;2209 words&nbsp;·&nbsp;Fuwei Li</footer><a class=entry-link aria-label="post link to Perspective-n-Point (PnP) Problem" href=https://livey.github.io/posts/2025-05-15-pnp/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Connecting Points with Grace: A Study on Natural Path Generation Methods</h2></header><div class=entry-content><p>Given a starting point, starting direction, ending point, and ending direction, the goal is to generate a feasible and “natural” path that connects the two points. This path should adhere to vehicle dynamics and avoids obstacles. However, it is hard to define what is “natural”.
Path Planning In this section, we review some classical path planning methods. We ignore the algorithmic details and focus on the resulting path shapes to provide an overview. The demonstration images are generated using the code repository [1].
...</p></div><footer class=entry-footer><span title='2025-04-16 00:00:00 +0000 UTC'>April 16, 2025</span>&nbsp;·&nbsp;16 min&nbsp;·&nbsp;3238 words&nbsp;·&nbsp;Fuwei Li</footer><a class=entry-link aria-label="post link to Connecting Points with Grace: A Study on Natural Path Generation Methods" href=https://livey.github.io/posts/2025-04-16-path-genrating/></a></article><footer class=page-footer><nav class=pagination><a class=next href=https://livey.github.io/posts/page/2/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2026 <a href=https://livey.github.io/>Fuwei's Tech Notes</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>
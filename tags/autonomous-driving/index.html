<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Autonomous Driving | Fuwei's Tech Notes</title>
<meta name=keywords content><meta name=description content="Technical blog covering topics in autonomous driving, computer vision, robotics, optimization, and software engineering"><meta name=author content="Fuwei Li"><link rel=canonical href=https://livey.github.io/tags/autonomous-driving/><link crossorigin=anonymous href=/assets/css/stylesheet.d6fcd20a4fb86efa4dfac8ec95da60244cc8871042183da1ef28e3a762ad79c8.css integrity="sha256-1vzSCk+4bvpN+sjsldpgJEzIhxBCGD2h7yjjp2Ktecg=" rel="preload stylesheet" as=style><link rel=icon href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://livey.github.io/tags/autonomous-driving/index.xml><link rel=alternate hreflang=en href=https://livey.github.io/tags/autonomous-driving/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="index, follow"><meta name=author content="Fuwei Li"><meta name=description content="Technical blog covering topics in autonomous driving, computer vision, robotics, optimization, and software engineering"><meta property="og:type" content="article"><meta property="og:url" content="https://livey.github.io/tags/autonomous-driving/"><meta property="og:title" content="Autonomous Driving"><meta property="og:description" content="Technical blog covering topics in autonomous driving, computer vision, robotics, optimization, and software engineering"><meta property="og:image" content="https://livey.github.io/images/site-preview.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="Autonomous Driving"><meta name=twitter:description content="Technical blog covering topics in autonomous driving, computer vision, robotics, optimization, and software engineering"><meta name=twitter:image content="https://livey.github.io/images/site-preview.jpg"><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css integrity=sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js integrity=sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><meta property="og:url" content="https://livey.github.io/tags/autonomous-driving/"><meta property="og:site_name" content="Fuwei's Tech Notes"><meta property="og:title" content="Autonomous Driving"><meta property="og:description" content="Technical blog covering topics in autonomous driving, computer vision, robotics, optimization, and software engineering"><meta property="og:locale" content="en"><meta property="og:type" content="website"><meta property="og:image" content="https://livey.github.io/images/site-preview.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://livey.github.io/images/site-preview.jpg"><meta name=twitter:title content="Autonomous Driving"><meta name=twitter:description content="Technical blog covering topics in autonomous driving, computer vision, robotics, optimization, and software engineering"></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://livey.github.io/ accesskey=h title="Home (Alt + H)"><img src=https://livey.github.io/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://livey.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://livey.github.io/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://livey.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://livey.github.io/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://livey.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://livey.github.io/tags/>Tags</a></div><h1>Autonomous Driving
<a href=/tags/autonomous-driving/index.xml title=RSS aria-label=RSS><svg viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" height="23"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></h1></header><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>LiDAR Extrinsic Parameter Adjustment for SLAM Recalibration</h2></header><div class=entry-content><p>Occasionally, we discover that the LiDAR extrinsic parameters are inaccurate. In such cases, we aim to recalibrate the SLAM poses and maps based on the updated parameters, without the need to rerun the entire SLAM process. By doing so, we can keep the annotations and the original SLAM map, which saves human effort and computational resources.
Raw Data Given LiDAR points in the LiDAR coordinate system
$$\mathbf{p}^{orig} = \bigcup_{t=0:T, i=1:N_t}\{\mathbf{p}_{t,i}\}$$Where $t$ is the time index, $i$ is the point index at time $t$, and $N_t$ is the number of points at time $t$.
...</p></div><footer class=entry-footer><span title='2025-08-21 00:00:00 +0000 UTC'>August 21, 2025</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;894 words&nbsp;·&nbsp;Fuwei Li</footer><a class=entry-link aria-label="post link to LiDAR Extrinsic Parameter Adjustment for SLAM Recalibration" href=https://livey.github.io/posts/2025-08-21-lidar-adjust/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Bundle Adjustment for LiDAR SLAM: Mathematical Formulation and Optimization</h2></header><div class=entry-content><p>In this post, we will discuss the post-processing of LiDAR SLAM. We mainly focus on its problem formulation. The content of this post follows papers [1] and [2].
Problem Formulation Factor graph representation of bundle adjustment formulation. (Fig. 1 of [2]) With LiDAR poses, each denoted by $\mathbf{T}_j = (\mathbf{R}_j,\mathbf{t}_j)$ $(j=1,\ldots,M_p)$, the bundle adjustment refers to simultaneously determining all the LiDAR poses (denoted by $\mathbf{T} = (\mathbf{T}_1,\cdots,\mathbf{T}_{M_p})$) and feature parameters (denoted by $\boldsymbol{\pi} = (\pi_1,\cdots,\pi_{M_f})$), such that the reconstructed map agrees with the LiDAR measurements to the best extent. Denote $c(\pi_i,\mathbf{T})$ the map consistency due to the $i$-th feature; a straightforward BA formulation is
...</p></div><footer class=entry-footer><span title='2025-08-20 00:00:00 +0000 UTC'>August 20, 2025</span>&nbsp;·&nbsp;6 min&nbsp;·&nbsp;1078 words&nbsp;·&nbsp;Fuwei Li</footer><a class=entry-link aria-label="post link to Bundle Adjustment for LiDAR SLAM: Mathematical Formulation and Optimization" href=https://livey.github.io/posts/2025-08-20-lidar-post-processing/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Probabilistic Collision Loss: Bounds and Soft Distance Maps for Autonomous Driving</h2></header><div class=entry-content><p>This post explores collision loss design for end-to-end autonomous driving training, focusing on extending PLUTO’s binary occupancy map approach to handle probabilistic maps. The method enables safer autonomous driving by providing smooth, uncertainty-aware collision avoidance while maintaining computational efficiency.
Using Signed Distance Map with Binary Occupancy Map How PLUTO Builds the Loss Map [2] Vehicle Model In PLUTO and other planning algorithms, the vehicle is modelded as a series of overlapping discs.
...</p></div><footer class=entry-footer><span title='2025-08-14 00:00:00 +0000 UTC'>August 14, 2025</span>&nbsp;·&nbsp;15 min&nbsp;·&nbsp;3118 words&nbsp;·&nbsp;Fuwei Li</footer><a class=entry-link aria-label="post link to Probabilistic Collision Loss: Bounds and Soft Distance Maps for Autonomous Driving" href=https://livey.github.io/posts/2025-08-13-collission-loss/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>LiDAR-SLAM Decoded: From Point Clouds to Precision Maps</h2></header><div class=entry-content><p>What is SLAM? SLAM demo. SLAM stands for Simultaneous Localization and Mapping. It is a computational problem of constructing or updating a map of an unknown environment while simultaneously keeping track of an agent's location within it. Applications Object Detection Parking Lot Annotation Lane Annotation Lane Reprojection HD Map [source] SLAM has various applications, including:
...</p></div><footer class=entry-footer><span title='2025-07-19 00:00:00 +0000 UTC'>July 19, 2025</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;1001 words&nbsp;·&nbsp;Fuwei Li</footer><a class=entry-link aria-label="post link to LiDAR-SLAM Decoded: From Point Clouds to Precision Maps" href=https://livey.github.io/posts/2025-02-20-slam/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Perspective-n-Point (PnP) Problem</h2></header><div class=entry-content><p>In this post, we will discuss the perspective-n-point (PnP) problem. We will start with the problem definition. Then, gradient-based optimization methods will be introduced. Finally, we will discuss two global optimization methods.
Problem Formulation The core task of the Perspective-n-Point (PnP) problem is to determine the pose—specifically, the rotation and translation—of a calibrated camera in 3D space. This is achieved by using a set of known 3D points in the world and their corresponding 2D projections observed on the camera’s image sensor.
...</p></div><footer class=entry-footer><span title='2025-07-19 00:00:00 +0000 UTC'>July 19, 2025</span>&nbsp;·&nbsp;11 min&nbsp;·&nbsp;2209 words&nbsp;·&nbsp;Fuwei Li</footer><a class=entry-link aria-label="post link to Perspective-n-Point (PnP) Problem" href=https://livey.github.io/posts/2025-05-15-pnp/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Connecting Points with Grace: A Study on Natural Path Generation Methods</h2></header><div class=entry-content><p>Given a starting point, starting direction, ending point, and ending direction, the goal is to generate a feasible and “natural” path that connects the two points. This path should adhere to vehicle dynamics and avoids obstacles. However, it is hard to define what is “natural”.
Path Planning In this section, we review some classical path planning methods. We ignore the algorithmic details and focus on the resulting path shapes to provide an overview. The demonstration images are generated using the code repository [1].
...</p></div><footer class=entry-footer><span title='2025-04-16 00:00:00 +0000 UTC'>April 16, 2025</span>&nbsp;·&nbsp;16 min&nbsp;·&nbsp;3238 words&nbsp;·&nbsp;Fuwei Li</footer><a class=entry-link aria-label="post link to Connecting Points with Grace: A Study on Natural Path Generation Methods" href=https://livey.github.io/posts/2025-04-16-path-genrating/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Coordinate Systems in Autonomous Driving</h2></header><div class=entry-content><p>In this post, we will discuss the coordinate systems commonly used in autonomous driving. In practice, different positioning providers may define their own coordinate systems. This post will introduce the fundamental concepts of these coordinate systems and explain how to convert between them for your specific needs.
Pose on the Earth When we talk about pose, we refer to the position and orientation of an object in the world. In the context of autonomous driving, the world is the Earth. Therefore, pose describes the position and orientation of an object relative to the Earth.
...</p></div><footer class=entry-footer><span title='2025-02-07 00:00:00 +0000 UTC'>February 7, 2025</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;1000 words&nbsp;·&nbsp;Fuwei Li</footer><a class=entry-link aria-label="post link to Coordinate Systems in Autonomous Driving" href=https://livey.github.io/posts/2025-02-07-coordinate/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>A Deep Dive into End-of-Line Camera Extrinsic Calibration for Autonomous Vehicles</h2></header><div class=entry-content><p>In this post, we will discuss the end-of-line (EOL) camera calibration, especially for camera bird’s-eye view (BEV) extrinsic calibration.
Suggested Pipeline Do single camera intrinsic calibration
Measure each corner in the world coordinate
Refine the corners’ coordinates according to board constraints (plane, parallel, equally spaced)
Find the plane equation in the world coordinate
Initialize each camera’s extrinsic parameters by solving the perspective-n-point (PnP) problem
Estimate the 3D coordinates by the intersection of the image ray and board plane
...</p></div><footer class=entry-footer><span title='2025-02-03 00:00:00 +0000 UTC'>February 3, 2025</span>&nbsp;·&nbsp;11 min&nbsp;·&nbsp;2234 words&nbsp;·&nbsp;Fuwei Li</footer><a class=entry-link aria-label="post link to A Deep Dive into End-of-Line Camera Extrinsic Calibration for Autonomous Vehicles" href=https://livey.github.io/posts/2025-02-eol-calib/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Pose Tracking with Iterative Extended Kalman Filter</h2></header><div class=entry-content><p>Tracking ego pose is critical in autonomous driving. In this article, we will discuss how to fuse the IMU, wheel encoder, GPS, etc. to track the ego pose. We will derive the pose tracking algorithm based on the iterative extended Kalman filter. This document mainly follows [1] and [2].
Preliminaries Let $\mathcal{M}$ be the manifold of dimension $n$ in consideration (e.g., $\mathcal{M} = SO(3)$). Since manifolds are locally homeomorphic to $\mathbb{R}^n$, we can establish a bijective mapping from a local neighborhood on $\mathcal{M}$ to its tangent space $\mathbb{R}^n$ via two encapsulation operators $\boxplus$ and $\boxminus$:
...</p></div><footer class=entry-footer><span title='2024-12-24 00:00:00 +0000 UTC'>December 24, 2024</span>&nbsp;·&nbsp;15 min&nbsp;·&nbsp;3073 words&nbsp;·&nbsp;Fuwei Li</footer><a class=entry-link aria-label="post link to Pose Tracking with Iterative Extended Kalman Filter" href=https://livey.github.io/posts/2024-12-pose-tracking/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Position Filtering with Ego Motion Compensation</h2></header><div class=entry-content><p>When tracking an object’s position, it is typically done from the ego vehicle’s perspective. However, the ego’s motion makes tracking the object somewhat difficult. The basic idea is to perform the tracking in the world coordinate system, then transform the results into the ego-car’s coordinate system. In this post, we will discuss how to concisely incorporate the ego’s motion into the object tracking process.
Continuous Form Coordinate Definitions The target’s movement in the world coordinate: $\mathbf{o}(t)$; ego-car movement in the world coordinate: $\mathbf{g}(t)$; ego-car’s heading angle: $\theta(t)$; observed target’s coordinate relative to the ego-car: $\mathbf{x}(t)$.
...</p></div><footer class=entry-footer><span title='2024-12-02 00:00:00 +0000 UTC'>December 2, 2024</span>&nbsp;·&nbsp;11 min&nbsp;·&nbsp;2210 words&nbsp;·&nbsp;Fuwei Li</footer><a class=entry-link aria-label="post link to Position Filtering with Ego Motion Compensation" href=https://livey.github.io/posts/2024-12-positioning-track/></a></article><footer class=page-footer><nav class=pagination><a class=next href=https://livey.github.io/tags/autonomous-driving/page/2/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2025 <a href=https://livey.github.io/>Fuwei's Tech Notes</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>
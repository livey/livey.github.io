<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Signal Processing | Fuwei's Tech Notes</title>
<meta name=keywords content><meta name=description content="Technical blog covering topics in autonomous driving, computer vision, robotics, optimization, and software engineering"><meta name=author content="Fuwei Li"><link rel=canonical href=https://livey.github.io/tags/signal-processing/><link crossorigin=anonymous href=/assets/css/stylesheet.d6fcd20a4fb86efa4dfac8ec95da60244cc8871042183da1ef28e3a762ad79c8.css integrity="sha256-1vzSCk+4bvpN+sjsldpgJEzIhxBCGD2h7yjjp2Ktecg=" rel="preload stylesheet" as=style><link rel=icon href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://livey.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://livey.github.io/tags/signal-processing/index.xml><link rel=alternate hreflang=en href=https://livey.github.io/tags/signal-processing/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="index, follow"><meta name=author content="Fuwei Li"><meta name=description content="Technical blog covering topics in autonomous driving, computer vision, robotics, optimization, and software engineering"><meta property="og:type" content="article"><meta property="og:url" content="https://livey.github.io/tags/signal-processing/"><meta property="og:title" content="Signal Processing"><meta property="og:description" content="Technical blog covering topics in autonomous driving, computer vision, robotics, optimization, and software engineering"><meta property="og:image" content="https://livey.github.io/images/site-preview.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="Signal Processing"><meta name=twitter:description content="Technical blog covering topics in autonomous driving, computer vision, robotics, optimization, and software engineering"><meta name=twitter:image content="https://livey.github.io/images/site-preview.jpg"><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css integrity=sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js integrity=sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><meta property="og:url" content="https://livey.github.io/tags/signal-processing/"><meta property="og:site_name" content="Fuwei's Tech Notes"><meta property="og:title" content="Signal Processing"><meta property="og:description" content="Technical blog covering topics in autonomous driving, computer vision, robotics, optimization, and software engineering"><meta property="og:locale" content="en"><meta property="og:type" content="website"><meta property="og:image" content="https://livey.github.io/images/site-preview.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://livey.github.io/images/site-preview.jpg"><meta name=twitter:title content="Signal Processing"><meta name=twitter:description content="Technical blog covering topics in autonomous driving, computer vision, robotics, optimization, and software engineering"></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://livey.github.io/ accesskey=h title="Home (Alt + H)"><img src=https://livey.github.io/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://livey.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://livey.github.io/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://livey.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://livey.github.io/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://livey.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://livey.github.io/tags/>Tags</a></div><h1>Signal Processing
<a href=/tags/signal-processing/index.xml title=RSS aria-label=RSS><svg viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" height="23"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></h1></header><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Fast LIO Paper Reading</h2></header><div class=entry-content><p>In this document, we provide detailed derivations complementing those presented in [2].
Details of the derivation Discrete model Based on the $\boxplus$ operation defined above, we can discretize the continuous model in (1) at the IMU sampling period $\Delta t$ using a zero-order holder. The resultant discrete model is
$$ \mathbf{x}_{i+1} = \mathbf{x}_i \boxplus (\Delta t f(\mathbf{x}_i, \mathbf{u}_i, \mathbf{w}_i))$$where $i$ is the index of IMU measurements, and the function $f$, state $\mathbf{x}$, input $\mathbf{u}$, and noise $\mathbf{w}$ are defined below:
...</p></div><footer class=entry-footer><span title='2024-12-27 00:00:00 +0000 UTC'>December 27, 2024</span>&nbsp;·&nbsp;7 min&nbsp;·&nbsp;1401 words&nbsp;·&nbsp;Fuwei Li</footer><a class=entry-link aria-label="post link to Fast LIO Paper Reading" href=https://livey.github.io/posts/2024-12-fast-lio/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Iterative Closest Point Problem</h2></header><div class=entry-content><p>Problem Formulation Let two 3D point-sets $\mathcal{X} = \{\mathbf{x}_i\}, i = 1, \ldots, N$ and $\mathcal{Y} = \{\mathbf{y}_j\}, j = 1, \ldots, M$, where $\mathbf{x}_i, \mathbf{y}_j \in \mathbb{R}^3$ are point coordinates, be the data point-set and the model point-set respectively. The goal is to estimate a rigid motion with rotation $\mathbf{R} \in SO(3)$ and translation $\mathbf{t} \in \mathbb{R}^3$ that minimizes the following $L_2$-error $E$:
$$\underset{\mathbf{R}, \mathbf{t}}{\arg\min E(\mathbf{R}}, \mathbf{t}) = \sum_{i=1}^N e_i(\mathbf{R}, \mathbf{t})^2 = \sum_{i=1}^N \left\| \mathbf{R} \mathbf{x}_i + \mathbf{t} - \mathbf{y}_{j^*} \right\|^2 \tag{1}$$where $e_i(\mathbf{R}, \mathbf{t})$ is the per-point residual error for $x_i$. Given $\mathbf{R}$ and $\mathbf{t}$, the point $y_{j^*} \in \mathcal{Y}$ is denoted as the optimal correspondence of $x_i$, which is the closest point to the transformed $x_i$ in $\mathcal{Y}$, i.e.,
...</p></div><footer class=entry-footer><span title='2024-12-26 00:00:00 +0000 UTC'>December 26, 2024</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;576 words&nbsp;·&nbsp;Fuwei Li</footer><a class=entry-link aria-label="post link to Iterative Closest Point Problem" href=https://livey.github.io/posts/2024-12-icp/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Radar Signal Processing: A Tutorial</h2></header><div class=entry-content><p>System Diagram See Appendix.VII
Figure 1: System diagram of a typical 4D mmWave radar signal processing chain (figure from [1])
Single Object Tx-Rx Model Below is a mathematical formalization of each major step in the traditional 4D mmWave Frequency Modulated Continuous Wave (FMCW) radar signal processing chain, from transmitted signals through to point-cloud generation. Please note that these equations represent a general framework; actual implementations may vary slightly depending on specific system parameters and design choices.
...</p></div><footer class=entry-footer><span title='2024-12-26 00:00:00 +0000 UTC'>December 26, 2024</span>&nbsp;·&nbsp;23 min&nbsp;·&nbsp;4800 words&nbsp;·&nbsp;Fuwei Li</footer><a class=entry-link aria-label="post link to Radar Signal Processing: A Tutorial" href=https://livey.github.io/posts/2024-12-radar-processing/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Pose Tracking with Iterative Extended Kalman Filter</h2></header><div class=entry-content><p>Tracking ego pose is critical in autonomous driving. In this article, we will discuss how to fuse the IMU, wheel encoder, GPS, etc. to track the ego pose. We will derive the pose tracking algorithm based on the iterative extended Kalman filter. This document mainly follows [1] and [2].
Preliminaries Let $\mathcal{M}$ be the manifold of dimension $n$ in consideration (e.g., $\mathcal{M} = SO(3)$). Since manifolds are locally homeomorphic to $\mathbb{R}^n$, we can establish a bijective mapping from a local neighborhood on $\mathcal{M}$ to its tangent space $\mathbb{R}^n$ via two encapsulation operators $\boxplus$ and $\boxminus$:
...</p></div><footer class=entry-footer><span title='2024-12-24 00:00:00 +0000 UTC'>December 24, 2024</span>&nbsp;·&nbsp;14 min&nbsp;·&nbsp;2940 words&nbsp;·&nbsp;Fuwei Li</footer><a class=entry-link aria-label="post link to Pose Tracking with Iterative Extended Kalman Filter" href=https://livey.github.io/posts/2024-12-pose-tracking/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Position Filtering with Ego Motion Compensation</h2></header><div class=entry-content><p>When tracking an object’s position, we always from the ego’s perspective. However, ego’s motion makes the tracking of the object a little difficult. The basic idea is doing the tracking on the world coordinate, then transforming into the ego-car’s coordinate. In this post, we will discusss how to combine the ego’s motion into the object’s tracking concisely.
Continuous Form Definitions The target’s movement in the world coordinate: $o(t)$; ego-car movement in the world coordinate: $g(t)$; ego-car’s heading angle: $\theta(t)$; observed target’s coordinate: $f(t)$.
...</p></div><footer class=entry-footer><span title='2024-12-02 00:00:00 +0000 UTC'>December 2, 2024</span>&nbsp;·&nbsp;10 min&nbsp;·&nbsp;2044 words&nbsp;·&nbsp;Fuwei Li</footer><a class=entry-link aria-label="post link to Position Filtering with Ego Motion Compensation" href=https://livey.github.io/posts/2024-12-positiong-track/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Angle Kalman Filter</h2></header><div class=entry-content><p>Besides object position tracking, heading angle tracking is also critical in autonomous driving. In this article, we will discuss how to track the angle of an object using the Kalman filter and how to do motion compensation.
Wrap the angle In this paper “On wrapping the Kalman filter and estimating with the SO(2) group”, the author has the conclusion:
“based on the mathematically grounded framework of filtering on Lie groups, yields the same result as heuristically wrapping the angular variable within the EKF framework”.
...</p></div><footer class=entry-footer><span title='2024-11-30 00:00:00 +0000 UTC'>November 30, 2024</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;362 words&nbsp;·&nbsp;Fuwei Li</footer><a class=entry-link aria-label="post link to Angle Kalman Filter" href=https://livey.github.io/posts/2024-12-angle-filter/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Rolling Shutter Camera Projection</h2></header><div class=entry-content><p>Unlike global shutter cameras that capture the entire frame at once, rolling shutter cameras capture each row sequentially, leading to image distortions when there is motion. This paper discusses the rolling shutter effect in cameras and methods to handle it.
Fundamentals of Rolling Shutter Camera Global Shutter Camera v.s. Rolling Shutter Camera. (a) Global Shutter Camera. (b) Rolling Shutter Camera. (figure from [6]) To efficiently capture and read the image, the time constraints for rolling shutter camera are:
...</p></div><footer class=entry-footer><span title='2024-11-25 00:00:00 +0000 UTC'>November 25, 2024</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;1053 words&nbsp;·&nbsp;Fuwei Li</footer><a class=entry-link aria-label="post link to Rolling Shutter Camera Projection" href=https://livey.github.io/posts/2024-12-rolling-shutter/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Camera Projection via View Frustum Culling</h2></header><div class=entry-content><p>When projecting a 3D object onto the camera plane, we usually use the pinhole model. However, it only applies to a single point. When we consider a solid object, we need to consider the interaction between the object and the camera, especially when the object is close to the camera. In the following, we will use the view frustum to cull the object and project it onto the camera plane.
...</p></div><footer class=entry-footer><span title='2024-11-24 00:00:00 +0000 UTC'>November 24, 2024</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;765 words&nbsp;·&nbsp;Fuwei Li</footer><a class=entry-link aria-label="post link to Camera Projection via View Frustum Culling" href=https://livey.github.io/posts/2024-12-camera-frustum/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>The Assignment Problem and Primal-Dual Algorithm</h2></header><div class=entry-content><p>This post discusses the assignment problem, its primal-dual interpretation, and the gated Hungarian algorithm.
Tutor HungarianAlgorithm and [4] gives a nice interpretation of the dual-prime of the Hungarian algorithm.
Prime-Dual Interpretation of Hungarian Algorithm [4] The following linear program gives a lower bound on the optimal value of the assignment problem:
$$\begin{array}{ll} \min & \sum_{i \in I} \sum_{j \in J} c_{i j} x_{i j} \\ \text { s.t. } & \sum_{j \in J} x_{i j}=1 \text { for all } i \in I \\ & \sum_{i \in I} x_{i j}=1 \text { for all } j \in J \\ & x_{i j} \geq 0 \end{array}$$To see this, note that we can let $x_{i j}=1$ if $i$ is assigned to $j$ and 0 otherwise. Clearly, this is a feasible solution to the L.P, so the optimal value of the LP must be at most the optimal value of the assignment problem.
...</p></div><footer class=entry-footer><span title='2024-11-20 00:00:00 +0000 UTC'>November 20, 2024</span>&nbsp;·&nbsp;7 min&nbsp;·&nbsp;1462 words&nbsp;·&nbsp;Fuwei Li</footer><a class=entry-link aria-label="post link to The Assignment Problem and Primal-Dual Algorithm" href=https://livey.github.io/posts/2024-11-assignment/></a></article></main><footer class=footer><span>&copy; 2025 <a href=https://livey.github.io/>Fuwei's Tech Notes</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>